{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://colab.research.google.com/github/dipanjanS/nlp_workshop_odsc19/blob/master/Module05%20-%20NLP%20Applications/Project03%20-%20Sentiment%20Analysis%20Unsupervised%20Lexical%20Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Sentiment Analysis with Lexicon Models\n",
    "\n",
    "We talked about unsupervised learning methods in the past, which refer to specific\n",
    "modeling methods that can be applied directly to data features without the presence of\n",
    "labeled data. One of the major challenges in any organization is getting labeled datasets\n",
    "due the lack of time as well as resources to do this tedious task. Unsupervised methods\n",
    "are very useful in this scenario and we look at some of these methods in this section.\n",
    "Even though we have labeled data, this section should give you a good idea of how\n",
    "lexicon based models work and you can apply them to your own datasets when you do\n",
    "not have labeled data.\n",
    "\n",
    "\n",
    "Unsupervised sentiment analysis models use well curated knowledgebases,\n",
    "ontologies, lexicons, and databases, which have detailed information pertaining to\n",
    "subjective words, phrases including sentiment, mood, polarity, objectivity, subjectivity,\n",
    "and so on. \n",
    "\n",
    "A lexicon model typically uses a lexicon, also known as a dictionary or\n",
    "vocabulary of words specifically aligned to sentiment analysis. These lexicons contain\n",
    "a list of words associated with positive and negative sentiment, polarity (magnitude of\n",
    "negative or positive score), parts of speech (POS) tags, subjectivity classifiers (strong,\n",
    "weak, neutral), mood, modality, and so on. \n",
    "\n",
    "You can use these lexicons and compute\n",
    "the sentiment of a text document by matching the presence of specific words from\n",
    "the lexicon and then looking at other factors like presence of negation parameters,\n",
    "surrounding words, overall context, phrases, and aggregate overall sentiment polarity\n",
    "scores to decide the final sentiment score. \n",
    "\n",
    "There are several popular lexicon models\n",
    "used for sentiment analysis. Some of them are as follows:\n",
    "\n",
    "- Bing Liu’s lexicon\n",
    "- MPQA subjectivity lexicon\n",
    "- Pattern lexicon\n",
    "- TextBlob lexicon\n",
    "- AFINN lexicon\n",
    "- SentiWordNet lexicon\n",
    "- VADER lexicon\n",
    "\n",
    "This is not an exhaustive list of lexicon models but these are definitely among the\n",
    "most popular ones available today. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x0DjFMcgdVKt"
   },
   "source": [
    "# Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "qkT1MELHbfpN",
    "outputId": "fe37338f-de81-416a-97a0-4dc996c5efdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in /usr/local/lib/python3.6/dist-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob) (3.2.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob) (1.12.0)\n",
      "Requirement already satisfied: textsearch in /usr/local/lib/python3.6/dist-packages (0.0.17)\n",
      "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.6/dist-packages (from textsearch) (1.4.0)\n",
      "Requirement already satisfied: Unidecode in /usr/local/lib/python3.6/dist-packages (from textsearch) (1.1.1)\n",
      "Requirement already satisfied: contractions in /usr/local/lib/python3.6/dist-packages (0.0.21)\n",
      "Requirement already satisfied: afinn in /usr/local/lib/python3.6/dist-packages (0.1)\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install textblob\n",
    "!pip install textsearch\n",
    "!pip install contractions\n",
    "!pip install afinn\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HwY5iYHpeH-V"
   },
   "source": [
    "# Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YRx1nYcwcyIi"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import textblob\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "np.set_printoptions(precision=2, linewidth=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z44C-8TZeVrc"
   },
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DLwcac_Icx7c"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r'https://github.com/dipanjanS/nlp_workshop_dhs18/raw/master/Unit%2011%20-%20Sentiment%20Analysis%20-%20Unsupervised%20Learning/movie_reviews.csv.bz2')\n",
    "\n",
    "reviews = np.array(dataset['review'])\n",
    "sentiments = np.array(dataset['sentiment'])\n",
    "\n",
    "# extract data for model evaluation\n",
    "test_reviews = reviews[35000:]\n",
    "test_sentiments = sentiments[35000:]\n",
    "sample_review_ids = [7626, 3533, 13010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QXZHK_ehf-pk"
   },
   "source": [
    "# Sentiment Analysis with TextBlob\n",
    "\n",
    "The lexicon that TextBlob uses is the\n",
    "same one as pattern and is available in their source code on GitHub (https://github.com/sloria/TextBlob/blob/dev/textblob/en/en-sentiment.xml). Some sample\n",
    "examples are shown from the lexicon as follows.\n",
    "\n",
    "```\n",
    "<word form=\"abhorrent\" wordnet_id=\"a-1625063\" pos=\"JJ\" sense=\"offensive\n",
    "to the mind\" polarity=\"-0.7\" subjectivity=\"0.8\" intensity=\"1.0\"\n",
    "reliability=\"0.9\" />\n",
    "<word form=\"able\" cornetto_synset_id=\"n_a-534450\" wordnet_id=\"a-01017439\"\n",
    "pos=\"JJ\" sense=\"having a strong healthy body\" polarity=\"0.5\"\n",
    "subjectivity=\"1.0\" intensity=\"1.0\" confidence=\"0.9\" />\n",
    "```\n",
    "\n",
    "Typically, specific adjectives have a polarity score (negative/positive, -1.0 to +1.0)\n",
    "and a subjectivity score (objective/subjective, +0.0 to +1.0). \n",
    "\n",
    "The reliability score specifies\n",
    "if an adjective was hand-tagged (1.0) or inferred (0.7). Words are tagged per sense, e.g.,\n",
    "ridiculous (pitiful) = negative, ridiculous (humorous) = positive. \n",
    "\n",
    "The Cornetto id (lexical\n",
    "unit id) and Cornetto synset id refer to the Cornetto lexical database for Dutch. The\n",
    "WordNet id refers to the WordNet3 lexical database for English. The part-of-speech\n",
    "tags (POS) use the Penn Treebank convention. Let’s look at how we can use TextBlob for\n",
    "sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FqxUHMuvg-5E"
   },
   "source": [
    "## Predict sentiment for sample reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "QZi_49bocx5L",
    "outputId": "dd1df26f-85a1-4c71-9b62-7887158db361"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REVIEW: no comment - stupid movie, acting average or worse... screenplay - no sense at all... SKIP IT!\n",
      "Actual Sentiment: negative\n",
      "Predicted Sentiment polarity: -0.3625\n",
      "------------------------------------------------------------\n",
      "REVIEW: I don't care if some people voted this movie to be bad. If you want the Truth this is a Very Good Movie! It has every thing a movie should have. You really should Get this one.\n",
      "Actual Sentiment: positive\n",
      "Predicted Sentiment polarity: 0.16666666666666674\n",
      "------------------------------------------------------------\n",
      "REVIEW: Worst horror film ever but funniest film ever rolled in one you have got to see this film it is so cheap it is unbeliaveble but you have to see it really!!!! P.s watch the carrot\n",
      "Actual Sentiment: positive\n",
      "Predicted Sentiment polarity: -0.037239583333333326\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for review, sentiment in zip(test_reviews[sample_review_ids], test_sentiments[sample_review_ids]):\n",
    "    print('REVIEW:', review)\n",
    "    print('Actual Sentiment:', sentiment)\n",
    "    print('Predicted Sentiment polarity:', textblob.TextBlob(review).sentiment.polarity)\n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I-FF1xWAhAy1"
   },
   "source": [
    "## Predict sentiment for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4NJIEroRcx3Z"
   },
   "outputs": [],
   "source": [
    "sentiment_polarity = [textblob.TextBlob(review).sentiment.polarity for review in test_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vLKVFxDRenfx"
   },
   "outputs": [],
   "source": [
    "predicted_sentiments = ['positive' if score >= 0.1 else 'negative' for score in sentiment_polarity]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SPmYAY8vhIo1"
   },
   "source": [
    "## Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "colab_type": "code",
    "id": "6clulh_DeqXc",
    "outputId": "86ece137-b4fd-412f-aa46-ae7cdc8efcbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.76      0.76      7490\n",
      "    positive       0.76      0.78      0.77      7510\n",
      "\n",
      "    accuracy                           0.77     15000\n",
      "   macro avg       0.77      0.77      0.77     15000\n",
      "weighted avg       0.77      0.77      0.77     15000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>5668</td>\n",
       "      <td>1822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>1675</td>\n",
       "      <td>5835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          negative  positive\n",
       "negative      5668      1822\n",
       "positive      1675      5835"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['negative', 'positive']\n",
    "print(classification_report(test_sentiments, predicted_sentiments))\n",
    "pd.DataFrame(confusion_matrix(test_sentiments, predicted_sentiments), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SvxKg_H8gCfr"
   },
   "source": [
    "# Sentiment Analysis with AFINN\n",
    "\n",
    "The AFINN lexicon is perhaps one of the simplest and most popular lexicons and can be\n",
    "used extensively for sentiment analysis. Developed and curated by Finn Årup Nielsen,\n",
    "you can find more details on this lexicon in the paper by Finn Årup Nielsen, entitled “A\n",
    "New ANEW: Evaluation of a Word List for Sentiment Analysis in Microblogs,” from the\n",
    "proceedings of the ESWC2011 workshop. \n",
    "\n",
    "The current version of the lexicon is AFINN-en-165.\n",
    "txt and it contains over 3,300 words with a polarity score associated with each word.\n",
    "You can find this lexicon at the author’s official GitHub repository along with\n",
    "previous versions of this lexicon including AFINN-111 at https://github.com/\n",
    "fnielsen/afinn/blob/master/afinn/data/. \n",
    "\n",
    "The author has also created a nice wrapper\n",
    "library on top of this in Python called afinn, which we will be using for our analysis\n",
    "needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XgC4PxTXgFIc"
   },
   "outputs": [],
   "source": [
    "from afinn import Afinn\n",
    "\n",
    "afn = Afinn(emoticons=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EjFvOvLJoMOF"
   },
   "source": [
    "## Predict sentiment for sample reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "h8UjbayGgFGO",
    "outputId": "85e7ddcb-e76d-4ee1-cd12-630343fd6add"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REVIEW: no comment - stupid movie, acting average or worse... screenplay - no sense at all... SKIP IT!\n",
      "Actual Sentiment: negative\n",
      "Predicted Sentiment polarity: -7.0\n",
      "------------------------------------------------------------\n",
      "REVIEW: I don't care if some people voted this movie to be bad. If you want the Truth this is a Very Good Movie! It has every thing a movie should have. You really should Get this one.\n",
      "Actual Sentiment: positive\n",
      "Predicted Sentiment polarity: 3.0\n",
      "------------------------------------------------------------\n",
      "REVIEW: Worst horror film ever but funniest film ever rolled in one you have got to see this film it is so cheap it is unbeliaveble but you have to see it really!!!! P.s watch the carrot\n",
      "Actual Sentiment: positive\n",
      "Predicted Sentiment polarity: -3.0\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for review, sentiment in zip(test_reviews[sample_review_ids], test_sentiments[sample_review_ids]):\n",
    "    print('REVIEW:', review)\n",
    "    print('Actual Sentiment:', sentiment)\n",
    "    print('Predicted Sentiment polarity:', afn.score(review))\n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0JIrOyKGgFDr"
   },
   "source": [
    "## Predict sentiment for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Ff40CrDgFA4"
   },
   "outputs": [],
   "source": [
    "sentiment_polarity = [afn.score(review) for review in test_reviews]\n",
    "predicted_sentiments = ['positive' if score >= 1.0 else 'negative' for score in sentiment_polarity]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bW02o_LpgE9h"
   },
   "source": [
    "## Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "colab_type": "code",
    "id": "F7D1Mh1ZoYiD",
    "outputId": "7926c458-ebe2-410d-c318-fceeb06c387d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.57      0.67      7490\n",
      "    positive       0.67      0.85      0.75      7510\n",
      "\n",
      "    accuracy                           0.71     15000\n",
      "   macro avg       0.73      0.71      0.71     15000\n",
      "weighted avg       0.73      0.71      0.71     15000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>4301</td>\n",
       "      <td>3189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>1134</td>\n",
       "      <td>6376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          negative  positive\n",
       "negative      4301      3189\n",
       "positive      1134      6376"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['negative', 'positive']\n",
    "print(classification_report(test_sentiments, predicted_sentiments))\n",
    "pd.DataFrame(confusion_matrix(test_sentiments, predicted_sentiments), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yuxTduACrcAt",
    "outputId": "4dd25aa5-ce93-4e86-ab19-1fce96583781"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import contractions\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.strip()\n",
    "    doc = contractions.fix(doc)\n",
    "    return doc\n",
    "\n",
    "normalize_corpus = np.vectorize(normalize_document)\n",
    "\n",
    "norm_corpus = normalize_corpus(test_reviews)\n",
    "len(norm_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ISeRrNhypJrk"
   },
   "source": [
    "# Sentiment Analysis with VADER\n",
    "\n",
    "The VADER lexicon, developed by C.J. Hutto, is based on a rule-based sentiment analysis\n",
    "framework, specifically tuned to analyze sentiments in social media. VADER stands for\n",
    "Valence Aware Dictionary and sEntiment Reasoner. Details about this framework can\n",
    "be read in the original paper by Hutto, C.J., and Gilbert, E.E. (2014), entitled “VADER:\n",
    "A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text,” from\n",
    "the proceedings of the Eighth International Conference on Weblogs and Social Media\n",
    "(ICWSM-14). You can use the library based on NLTK’s interface under the `nltk.\n",
    "sentiment.vader` module.\n",
    "\n",
    "You can also download the actual lexicon or install the framework from https://\n",
    "github.com/cjhutto/vaderSentiment, which also contains detailed information about\n",
    "VADER. This lexicon, present in the file titled vader_lexicon.txt, contains necessary\n",
    "sentiment scores associated with words, emoticons, and slangs (like wtf, lol, nah, and\n",
    "so on). \n",
    "\n",
    "There were a total of over 9,000 lexical features from which over 7,500 curated\n",
    "lexical features were finally selected in the lexicon with proper validated valence scores.\n",
    "\n",
    "Each feature was rated on a scale from `\"[-4] Extremely Negative\" to \"[4] Extremely Positive\", with allowance for \"[0] Neutral (or Neither, N/A)\"`.\n",
    "\n",
    "The process of selecting lexical features was done by keeping all features that had\n",
    "a non-zero mean rating and whose standard deviation was less than 2.5, which was\n",
    "determined by the aggregate of ten independent raters. We depict a sample from the\n",
    "VADER lexicon as follows:\n",
    "\n",
    "```\n",
    ":( -1.9 1.13578 [-2, -3, -2, 0, -1, -1, -2, -3, -1, -4]\n",
    ":) 2.0 1.18322 [2, 2, 1, 1, 1, 1, 4, 3, 4, 1]\n",
    "...\n",
    "terrorizing -3.0 1.0 [-3, -1, -4, -4, -4, -3, -2, -3, -2, -4]\n",
    "thankful 2.7 0.78102 [4, 2, 2, 3, 2, 4, 3, 3, 2, 2]\n",
    "```\n",
    "\n",
    "Each line in the preceding lexicon sample depicts a unique term, which can either\n",
    "be an emoticon or a word. The first token indicates the word/emoticon, the second\n",
    "token indicates the mean sentiment polarity score, the third token indicates the standard\n",
    "deviation, and the final token indicates a list of scores given by 10 independent scorers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xn6pHpDgpMjr"
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "def analyze_sentiment_vader_lexicon(review, \n",
    "                                    threshold=0.1,\n",
    "                                    verbose=False):    \n",
    "    # analyze the sentiment for review\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(review)\n",
    "    # get aggregate scores and final sentiment\n",
    "    agg_score = scores['compound']\n",
    "    final_sentiment = 'positive' if agg_score >= threshold\\\n",
    "                                   else 'negative'\n",
    "    if verbose:\n",
    "        # display detailed sentiment statistics\n",
    "        positive = str(round(scores['pos'], 2)*100)+'%'\n",
    "        final = round(agg_score, 2)\n",
    "        negative = str(round(scores['neg'], 2)*100)+'%'\n",
    "        neutral = str(round(scores['neu'], 2)*100)+'%'\n",
    "        sentiment_frame = pd.DataFrame([[final_sentiment, final, positive,\n",
    "                                        negative, neutral]],\n",
    "                                        columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'], \n",
    "                                                                      ['Predicted Sentiment', 'Polarity Score',\n",
    "                                                                       'Positive', 'Negative', 'Neutral']], \n",
    "                                                              codes=[[0,0,0,0,0],[0,1,2,3,4]]))\n",
    "        print(sentiment_frame)\n",
    "    \n",
    "    return final_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VAevBuBVq4wA"
   },
   "source": [
    "## Predict sentiment for sample reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "aCdAT9w_pMaX",
    "outputId": "9937770e-852c-49eb-a789-c53eca56f2f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REVIEW: no comment  stupid movie acting average or worse screenplay  no sense at all SKIP IT\n",
      "Actual Sentiment: negative\n",
      "     SENTIMENT STATS:                                         \n",
      "  Predicted Sentiment Polarity Score Positive Negative Neutral\n",
      "0            negative          -0.87     0.0%    50.0%   50.0%\n",
      "------------------------------------------------------------\n",
      "REVIEW: I do not care if some people voted this movie to be bad If you want the Truth this is a Very Good Movie It has every thing a movie should have You really should Get this one\n",
      "Actual Sentiment: positive\n",
      "     SENTIMENT STATS:                                                     \n",
      "  Predicted Sentiment Polarity Score Positive             Negative Neutral\n",
      "0            negative          -0.09    16.0%  14.000000000000002%   70.0%\n",
      "------------------------------------------------------------\n",
      "REVIEW: Worst horror film ever but funniest film ever rolled in one you have got to see this film it is so cheap it is unbeliaveble but you have to see it really Ps watch the carrot\n",
      "Actual Sentiment: positive\n",
      "     SENTIMENT STATS:                                         \n",
      "  Predicted Sentiment Polarity Score Positive Negative Neutral\n",
      "0            negative           0.25    11.0%    11.0%   77.0%\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for review, sentiment in zip(norm_corpus[sample_review_ids], test_sentiments[sample_review_ids]):\n",
    "    print('REVIEW:', review)\n",
    "    print('Actual Sentiment:', sentiment)\n",
    "    pred = analyze_sentiment_vader_lexicon(review, threshold=0.4, verbose=True)    \n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uhd5Y7eT5BLO"
   },
   "source": [
    "## Predict sentiment for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AbMHqrF-cx1Q"
   },
   "outputs": [],
   "source": [
    "predicted_sentiments = [analyze_sentiment_vader_lexicon(review, threshold=0.4, verbose=False) for review in test_reviews]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sva8AEre5Cis"
   },
   "source": [
    "## Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "colab_type": "code",
    "id": "uSIua52x4xm0",
    "outputId": "3145e7e1-c010-4fd2-8858-711869c52ddc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.59      0.67      7490\n",
      "    positive       0.67      0.83      0.74      7510\n",
      "\n",
      "    accuracy                           0.71     15000\n",
      "   macro avg       0.72      0.71      0.71     15000\n",
      "weighted avg       0.72      0.71      0.71     15000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>4429</td>\n",
       "      <td>3061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>1272</td>\n",
       "      <td>6238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          negative  positive\n",
       "negative      4429      3061\n",
       "positive      1272      6238"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['negative', 'positive']\n",
    "print(classification_report(test_sentiments, predicted_sentiments))\n",
    "pd.DataFrame(confusion_matrix(test_sentiments, predicted_sentiments), index=labels, columns=labels)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Sentiment Analysis - Unsupervised Lexical Models.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
