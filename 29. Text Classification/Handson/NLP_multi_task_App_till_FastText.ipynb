{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ef1Ync0SZEMc"
      },
      "outputs": [],
      "source": [
        "# create the requirement file"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "pandas\n",
        "numpy\n",
        "scikit-learn\n",
        "streamlit\n",
        "nltk\n",
        "joblib\n",
        "\n",
        "gensim\n",
        "textblob  #addfor sentiment\n",
        "fasttext  #addfor fasttext embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmUGdjERhOcF",
        "outputId": "af90eb1e-22b9-4cf5-957a-290189dfee3b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-LiSVIZvhkAY",
        "outputId": "1f5b745d-3a38-4057-a7b4-ccea711b9526"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r /content/requirements.txt (line 1)) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r /content/requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r /content/requirements.txt (line 3)) (1.6.1)\n",
            "Collecting streamlit (from -r /content/requirements.txt (line 4))\n",
            "  Downloading streamlit-1.46.1-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from -r /content/requirements.txt (line 5)) (3.9.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from -r /content/requirements.txt (line 6)) (1.5.1)\n",
            "Collecting gensim (from -r /content/requirements.txt (line 8))\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.11/dist-packages (from -r /content/requirements.txt (line 9)) (0.19.0)\n",
            "Collecting fasttext (from -r /content/requirements.txt (line 10))\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /content/requirements.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /content/requirements.txt (line 1)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /content/requirements.txt (line 1)) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r /content/requirements.txt (line 3)) (1.15.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r /content/requirements.txt (line 3)) (3.6.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r /content/requirements.txt (line 4)) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r /content/requirements.txt (line 4)) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r /content/requirements.txt (line 4)) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r /content/requirements.txt (line 4)) (8.2.1)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r /content/requirements.txt (line 4)) (24.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r /content/requirements.txt (line 4)) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r /content/requirements.txt (line 4)) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r /content/requirements.txt (line 4)) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r /content/requirements.txt (line 4)) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r /content/requirements.txt (line 4)) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r /content/requirements.txt (line 4)) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r /content/requirements.txt (line 4)) (4.14.0)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit->-r /content/requirements.txt (line 4))\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r /content/requirements.txt (line 4)) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit->-r /content/requirements.txt (line 4))\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r /content/requirements.txt (line 4)) (6.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->-r /content/requirements.txt (line 5)) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->-r /content/requirements.txt (line 5)) (4.67.1)\n",
            "Collecting numpy (from -r /content/requirements.txt (line 2))\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy>=1.6.0 (from scikit-learn->-r /content/requirements.txt (line 3))\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim->-r /content/requirements.txt (line 8)) (7.1.0)\n",
            "Collecting pybind11>=2.2 (from fasttext->-r /content/requirements.txt (line 10))\n",
            "  Using cached pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext->-r /content/requirements.txt (line 10)) (75.2.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit->-r /content/requirements.txt (line 4)) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit->-r /content/requirements.txt (line 4)) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit->-r /content/requirements.txt (line 4)) (1.44.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r /content/requirements.txt (line 4)) (4.0.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->-r /content/requirements.txt (line 1)) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit->-r /content/requirements.txt (line 4)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit->-r /content/requirements.txt (line 4)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit->-r /content/requirements.txt (line 4)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit->-r /content/requirements.txt (line 4)) (2025.6.15)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim->-r /content/requirements.txt (line 8)) (1.17.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r /content/requirements.txt (line 4)) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit->-r /content/requirements.txt (line 4)) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r /content/requirements.txt (line 4)) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r /content/requirements.txt (line 4)) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r /content/requirements.txt (line 4)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r /content/requirements.txt (line 4)) (0.25.1)\n",
            "Downloading streamlit-1.46.1-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.3-cp311-cp311-linux_x86_64.whl size=4313507 sha256=a48aefee4017700b7e99809a949471fe07696adc7eddc6c009894722507c9c36\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/4f/35/5057db0249224e9ab55a513fa6b79451473ceb7713017823c3\n",
            "Successfully built fasttext\n",
            "Installing collected packages: watchdog, pybind11, numpy, scipy, pydeck, fasttext, gensim, streamlit\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.3\n",
            "    Uninstalling scipy-1.15.3:\n",
            "      Successfully uninstalled scipy-1.15.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fasttext-0.9.3 gensim-4.3.3 numpy-1.26.4 pybind11-2.13.6 pydeck-0.9.1 scipy-1.13.1 streamlit-1.46.1 watchdog-6.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "6404680e1ac549baaeda50370b283f66"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors #add glove\n",
        "\n",
        "import fasttext #add fastext"
      ],
      "metadata": {
        "id": "-s7CETD4hxxC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download the nltk resource\n",
        "\n",
        "# split text into words\n",
        "nltk.download('punkt')\n",
        "\n",
        "# remove common words like \"the,is,and,etc'\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# do lemmatization\n",
        "nltk.download('wordnet')\n",
        "\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ml2PqiPyjqQL",
        "outputId": "6839d745-155e-43b3-a04f-9c143b9decab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create utility file for reusablity"
      ],
      "metadata": {
        "id": "k6Li3Pu-j9EU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set random state\n",
        "# reusing the same dataset after splitting for various algo execution multiple times\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "K7Vv6jLGkz4J"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data loading from the web\n",
        "\n",
        "import os  # to interact with system operation\n",
        "import tarfile # to work with archived files\n",
        "import urllib.request # to download the files from internet\n",
        "\n",
        "# data from the discussion forum with 20 different sub categories\n",
        "\n",
        "# download the dataset from net\n",
        "url = \"http://qwone.com/~jason/20Newsgroups/20news-bydate.tar.gz\"\n",
        "archive_path = \"20news-bydate.tar.gz\"\n",
        "urllib.request.urlretrieve(url,archive_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuZRYHbDlRxZ",
        "outputId": "03a5d83d-2b4a-4197-f781-5d320f81c668"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('20news-bydate.tar.gz', <http.client.HTTPMessage at 0x7b7b05882450>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extract the file\n",
        "with tarfile.open(archive_path, \"r:gz\") as tar:\n",
        "  tar.extractall(path='.')\n"
      ],
      "metadata": {
        "id": "XjD8KoTOnShf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build the list of articles from the files into a dataframe\n",
        "data = []\n",
        "for split in ['20news-bydate-train','20news-bydate-test']: # loop thru train and test folders\n",
        "  for newsgroup in sorted(os.listdir(split)): # loop thru each sub folder\n",
        "    group_path = os.path.join(split,newsgroup)\n",
        "    if not os.path.isdir(group_path):  # skip if there are further folder (go to next iteration)\n",
        "        continue\n",
        "\n",
        "    tgt = newsgroup.split('.')[0] # building main categorization alt/comp/rec/sci/etc\n",
        "\n",
        "    for filename in os.listdir(group_path): # loop thru each article\n",
        "        file_path = os.path.join(group_path,filename)\n",
        "\n",
        "        with open(file_path, encoding='latin1') as f:  # read the artcile\n",
        "          text = f.read()\n",
        "          # append to a dictionary\n",
        "          data.append(\n",
        "             { 'text': text,   # full_article_text\n",
        "              'tgt' : tgt,    # main category(short category)\n",
        "               'true_label_original': newsgroup, # original category with subcategory\n",
        "               'article_id': filename # filename\n",
        "             }\n",
        "         )\n",
        "\n",
        "df = pd.DataFrame(data) # create a df from dictionary\n",
        "print(df.shape)\n",
        "print(df.head(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJA_iwSSn3p7",
        "outputId": "03d4b4cd-1307-45dc-970f-8ead4017c7c2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18846, 4)\n",
            "                                                text  tgt true_label_original  \\\n",
            "0  From: I3150101@dbstu1.rz.tu-bs.de (Benedikt Ro...  alt         alt.atheism   \n",
            "\n",
            "  article_id  \n",
            "0      51261  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.tgt.nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoCCNVWfrAI-",
        "outputId": "5c82a9db-2570-4220-f5b5-671da23ddcc4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.true_label_original.nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CH-r4knQscMy",
        "outputId": "bcbe54ac-4af8-4e6a-ea23-2cbb9b74dec1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.tgt.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zf_a-TAVshw0",
        "outputId": "7d4e1507-a3fe-4c74-b9d1-6cc4056a7f9c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['alt', 'comp', 'misc', 'rec', 'sci', 'soc', 'talk'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.true_label_original.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRoTRwwtsm75",
        "outputId": "28218135-598f-4d94-a04f-0c3defe8d89b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc',\n",
              "       'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware',\n",
              "       'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles',\n",
              "       'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt',\n",
              "       'sci.electronics', 'sci.med', 'sci.space',\n",
              "       'soc.religion.christian', 'talk.politics.guns',\n",
              "       'talk.politics.mideast', 'talk.politics.misc',\n",
              "       'talk.religion.misc'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# major categories\n",
        "alt = alternate\n",
        "comp = computer\n",
        "misc = miscellaneous\n",
        "rec = recreational\n",
        "sci = science\n",
        "soc = social\n",
        "talk = dicussion\n",
        "'''"
      ],
      "metadata": {
        "id": "n_6XV-KTspmz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "146727f4-8fb5-4d30-a040-aa6a1f4189d3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# major categories\\nalt = alternate\\ncomp = computer\\nmisc = miscellaneous\\nrec = recreational\\nsci = science\\nsoc = social\\ntalk = dicussion\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(df.head(4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "r_tkpeveuAaC",
        "outputId": "1b1cdd8d-9cf4-4aca-c20a-7cea7ae0f077"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                text  tgt true_label_original  \\\n",
              "0  From: I3150101@dbstu1.rz.tu-bs.de (Benedikt Ro...  alt         alt.atheism   \n",
              "1  From: mathew <mathew@mantis.co.uk>\\nSubject: R...  alt         alt.atheism   \n",
              "2  From: timmbake@mcl.ucsb.edu (Bake Timmons)\\nSu...  alt         alt.atheism   \n",
              "3  From: sandvik@newton.apple.com (Kent Sandvik)\\...  alt         alt.atheism   \n",
              "\n",
              "  article_id  \n",
              "0      51261  \n",
              "1      51240  \n",
              "2      53334  \n",
              "3      53057  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-27f72072-c0d4-489e-bfab-8011e5f0e60c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>tgt</th>\n",
              "      <th>true_label_original</th>\n",
              "      <th>article_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: I3150101@dbstu1.rz.tu-bs.de (Benedikt Ro...</td>\n",
              "      <td>alt</td>\n",
              "      <td>alt.atheism</td>\n",
              "      <td>51261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: mathew &lt;mathew@mantis.co.uk&gt;\\nSubject: R...</td>\n",
              "      <td>alt</td>\n",
              "      <td>alt.atheism</td>\n",
              "      <td>51240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From: timmbake@mcl.ucsb.edu (Bake Timmons)\\nSu...</td>\n",
              "      <td>alt</td>\n",
              "      <td>alt.atheism</td>\n",
              "      <td>53334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From: sandvik@newton.apple.com (Kent Sandvik)\\...</td>\n",
              "      <td>alt</td>\n",
              "      <td>alt.atheism</td>\n",
              "      <td>53057</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-27f72072-c0d4-489e-bfab-8011e5f0e60c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-27f72072-c0d4-489e-bfab-8011e5f0e60c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-27f72072-c0d4-489e-bfab-8011e5f0e60c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-04c7a04f-8001-4762-982f-44c0b3cfaee2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-04c7a04f-8001-4762-982f-44c0b3cfaee2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-04c7a04f-8001-4762-982f-44c0b3cfaee2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"From: mathew <mathew@mantis.co.uk>\\nSubject: Re: <Political Atheists?\\nOrganization: Mantis Consultants, Cambridge. UK.\\nX-Newsreader: rusnews v1.01\\nLines: 15\\n\\nkeith@cco.caltech.edu (Keith Allan Schneider) writes:\\n>mathew <mathew@mantis.co.uk> writes:\\n>>>Perhaps we shouldn't imprision people if we could watch them closely\\n>>>instead.  The cost would probably be similar, especially if we just\\n>>>implanted some sort of electronic device.\\n>>Why wait until they commit the crime?  Why not implant such devices in\\n>>potential criminals like Communists and atheists?\\n> \\n> Sorry, I don't follow your reasoning.  You are proposing to punish people\\n> *before* they commit a crime?  What justification do you have for this?\\n\\nLook up \\\"irony\\\", Keith.\\n\\n\\nmathew\\n\",\n          \"From: sandvik@newton.apple.com (Kent Sandvik)\\nSubject: Re: Nicknames\\nOrganization: Cookamunga Tourist Bureau\\nLines: 21\\n\\nIn article <1993Apr18.231914.143616@zeus.calpoly.edu>,\\njmunch@hertz.elee.calpoly.edu (John Munch) wrote:\\n> >Mathew \\\"FAQ\\\" can't remember his last name\\n> >Keith \\\"Lie Tally .sig\\\" Ryan\\n> >Kent \\\"Finn-tastic\\\" Sandvick\\n> >Cindy \\\"Popsicle Toes\\\" Kandolf\\n> >Jim \\\"Face .sig\\\" Tims\\n> >Simon \\\"Clip-that-theist\\\" Clippendale\\n> >Umar \\\"Reasonable\\\" Khan\\n> >Rob \\\"Argue with G-d\\\" Strom\\n> >Dave \\\"Buckminster\\\" Fuller\\n> >Maddi \\\"Never a useful post\\\" Hausmann\\n> \\n> Hey, what about an affectionate nickname for me?\\n\\nYou could take my wrongly spelled surname :-).\\n\\nCheers,\\nKent Sandvik\\n---\\nsandvik@newton.apple.com. ALink: KSAND -- Private activities on the net.\\n\",\n          \"From: I3150101@dbstu1.rz.tu-bs.de (Benedikt Rosenau)\\nSubject: Re: atheist?\\nOrganization: Technical University Braunschweig, Germany\\nLines: 38\\n\\nIn article <ePVk2B3w165w@mantis.co.uk>\\nTony Lezard <tony@mantis.co.uk> writes:\\n \\n(Deletion)\\n>> In other words, if there were gods, they would hardly make sense, and\\n>> it is possible to explain the phenomenon of religion without gods.\\n>>\\n>> The concept is useless, and I don't have to introduce new assumptions\\n>> in order to show that.\\n>\\n>Yes I fully agree with that, but is it \\\"I don't believe gods exist\\\", or\\n>\\\"I believe no gods exist\\\"? As MANDTBACKA@FINABO.ABO.FI (Mats Andtbacka)\\n>pointed out, it all hinges on what you take the word \\\"believe\\\" to mean.\\n>\\n \\nFor me, it is a \\\"I believe no gods exist\\\" and a \\\"I don't believe gods exist\\\".\\n \\nIn other words, I think that statements like gods are or somehow interfere\\nwith this world are false or meaningless. In Ontology, one can fairly\\nconclude that when \\\"A exist\\\" is meaningless A does not exist. Under the\\nPragmatic definition of truth, \\\"A exists\\\" is meaningless makes A exist\\neven logically false.\\n \\nA problem with such statements is that one can't disprove a subjective god\\nby definition, and there might be cases where a subjective god would even\\nmake sense. The trouble with most god definitions is that they include\\nsome form of objective existence with the consequence of the gods affecting\\nall. Believers derive from it a right to interfere with the life of others.\\n \\n \\n(Deletion)\\n>\\n>Should the FAQ be clarified to try to pin down this notion of \\\"belief\\\"?\\n>Can it?\\n>\\n \\nHonestly, I don't see the problem.\\n   Benedikt\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tgt\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"alt\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"true_label_original\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"alt.atheism\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"article_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"51240\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take 20% of the data\n",
        "\n",
        "sample_df, _ = train_test_split(df, train_size=.2, random_state=42, stratify=df['tgt'])\n",
        "orig_df = df.copy()  # ~18k\n",
        "data = sample_df.copy()  # ~4k\n",
        "\n",
        "print(data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkaBpjQZuACF",
        "outputId": "49caf28d-68e3-4912-bdc0-583f8c0ff58b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3769, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "ax,ay,bx,by = tts(x,y)\n",
        "a,_ = ttx(df)\n",
        "'''"
      ],
      "metadata": {
        "id": "yPS6dGPDvkWj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f9984da5-5ca3-4d57-dc87-8b9cad157e5e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nax,ay,bx,by = tts(x,y)\\na,_ = ttx(df)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data.tgt.value_counts().index\n",
        "data.tgt.value_counts().keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwpAER57w6Rg",
        "outputId": "d76bc0d6-c25d-4a4f-f9ef-62e102725d9d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['comp', 'rec', 'sci', 'talk', 'soc', 'misc', 'alt'], dtype='object', name='tgt')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categories = {\n",
        "'comp':0, 'rec':1, 'sci':2, 'talk':3, 'soc':4, 'misc':5, 'alt':6 }\n",
        "data.rename(columns={'tgt':'category_name'},inplace=True)\n",
        "data['category'] = data['category_name'].map(categories)\n",
        "print(data.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GTWE0RvxBL6",
        "outputId": "7ec4263c-7263-43e9-ebe6-c4bf0395881b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['text', 'category_name', 'true_label_original', 'article_id',\n",
            "       'category'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(data.head(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "O1GZJJZzx-5C",
        "outputId": "4172dbf2-caae-43be-b5aa-1c94df2e34d0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                   text category_name  \\\n",
              "6347  From: maynard@ramsey.cs.laurentian.ca (Roger M...           rec   \n",
              "\n",
              "     true_label_original article_id  category  \n",
              "6347    rec.sport.hockey      53696         1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-560f34e0-c7f9-42fe-81b5-7cf4118e2dc8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category_name</th>\n",
              "      <th>true_label_original</th>\n",
              "      <th>article_id</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6347</th>\n",
              "      <td>From: maynard@ramsey.cs.laurentian.ca (Roger M...</td>\n",
              "      <td>rec</td>\n",
              "      <td>rec.sport.hockey</td>\n",
              "      <td>53696</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-560f34e0-c7f9-42fe-81b5-7cf4118e2dc8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-560f34e0-c7f9-42fe-81b5-7cf4118e2dc8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-560f34e0-c7f9-42fe-81b5-7cf4118e2dc8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(data\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"From: maynard@ramsey.cs.laurentian.ca (Roger Maynard)\\nSubject: Re: Plus minus stat\\nOrganization: Dept. of Computer Science, Laurentian University, Sudbury, ON\\nLines: 130\\n\\nIn <VFq32B2w165w@sms.business.uwo.ca> j3david@sms.business.uwo.ca (James David) writes:\\n\\n>>If Gilmour was taken completely by surprise, as Gainey was, then\\n>>yeah, I would have to say that Doug wasn't playing\\n>>\\\"technically\\\" smart  hockey.  In any case, to claim as Greg did,\\n>>that Gainey *never* made  a technical mistake is absolutely\\n>>ludicrous.\\n> \\n>Later on, in your posting, you make reference to \\\"putting words\\n>into other people's mouths\\\"...I would suggest that your last\\n>paragraph can only be interpreted in one way...namely, that I,\\n>along with Greg, claim that Gainey never made a technical\\n>mistake.  If you actually read what I've written, you will find\\n>that I make no such claim...soooo, if logic serves me well,\\n>you're contradicting yourself.\\n\\nNonsense.  I quite clearly state that it was Greg that made the claim\\nthat Gainey never made an error.  And he made the claim. Read below.\\n\\nFrom rec.sport.hockey Thu Apr 15 21:22:49 1993\\nFrom: gballent@hudson.UVic.CA (Greg  Ballentine)\\nMessage-ID: <1993Apr15.160450.27799@sol.UVic.CA>\\n\\n[nonsense deleted]\\n\\nGainey is the best defensive forward ever.  I stand by that assessment.\\nHe was a very good player who belongs in the hall of fame.  Did you\\never watch him play? He never made a technical error.\\n\\n[more nonsense deleted]\\n\\n>>Good for you.  You'd only be displaying your ignorance of\\n>>course, but to each his own...\\n> \\n>Roger, I'm not sure here, but I think \\\"ignorance\\\" is really a\\n>function of \\\"a lack of knowledge\\\" and not \\\"formulating an\\n>opinion\\\"...but hey, if you need to take a cheap shot, then by all\\n>means go ahead...that's if it makes you feel better.\\n\\nTo knowledgeable observers of the game my meaning is obvious.  Your\\nhockey education is not my responsibility.\\n \\n>My word, such vehemence against poor ol' Bob Gainey.  Why does\\n>he bother you so much...he was an effective player for his style\\n>of play.\\n\\nHe was just another player.  To laud him as anything more I find\\nbothersome.  I hated the Habs.  I hated Lafleur until I realized\\nthat he was likely the most aesthetically pleasing player to ever \\nskate in my lifetime.  Why would anyone talk about Gainey?\\n  \\n>>go  around.  Who would you rather have as your \\\"checking\\\"\\n>>centre?  Doug Gilmour or Doug Jarvis?  For that matter I would\\n>>take either Gretzky or Mario as my \\\"checking\\\" centres.  Do you\\n>>think Gretzky could cover Bob Gainey?\\n\\n>I'm really sorry Roger, but you have lost me completely here. \\n>Why don't you ask me if I would rather have Jesus Christ,\\n>himself, in nets?\\n\\nDid he play hockey at a high level?  Was he any good?  If not, why\\nwould you bother to bring JC up?  I am talking about hockey players\\nhere.  If you can't follow the conversation don't follow up.  As I\\nsaid previously, it is not my responsibility to educate you.\\n\\n>Now, if you were to compare, say for example, Bob Gainey with Guy\\n>Carbonneau, you would have a balanced comparison.\\n\\nSure.  Two journeymen.  Big deal.  Neither one of them is worth\\ndiscussing.\\n\\n>I'm wrong AGAIN...hmmm, let's see...where was I wrong in the\\n\\n>>>I would take Fuhr and Sanderson off of the latter.\\n\\n>first place?  I'm only guessing here, Rog, but I have a feeling\\n>that you've setup a \\\"You're wrong again\\\" macro key on your\\n>machine.\\n\\nThat is an excellent idea and if I decide to waste any more time\\nresponding to any of your, or Greg's, postings then I will be sure\\nto implement that very macro.\\n \\n>I would suggest that your comment: \\\"And when the press runs out\\n>of things to say about  the stars on dynasties they start to hype\\n>the pluggers.  Grant Fuhr, Essa Tikkannen, Butch Goring, Bob\\n>Nystrom, Bob Gainey, Doug Jarvis, Derek Sanderson, Wayne Cashman,\\n>Bob Baun, Bob Pulford, Ralph Backstrom, Henri Richard, Dick\\n>Duff...and so on...\\\" demonstrates a blanket disregard for these\\n>individuals as contributors to the game...so yes, settle\\n>down...nobody has claimed that they are hockey gods.\\n\\nTarasov claimed that Gainey was a \\\"hockey god.\\\"  And Greg ate it up.\\nAnd that is what this thread is all about.  If you didn't know \\nthat then why are you responding?\\n\\nAnd as for \\\"blanket disregard for these individuals\\\", I can remember \\nLeaf teams, purely populated by such \\\"individuals\\\", winning four \\nStanley Cups.  Teams.  No one ran around telling us that George\\nArmstrong was the best hockey player in the world.\\n\\n>>>congenially, as always,\\n>>> \\n>>>jd\\n>>> \\n>>>--\\n>>>James David\\n>>>david@student.business.uwo.ca\\n> \\n>>You might consider developing your own style.  After all,\\n>>imitation is  the sincerest form of flattery and I am quite sure\\n>>that flattery is not  your intention.\\n> \\n>C'mon...it has a nice ring to it...and admit it, you had a good\\n>laugh.\\n\\nRight.  I had to get to the end of your posting before I realized you were \\na complete joke.\\n\\nIn the future, if you are going to respond to my postings I would appreciate\\nit if you could present a cogent argument supported by facts gleaned from a\\nversion of reality that most of the rest of us would recognize.\\n\\ncordially, as always, \\n\\nrm\\n\\n-- \\nRoger Maynard \\nmaynard@ramsey.cs.laurentian.ca \\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"rec\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"true_label_original\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"rec.sport.hockey\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"article_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"53696\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#download the glove embeddings from web"
      ],
      "metadata": {
        "id": "oTYMNThZMpB-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Download the ZIP file\n",
        "url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
        "zip_path = \"glove.6B.zip\"\n",
        "urllib.request.urlretrieve(url, zip_path)  # Downloads the file to zip_path\n",
        "\n",
        "# Extract only the desired file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extract('glove.6B.50d.txt', path='.')\n",
        "\n",
        "# (Optional) Remove the ZIP file to save space\n",
        "os.remove(zip_path)\n",
        "\n",
        "print(\"Downloaded and extracted glove.6B.50d.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEjiqfF4MfZX",
        "outputId": "3e3f14c3-8252-4b78-f818-894677c032ee"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded and extracted glove.6B.50d.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nTEg3hJt9FE",
        "outputId": "12d31bdc-f8f6-4bc6-a164-70d9c53f912c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['text', 'category_name', 'true_label_original', 'article_id',\n",
              "       'category'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a ownlibrary and create methods into it for resuse"
      ],
      "metadata": {
        "id": "HJ0Jbd5myYSd"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile utils.py\n",
        "# utility functions for text preprocessing\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "import string\n",
        "import numpy as np\n",
        "\n",
        "# create a function to lowercase, remove punctuations,tokenize , remove stopwords and lemmatization\n",
        "def preprocess_text(text):\n",
        "\n",
        "    # lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # remove punctuations\n",
        "    text = text.translate(str.maketrans('','',string.punctuation))\n",
        "\n",
        "    # tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    #leammatize\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "def get_word2vec_embeddings(tokens, model):\n",
        "    \"\"\"\n",
        "    Generate Word2Vec embeddings for a list of tokens.\"\"\"\n",
        "\n",
        "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
        "    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
        "\n",
        "def get_glove_embeddings(tokens, model): #add blk for glove\n",
        "    vectors = [model[word] for word in tokens if word in model]\n",
        "    return np.mean(vectors, axis=0) if vectors else np.zeros(100)\n",
        "\n",
        "def get_fasttext_embeddings(text, model): #add blk for fastext\n",
        "    return model.get_sentence_vector(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUKhuAX1yCK-",
        "outputId": "0405d7d9-2d4c-4e32-a495-78ac09aacb69"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kCmD9Bx09dj",
        "outputId": "0a177f07-ebf3-404c-b5a2-c3805ea7e6ff"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from utils import preprocess_text\n",
        "from utils import preprocess_text , get_word2vec_embeddings"
      ],
      "metadata": {
        "id": "n8SG3wd50bt_"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['claened_text'] = data['text'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "kGHj9Jeq0wDV"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(data.head(2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "IePUX8F80yxL",
        "outputId": "6606dae8-854f-4234-855c-0a59ccbe393f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                   text category_name  \\\n",
              "6347  From: maynard@ramsey.cs.laurentian.ca (Roger M...           rec   \n",
              "4879  From: James Leo Belliveau <jbc9+@andrew.cmu.ed...           rec   \n",
              "\n",
              "     true_label_original article_id  category  \\\n",
              "6347    rec.sport.hockey      53696         1   \n",
              "4879     rec.motorcycles     104667         1   \n",
              "\n",
              "                                           claened_text  \n",
              "6347  maynardramseycslaurentianca roger maynard subj...  \n",
              "4879  james leo belliveau jbc9andrewcmuedu subject f...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dfb0180b-bf88-4b29-bc32-e97fd6669b8c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category_name</th>\n",
              "      <th>true_label_original</th>\n",
              "      <th>article_id</th>\n",
              "      <th>category</th>\n",
              "      <th>claened_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6347</th>\n",
              "      <td>From: maynard@ramsey.cs.laurentian.ca (Roger M...</td>\n",
              "      <td>rec</td>\n",
              "      <td>rec.sport.hockey</td>\n",
              "      <td>53696</td>\n",
              "      <td>1</td>\n",
              "      <td>maynardramseycslaurentianca roger maynard subj...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4879</th>\n",
              "      <td>From: James Leo Belliveau &lt;jbc9+@andrew.cmu.ed...</td>\n",
              "      <td>rec</td>\n",
              "      <td>rec.motorcycles</td>\n",
              "      <td>104667</td>\n",
              "      <td>1</td>\n",
              "      <td>james leo belliveau jbc9andrewcmuedu subject f...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dfb0180b-bf88-4b29-bc32-e97fd6669b8c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dfb0180b-bf88-4b29-bc32-e97fd6669b8c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dfb0180b-bf88-4b29-bc32-e97fd6669b8c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c82f0e3e-f869-4ff6-af66-14d6287e9b63\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c82f0e3e-f869-4ff6-af66-14d6287e9b63')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c82f0e3e-f869-4ff6-af66-14d6287e9b63 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(data\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"From: James Leo Belliveau <jbc9+@andrew.cmu.edu>\\nSubject: First Bike??\\nOrganization: Freshman, Mechanical Engineering, Carnegie Mellon, Pittsburgh, PA\\nLines: 17\\nNNTP-Posting-Host: po2.andrew.cmu.edu\\n\\n Anyone, \\n\\n    I am a serious motorcycle enthusiast without a motorcycle, and to\\nput it bluntly, it sucks.  I really would like some advice on what would\\nbe a good starter bike for me.  I do know one thing however, I need to\\nmake my first bike a good one, because buying a second any time soon is\\nout of the question.  I am specifically interested in racing bikes, (CBR\\n600 F2, GSX-R 750).  I know that this may sound kind of crazy\\nconsidering that I've never had a bike before, but I am responsible, a\\nfast learner, and in love.  Please give me any advice that you think\\nwould help me in my search, including places to look or even specific\\nbikes that you want to sell me.\\n\\n    Thanks  :-)\\n\\n    Jamie Belliveau (jbc9@andrew.cmu.edu)  \\n\\n\",\n          \"From: maynard@ramsey.cs.laurentian.ca (Roger Maynard)\\nSubject: Re: Plus minus stat\\nOrganization: Dept. of Computer Science, Laurentian University, Sudbury, ON\\nLines: 130\\n\\nIn <VFq32B2w165w@sms.business.uwo.ca> j3david@sms.business.uwo.ca (James David) writes:\\n\\n>>If Gilmour was taken completely by surprise, as Gainey was, then\\n>>yeah, I would have to say that Doug wasn't playing\\n>>\\\"technically\\\" smart  hockey.  In any case, to claim as Greg did,\\n>>that Gainey *never* made  a technical mistake is absolutely\\n>>ludicrous.\\n> \\n>Later on, in your posting, you make reference to \\\"putting words\\n>into other people's mouths\\\"...I would suggest that your last\\n>paragraph can only be interpreted in one way...namely, that I,\\n>along with Greg, claim that Gainey never made a technical\\n>mistake.  If you actually read what I've written, you will find\\n>that I make no such claim...soooo, if logic serves me well,\\n>you're contradicting yourself.\\n\\nNonsense.  I quite clearly state that it was Greg that made the claim\\nthat Gainey never made an error.  And he made the claim. Read below.\\n\\nFrom rec.sport.hockey Thu Apr 15 21:22:49 1993\\nFrom: gballent@hudson.UVic.CA (Greg  Ballentine)\\nMessage-ID: <1993Apr15.160450.27799@sol.UVic.CA>\\n\\n[nonsense deleted]\\n\\nGainey is the best defensive forward ever.  I stand by that assessment.\\nHe was a very good player who belongs in the hall of fame.  Did you\\never watch him play? He never made a technical error.\\n\\n[more nonsense deleted]\\n\\n>>Good for you.  You'd only be displaying your ignorance of\\n>>course, but to each his own...\\n> \\n>Roger, I'm not sure here, but I think \\\"ignorance\\\" is really a\\n>function of \\\"a lack of knowledge\\\" and not \\\"formulating an\\n>opinion\\\"...but hey, if you need to take a cheap shot, then by all\\n>means go ahead...that's if it makes you feel better.\\n\\nTo knowledgeable observers of the game my meaning is obvious.  Your\\nhockey education is not my responsibility.\\n \\n>My word, such vehemence against poor ol' Bob Gainey.  Why does\\n>he bother you so much...he was an effective player for his style\\n>of play.\\n\\nHe was just another player.  To laud him as anything more I find\\nbothersome.  I hated the Habs.  I hated Lafleur until I realized\\nthat he was likely the most aesthetically pleasing player to ever \\nskate in my lifetime.  Why would anyone talk about Gainey?\\n  \\n>>go  around.  Who would you rather have as your \\\"checking\\\"\\n>>centre?  Doug Gilmour or Doug Jarvis?  For that matter I would\\n>>take either Gretzky or Mario as my \\\"checking\\\" centres.  Do you\\n>>think Gretzky could cover Bob Gainey?\\n\\n>I'm really sorry Roger, but you have lost me completely here. \\n>Why don't you ask me if I would rather have Jesus Christ,\\n>himself, in nets?\\n\\nDid he play hockey at a high level?  Was he any good?  If not, why\\nwould you bother to bring JC up?  I am talking about hockey players\\nhere.  If you can't follow the conversation don't follow up.  As I\\nsaid previously, it is not my responsibility to educate you.\\n\\n>Now, if you were to compare, say for example, Bob Gainey with Guy\\n>Carbonneau, you would have a balanced comparison.\\n\\nSure.  Two journeymen.  Big deal.  Neither one of them is worth\\ndiscussing.\\n\\n>I'm wrong AGAIN...hmmm, let's see...where was I wrong in the\\n\\n>>>I would take Fuhr and Sanderson off of the latter.\\n\\n>first place?  I'm only guessing here, Rog, but I have a feeling\\n>that you've setup a \\\"You're wrong again\\\" macro key on your\\n>machine.\\n\\nThat is an excellent idea and if I decide to waste any more time\\nresponding to any of your, or Greg's, postings then I will be sure\\nto implement that very macro.\\n \\n>I would suggest that your comment: \\\"And when the press runs out\\n>of things to say about  the stars on dynasties they start to hype\\n>the pluggers.  Grant Fuhr, Essa Tikkannen, Butch Goring, Bob\\n>Nystrom, Bob Gainey, Doug Jarvis, Derek Sanderson, Wayne Cashman,\\n>Bob Baun, Bob Pulford, Ralph Backstrom, Henri Richard, Dick\\n>Duff...and so on...\\\" demonstrates a blanket disregard for these\\n>individuals as contributors to the game...so yes, settle\\n>down...nobody has claimed that they are hockey gods.\\n\\nTarasov claimed that Gainey was a \\\"hockey god.\\\"  And Greg ate it up.\\nAnd that is what this thread is all about.  If you didn't know \\nthat then why are you responding?\\n\\nAnd as for \\\"blanket disregard for these individuals\\\", I can remember \\nLeaf teams, purely populated by such \\\"individuals\\\", winning four \\nStanley Cups.  Teams.  No one ran around telling us that George\\nArmstrong was the best hockey player in the world.\\n\\n>>>congenially, as always,\\n>>> \\n>>>jd\\n>>> \\n>>>--\\n>>>James David\\n>>>david@student.business.uwo.ca\\n> \\n>>You might consider developing your own style.  After all,\\n>>imitation is  the sincerest form of flattery and I am quite sure\\n>>that flattery is not  your intention.\\n> \\n>C'mon...it has a nice ring to it...and admit it, you had a good\\n>laugh.\\n\\nRight.  I had to get to the end of your posting before I realized you were \\na complete joke.\\n\\nIn the future, if you are going to respond to my postings I would appreciate\\nit if you could present a cogent argument supported by facts gleaned from a\\nversion of reality that most of the rest of us would recognize.\\n\\ncordially, as always, \\n\\nrm\\n\\n-- \\nRoger Maynard \\nmaynard@ramsey.cs.laurentian.ca \\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"rec\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"true_label_original\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"rec.motorcycles\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"article_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"104667\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"claened_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"james leo belliveau jbc9andrewcmuedu subject first bike organization freshman mechanical engineering carnegie mellon pittsburgh pa line 17 nntppostinghost po2andrewcmuedu anyone serious motorcycle enthusiast without motorcycle put bluntly suck really would like advice would good starter bike know one thing however need make first bike good one buying second time soon question specifically interested racing bike cbr 600 f2 gsxr 750 know may sound kind crazy considering ive never bike responsible fast learner love please give advice think would help search including place look even specific bike want sell thanks jamie belliveau jbc9andrewcmuedu\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data.rename(columns={'claened_text':'cleaned_text'},inplace=True)"
      ],
      "metadata": {
        "id": "xUkHa1GF55Ci"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save preprocessed data\n",
        "data.to_csv('preprocessed_data.csv',index=False)\n",
        "print('preprocessed data saved')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoLc3R2g2b9Q",
        "outputId": "b310654d-bf5e-4d54-dcf0-2696cf6677c5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preprocessed data saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to clear the modules and use it before recreation\n",
        "'''\n",
        "import sys\n",
        "del sys.modules[\"utils\"]\n",
        "'''\n",
        "\n",
        "import sys\n",
        "# Check if 'utils' module is already in the loaded modules\n",
        "if 'utils' in sys.modules:\n",
        "  del sys.modules['utils']"
      ],
      "metadata": {
        "id": "KNFvvji433SQ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test the function\n",
        "preprocess_text('abc!@##$%#$%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tnGINm2c39fd",
        "outputId": "1e4d0ae5-51a0-4930-92e5-5c3396042efc"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'abc'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create vectors - to convert text into numerics\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(data['claened_text'])\n",
        "\n",
        "X_tfidf.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pfhfVox4DhU",
        "outputId": "e863f3c2-230d-4656-dbe8-6ac550d48c4d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3769, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_tfidf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKAtuq2c6Jut",
        "outputId": "08e4e200-44ad-47b1-de2c-efc1321464b3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<3769x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 169907 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_tfidf[:1, :1000].toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CluO84-P6OvJ",
        "outputId": "d64da4a8-78fe-48ac-adc2-df27736cb6bb"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.04008352, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.04057648, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.03764108, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.04316724, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.04572175, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.04239858, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.07606968,\n",
              "        0.03594078, 0.        , 0.04210544, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.3658688 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.05263463, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.03524409, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.05168007,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.05168007, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.17100266, 0.        , 0.        ,\n",
              "        0.04998691, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.04585617, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.05367915, 0.10181466, 0.        ,\n",
              "        0.03270214, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.04691991, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.03751287, 0.        , 0.05340865, 0.        ,\n",
              "        0.        , 0.        , 0.05629154, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.07600297, 0.        , 0.        , 0.        , 0.0462695 ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.09669544, 0.        , 0.04399316, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.03823709, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.04917963, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.05514045, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.03965011, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.10036989, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.04135962, 0.05191112, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.03605196, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.04316724, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.10382223, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.04655387, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.05168007, 0.05008548,\n",
              "        0.03988441, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.08123713, 0.03458859, 0.        , 0.11598916, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.28691615, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.04306162, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.04131463, 0.        , 0.        , 0.        , 0.37480152,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.03748105, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.10996977, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.14852025, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.03327423, 0.09586464,\n",
              "        0.        , 0.04895673, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.04458007, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.02385919, 0.05214708, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.05275994,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.04599224,\n",
              "        0.        , 0.        , 0.        , 0.05700727, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.03624924, 0.        , 0.0464821 , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.04745355, 0.        ,\n",
              "        0.01111931, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.04895673, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.04316724, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.08451366, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.04239858, 0.        ,\n",
              "        0.        , 0.        , 0.03466227, 0.05483238, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.02990592,\n",
              "        0.        , 0.04539265, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.04633992, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.05314459,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.01151258, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.02796723, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.03854756, 0.        , 0.13521909, 0.28519152,\n",
              "        0.        , 0.05179499, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.17760285, 0.        ,\n",
              "        0.        , 0.04998691, 0.        , 0.05008548, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.07976882, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.07138927,\n",
              "        0.        , 0.        , 0.06443451, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.04641078, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.04234918, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.10936299,\n",
              "        0.        , 0.04801416, 0.        , 0.        , 0.        ,\n",
              "        0.05156633, 0.03171484, 0.        , 0.        , 0.        ,\n",
              "        0.23523831, 0.        , 0.03748105, 0.        , 0.        ,\n",
              "        0.        , 0.0348612 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.08690327, 0.        , 0.        , 0.03833962,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.05340865, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.04578875,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.05080121, 0.        , 0.04172626, 0.        , 0.0334275 ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.01108986, 0.10313265,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.14288686, 0.        , 0.04793232, 0.        ,\n",
              "        0.04753192, 0.04619954, 0.        , 0.        , 0.        ,\n",
              "        0.08821617, 0.16022595, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.02929703, 0.05268161,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.02646955, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.02154198,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.03726081, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.04809662, 0.05214708,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.07831765, 0.        , 0.        , 0.        , 0.03058426,\n",
              "        0.04932036, 0.        , 0.        , 0.01837808, 0.        ,\n",
              "        0.04979234, 0.12223738, 0.        , 0.        , 0.        ,\n",
              "        0.04008352, 0.        , 0.        , 0.        , 0.08174899]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2PR7bag5jpO",
        "outputId": "26fc8457-feb6-4823-a2fe-5103dad82dac"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tfidf_vectorizer.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Word2Vec\n",
        "tokenized_texts = [word_tokenize(text) for text in data['claened_text']]\n",
        "w2v_model = Word2Vec(sentences=tokenized_texts, vector_size=50, window=5, min_count=1, workers=4)\n",
        "X_w2v = np.array([get_word2vec_embeddings(text, w2v_model) for text in tokenized_texts])\n",
        "w2v_model.save('word2vec.model')\n"
      ],
      "metadata": {
        "id": "HL0AcotIsAfm"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from utils import preprocess_text , get_word2vec_embeddings,get_glove_embeddings, get_fasttext_embeddings\n",
        "# GloVe (assuming GloVe embeddings are downloaded)\n",
        "glove_model = KeyedVectors.load_word2vec_format('glove.6B.50d.txt', binary=False, no_header=True)\n",
        "X_glove = np.array([get_glove_embeddings(text, glove_model) for text in tokenized_texts])\n"
      ],
      "metadata": {
        "id": "9JfC7xWQNq2d"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('fasttext_input.txt', 'w', encoding='utf-8') as f:\n",
        "    for text in data['claened_text']:\n",
        "        f.write(text + '\\n')\n",
        "ft_model = fasttext.train_unsupervised('fasttext_input.txt', model='skipgram', dim=50)\n",
        "X_ft = np.array([get_fasttext_embeddings(\" \".join(tokens), ft_model) for tokens in tokenized_texts])\n",
        "ft_model.save_model('fasttext.model')"
      ],
      "metadata": {
        "id": "KCrMe5HiNtLS"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(tokenized_texts), tokenized_texts[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFI0RD-1WqX4",
        "outputId": "8e073a31-a094-4aef-f771-f0e5fd784ef6"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list,\n",
              " [['maynardramseycslaurentianca',\n",
              "   'roger',\n",
              "   'maynard',\n",
              "   'subject',\n",
              "   'plus',\n",
              "   'minus',\n",
              "   'stat',\n",
              "   'organization',\n",
              "   'dept',\n",
              "   'computer',\n",
              "   'science',\n",
              "   'laurentian',\n",
              "   'university',\n",
              "   'sudbury',\n",
              "   'line',\n",
              "   '130',\n",
              "   'vfq32b2w165wsmsbusinessuwoca',\n",
              "   'j3davidsmsbusinessuwoca',\n",
              "   'james',\n",
              "   'david',\n",
              "   'writes',\n",
              "   'gilmour',\n",
              "   'taken',\n",
              "   'completely',\n",
              "   'surprise',\n",
              "   'gainey',\n",
              "   'yeah',\n",
              "   'would',\n",
              "   'say',\n",
              "   'doug',\n",
              "   'wasnt',\n",
              "   'playing',\n",
              "   'technically',\n",
              "   'smart',\n",
              "   'hockey',\n",
              "   'case',\n",
              "   'claim',\n",
              "   'greg',\n",
              "   'gainey',\n",
              "   'never',\n",
              "   'made',\n",
              "   'technical',\n",
              "   'mistake',\n",
              "   'absolutely',\n",
              "   'ludicrous',\n",
              "   'later',\n",
              "   'posting',\n",
              "   'make',\n",
              "   'reference',\n",
              "   'putting',\n",
              "   'word',\n",
              "   'people',\n",
              "   'mouthsi',\n",
              "   'would',\n",
              "   'suggest',\n",
              "   'last',\n",
              "   'paragraph',\n",
              "   'interpreted',\n",
              "   'one',\n",
              "   'waynamely',\n",
              "   'along',\n",
              "   'greg',\n",
              "   'claim',\n",
              "   'gainey',\n",
              "   'never',\n",
              "   'made',\n",
              "   'technical',\n",
              "   'mistake',\n",
              "   'actually',\n",
              "   'read',\n",
              "   'ive',\n",
              "   'written',\n",
              "   'find',\n",
              "   'make',\n",
              "   'claimsoooo',\n",
              "   'logic',\n",
              "   'serf',\n",
              "   'well',\n",
              "   'youre',\n",
              "   'contradicting',\n",
              "   'nonsense',\n",
              "   'quite',\n",
              "   'clearly',\n",
              "   'state',\n",
              "   'greg',\n",
              "   'made',\n",
              "   'claim',\n",
              "   'gainey',\n",
              "   'never',\n",
              "   'made',\n",
              "   'error',\n",
              "   'made',\n",
              "   'claim',\n",
              "   'read',\n",
              "   'recsporthockey',\n",
              "   'thu',\n",
              "   'apr',\n",
              "   '15',\n",
              "   '212249',\n",
              "   '1993',\n",
              "   'gballenthudsonuvicca',\n",
              "   'greg',\n",
              "   'ballentine',\n",
              "   'messageid',\n",
              "   '1993apr1516045027799soluvicca',\n",
              "   'nonsense',\n",
              "   'deleted',\n",
              "   'gainey',\n",
              "   'best',\n",
              "   'defensive',\n",
              "   'forward',\n",
              "   'ever',\n",
              "   'stand',\n",
              "   'assessment',\n",
              "   'good',\n",
              "   'player',\n",
              "   'belongs',\n",
              "   'hall',\n",
              "   'fame',\n",
              "   'ever',\n",
              "   'watch',\n",
              "   'play',\n",
              "   'never',\n",
              "   'made',\n",
              "   'technical',\n",
              "   'error',\n",
              "   'nonsense',\n",
              "   'deleted',\n",
              "   'good',\n",
              "   'youd',\n",
              "   'displaying',\n",
              "   'ignorance',\n",
              "   'course',\n",
              "   'roger',\n",
              "   'im',\n",
              "   'sure',\n",
              "   'think',\n",
              "   'ignorance',\n",
              "   'really',\n",
              "   'function',\n",
              "   'lack',\n",
              "   'knowledge',\n",
              "   'formulating',\n",
              "   'opinionbut',\n",
              "   'hey',\n",
              "   'need',\n",
              "   'take',\n",
              "   'cheap',\n",
              "   'shot',\n",
              "   'mean',\n",
              "   'go',\n",
              "   'aheadthats',\n",
              "   'make',\n",
              "   'feel',\n",
              "   'better',\n",
              "   'knowledgeable',\n",
              "   'observer',\n",
              "   'game',\n",
              "   'meaning',\n",
              "   'obvious',\n",
              "   'hockey',\n",
              "   'education',\n",
              "   'responsibility',\n",
              "   'word',\n",
              "   'vehemence',\n",
              "   'poor',\n",
              "   'ol',\n",
              "   'bob',\n",
              "   'gainey',\n",
              "   'bother',\n",
              "   'muchhe',\n",
              "   'effective',\n",
              "   'player',\n",
              "   'style',\n",
              "   'play',\n",
              "   'another',\n",
              "   'player',\n",
              "   'laud',\n",
              "   'anything',\n",
              "   'find',\n",
              "   'bothersome',\n",
              "   'hated',\n",
              "   'habs',\n",
              "   'hated',\n",
              "   'lafleur',\n",
              "   'realized',\n",
              "   'likely',\n",
              "   'aesthetically',\n",
              "   'pleasing',\n",
              "   'player',\n",
              "   'ever',\n",
              "   'skate',\n",
              "   'lifetime',\n",
              "   'would',\n",
              "   'anyone',\n",
              "   'talk',\n",
              "   'gainey',\n",
              "   'go',\n",
              "   'around',\n",
              "   'would',\n",
              "   'rather',\n",
              "   'checking',\n",
              "   'centre',\n",
              "   'doug',\n",
              "   'gilmour',\n",
              "   'doug',\n",
              "   'jarvis',\n",
              "   'matter',\n",
              "   'would',\n",
              "   'take',\n",
              "   'either',\n",
              "   'gretzky',\n",
              "   'mario',\n",
              "   'checking',\n",
              "   'centre',\n",
              "   'think',\n",
              "   'gretzky',\n",
              "   'could',\n",
              "   'cover',\n",
              "   'bob',\n",
              "   'gainey',\n",
              "   'im',\n",
              "   'really',\n",
              "   'sorry',\n",
              "   'roger',\n",
              "   'lost',\n",
              "   'completely',\n",
              "   'dont',\n",
              "   'ask',\n",
              "   'would',\n",
              "   'rather',\n",
              "   'jesus',\n",
              "   'christ',\n",
              "   'net',\n",
              "   'play',\n",
              "   'hockey',\n",
              "   'high',\n",
              "   'level',\n",
              "   'good',\n",
              "   'would',\n",
              "   'bother',\n",
              "   'bring',\n",
              "   'jc',\n",
              "   'talking',\n",
              "   'hockey',\n",
              "   'player',\n",
              "   'cant',\n",
              "   'follow',\n",
              "   'conversation',\n",
              "   'dont',\n",
              "   'follow',\n",
              "   'said',\n",
              "   'previously',\n",
              "   'responsibility',\n",
              "   'educate',\n",
              "   'compare',\n",
              "   'say',\n",
              "   'example',\n",
              "   'bob',\n",
              "   'gainey',\n",
              "   'guy',\n",
              "   'carbonneau',\n",
              "   'would',\n",
              "   'balanced',\n",
              "   'comparison',\n",
              "   'sure',\n",
              "   'two',\n",
              "   'journeyman',\n",
              "   'big',\n",
              "   'deal',\n",
              "   'neither',\n",
              "   'one',\n",
              "   'worth',\n",
              "   'discussing',\n",
              "   'im',\n",
              "   'wrong',\n",
              "   'againhmmm',\n",
              "   'let',\n",
              "   'seewhere',\n",
              "   'wrong',\n",
              "   'would',\n",
              "   'take',\n",
              "   'fuhr',\n",
              "   'sanderson',\n",
              "   'latter',\n",
              "   'first',\n",
              "   'place',\n",
              "   'im',\n",
              "   'guessing',\n",
              "   'rog',\n",
              "   'feeling',\n",
              "   'youve',\n",
              "   'setup',\n",
              "   'youre',\n",
              "   'wrong',\n",
              "   'macro',\n",
              "   'key',\n",
              "   'machine',\n",
              "   'excellent',\n",
              "   'idea',\n",
              "   'decide',\n",
              "   'waste',\n",
              "   'time',\n",
              "   'responding',\n",
              "   'gregs',\n",
              "   'posting',\n",
              "   'sure',\n",
              "   'implement',\n",
              "   'macro',\n",
              "   'would',\n",
              "   'suggest',\n",
              "   'comment',\n",
              "   'press',\n",
              "   'run',\n",
              "   'thing',\n",
              "   'say',\n",
              "   'star',\n",
              "   'dynasty',\n",
              "   'start',\n",
              "   'hype',\n",
              "   'plugger',\n",
              "   'grant',\n",
              "   'fuhr',\n",
              "   'essa',\n",
              "   'tikkannen',\n",
              "   'butch',\n",
              "   'goring',\n",
              "   'bob',\n",
              "   'nystrom',\n",
              "   'bob',\n",
              "   'gainey',\n",
              "   'doug',\n",
              "   'jarvis',\n",
              "   'derek',\n",
              "   'sanderson',\n",
              "   'wayne',\n",
              "   'cashman',\n",
              "   'bob',\n",
              "   'baun',\n",
              "   'bob',\n",
              "   'pulford',\n",
              "   'ralph',\n",
              "   'backstrom',\n",
              "   'henri',\n",
              "   'richard',\n",
              "   'dick',\n",
              "   'duffand',\n",
              "   'demonstrates',\n",
              "   'blanket',\n",
              "   'disregard',\n",
              "   'individual',\n",
              "   'contributor',\n",
              "   'gameso',\n",
              "   'yes',\n",
              "   'settle',\n",
              "   'downnobody',\n",
              "   'claimed',\n",
              "   'hockey',\n",
              "   'god',\n",
              "   'tarasov',\n",
              "   'claimed',\n",
              "   'gainey',\n",
              "   'hockey',\n",
              "   'god',\n",
              "   'greg',\n",
              "   'ate',\n",
              "   'thread',\n",
              "   'didnt',\n",
              "   'know',\n",
              "   'responding',\n",
              "   'blanket',\n",
              "   'disregard',\n",
              "   'individual',\n",
              "   'remember',\n",
              "   'leaf',\n",
              "   'team',\n",
              "   'purely',\n",
              "   'populated',\n",
              "   'individual',\n",
              "   'winning',\n",
              "   'four',\n",
              "   'stanley',\n",
              "   'cup',\n",
              "   'team',\n",
              "   'one',\n",
              "   'ran',\n",
              "   'around',\n",
              "   'telling',\n",
              "   'u',\n",
              "   'george',\n",
              "   'armstrong',\n",
              "   'best',\n",
              "   'hockey',\n",
              "   'player',\n",
              "   'world',\n",
              "   'congenially',\n",
              "   'always',\n",
              "   'jd',\n",
              "   'james',\n",
              "   'david',\n",
              "   'davidstudentbusinessuwoca',\n",
              "   'might',\n",
              "   'consider',\n",
              "   'developing',\n",
              "   'style',\n",
              "   'imitation',\n",
              "   'sincerest',\n",
              "   'form',\n",
              "   'flattery',\n",
              "   'quite',\n",
              "   'sure',\n",
              "   'flattery',\n",
              "   'intention',\n",
              "   'cmonit',\n",
              "   'nice',\n",
              "   'ring',\n",
              "   'itand',\n",
              "   'admit',\n",
              "   'good',\n",
              "   'laugh',\n",
              "   'right',\n",
              "   'get',\n",
              "   'end',\n",
              "   'posting',\n",
              "   'realized',\n",
              "   'complete',\n",
              "   'joke',\n",
              "   'future',\n",
              "   'going',\n",
              "   'respond',\n",
              "   'posting',\n",
              "   'would',\n",
              "   'appreciate',\n",
              "   'could',\n",
              "   'present',\n",
              "   'cogent',\n",
              "   'argument',\n",
              "   'supported',\n",
              "   'fact',\n",
              "   'gleaned',\n",
              "   'version',\n",
              "   'reality',\n",
              "   'rest',\n",
              "   'u',\n",
              "   'would',\n",
              "   'recognize',\n",
              "   'cordially',\n",
              "   'always',\n",
              "   'rm',\n",
              "   'roger',\n",
              "   'maynard',\n",
              "   'maynardramseycslaurentianca'],\n",
              "  ['james',\n",
              "   'leo',\n",
              "   'belliveau',\n",
              "   'jbc9andrewcmuedu',\n",
              "   'subject',\n",
              "   'first',\n",
              "   'bike',\n",
              "   'organization',\n",
              "   'freshman',\n",
              "   'mechanical',\n",
              "   'engineering',\n",
              "   'carnegie',\n",
              "   'mellon',\n",
              "   'pittsburgh',\n",
              "   'pa',\n",
              "   'line',\n",
              "   '17',\n",
              "   'nntppostinghost',\n",
              "   'po2andrewcmuedu',\n",
              "   'anyone',\n",
              "   'serious',\n",
              "   'motorcycle',\n",
              "   'enthusiast',\n",
              "   'without',\n",
              "   'motorcycle',\n",
              "   'put',\n",
              "   'bluntly',\n",
              "   'suck',\n",
              "   'really',\n",
              "   'would',\n",
              "   'like',\n",
              "   'advice',\n",
              "   'would',\n",
              "   'good',\n",
              "   'starter',\n",
              "   'bike',\n",
              "   'know',\n",
              "   'one',\n",
              "   'thing',\n",
              "   'however',\n",
              "   'need',\n",
              "   'make',\n",
              "   'first',\n",
              "   'bike',\n",
              "   'good',\n",
              "   'one',\n",
              "   'buying',\n",
              "   'second',\n",
              "   'time',\n",
              "   'soon',\n",
              "   'question',\n",
              "   'specifically',\n",
              "   'interested',\n",
              "   'racing',\n",
              "   'bike',\n",
              "   'cbr',\n",
              "   '600',\n",
              "   'f2',\n",
              "   'gsxr',\n",
              "   '750',\n",
              "   'know',\n",
              "   'may',\n",
              "   'sound',\n",
              "   'kind',\n",
              "   'crazy',\n",
              "   'considering',\n",
              "   'ive',\n",
              "   'never',\n",
              "   'bike',\n",
              "   'responsible',\n",
              "   'fast',\n",
              "   'learner',\n",
              "   'love',\n",
              "   'please',\n",
              "   'give',\n",
              "   'advice',\n",
              "   'think',\n",
              "   'would',\n",
              "   'help',\n",
              "   'search',\n",
              "   'including',\n",
              "   'place',\n",
              "   'look',\n",
              "   'even',\n",
              "   'specific',\n",
              "   'bike',\n",
              "   'want',\n",
              "   'sell',\n",
              "   'thanks',\n",
              "   'jamie',\n",
              "   'belliveau',\n",
              "   'jbc9andrewcmuedu'],\n",
              "  ['tankutiastateedu',\n",
              "   'sabri',\n",
              "   'atan',\n",
              "   'subject',\n",
              "   'stretching',\n",
              "   'adriatic',\n",
              "   'sea',\n",
              "   'great',\n",
              "   'wall',\n",
              "   'china',\n",
              "   'replyto',\n",
              "   'tankutiastateedu',\n",
              "   'sabri',\n",
              "   'atan',\n",
              "   'organization',\n",
              "   'iowa',\n",
              "   'state',\n",
              "   'university',\n",
              "   'line',\n",
              "   '33',\n",
              "   'article',\n",
              "   '1993apr290250084586urartusdpaorg',\n",
              "   'dbdurartusdpaorg',\n",
              "   'david',\n",
              "   'davidian',\n",
              "   'writes',\n",
              "   'following',\n",
              "   'report',\n",
              "   'turkey',\n",
              "   'eye',\n",
              "   'regional',\n",
              "   'role',\n",
              "   'ankara',\n",
              "   'turkey',\n",
              "   'ap',\n",
              "   'april',\n",
              "   '27',\n",
              "   '1993',\n",
              "   'find',\n",
              "   'last',\n",
              "   'paragraph',\n",
              "   'turanist',\n",
              "   'although',\n",
              "   'premier',\n",
              "   'suleyman',\n",
              "   'demirel',\n",
              "   'criticized',\n",
              "   'ozals',\n",
              "   'often',\n",
              "   'turanist',\n",
              "   'brash',\n",
              "   'call',\n",
              "   'turkish',\n",
              "   'influence',\n",
              "   'also',\n",
              "   'spoken',\n",
              "   'turanist',\n",
              "   'swath',\n",
              "   'turkic',\n",
              "   'people',\n",
              "   'stretching',\n",
              "   'adriatic',\n",
              "   'turanist',\n",
              "   'sea',\n",
              "   'great',\n",
              "   'wall',\n",
              "   'china',\n",
              "   'demirel',\n",
              "   'think',\n",
              "   'fooling',\n",
              "   'seems',\n",
              "   'end',\n",
              "   'envisioned',\n",
              "   'panturkic',\n",
              "   'empire',\n",
              "   'balkan',\n",
              "   'caucasus',\n",
              "   'turkey',\n",
              "   'fascist',\n",
              "   'boast',\n",
              "   'preempted',\n",
              "   'would',\n",
              "   'suggest',\n",
              "   'turkey',\n",
              "   'let',\n",
              "   'world',\n",
              "   'feel',\n",
              "   'grey',\n",
              "   'wolf',\n",
              "   'teeth',\n",
              "   'attempt',\n",
              "   'stretch',\n",
              "   'adriatic',\n",
              "   'china',\n",
              "   'turkey',\n",
              "   'cried',\n",
              "   'wolf',\n",
              "   'much',\n",
              "   'mentioning',\n",
              "   'turkic',\n",
              "   'people',\n",
              "   'widespread',\n",
              "   'mean',\n",
              "   'desiring',\n",
              "   'turkish',\n",
              "   'empire',\n",
              "   'logical',\n",
              "   'thing',\n",
              "   'conclude',\n",
              "   'statement',\n",
              "   'like',\n",
              "   'say',\n",
              "   'turkey',\n",
              "   'may',\n",
              "   'economical',\n",
              "   'benefit',\n",
              "   'competitive',\n",
              "   'enough',\n",
              "   'course',\n",
              "   'freedom',\n",
              "   'extrapolating',\n",
              "   'wish',\n",
              "   'statement',\n",
              "   'one',\n",
              "   'question',\n",
              "   'context',\n",
              "   'ozal',\n",
              "   'use',\n",
              "   'word',\n",
              "   'quoting',\n",
              "   'give',\n",
              "   'whole',\n",
              "   'speech',\n",
              "   'tankut',\n",
              "   'atan',\n",
              "   'tankutiastateedu',\n",
              "   'achtung',\n",
              "   'baby'],\n",
              "  ['lourayseasgwuedu',\n",
              "   'michael',\n",
              "   'panayiotakis',\n",
              "   'subject',\n",
              "   'bootup',\n",
              "   'sometimes',\n",
              "   'fails',\n",
              "   'organization',\n",
              "   'george',\n",
              "   'washington',\n",
              "   'university',\n",
              "   'line',\n",
              "   '27',\n",
              "   'article',\n",
              "   'dbasson110mattekcsircoza',\n",
              "   'dbassonmattekcsircoza',\n",
              "   'dominique',\n",
              "   'basson',\n",
              "   'writes',\n",
              "   'do',\n",
              "   '5',\n",
              "   'never',\n",
              "   'used',\n",
              "   'area',\n",
              "   'e000',\n",
              "   'efff',\n",
              "   'well',\n",
              "   'others',\n",
              "   'card',\n",
              "   'use',\n",
              "   'lan',\n",
              "   'card',\n",
              "   'might',\n",
              "   'get',\n",
              "   'problem',\n",
              "   'use',\n",
              "   'xe000efff',\n",
              "   'emm386exe',\n",
              "   'line',\n",
              "   'configsys',\n",
              "   'run',\n",
              "   'memmaker',\n",
              "   'instruct',\n",
              "   'retain',\n",
              "   'inclusion',\n",
              "   'exclusion',\n",
              "   'speaking',\n",
              "   'comp',\n",
              "   'emmexcludee000efff',\n",
              "   'something',\n",
              "   'nature',\n",
              "   'systemini',\n",
              "   'file',\n",
              "   'system',\n",
              "   'file',\n",
              "   'window',\n",
              "   'wondering',\n",
              "   'line',\n",
              "   'window',\n",
              "   'startup',\n",
              "   'file',\n",
              "   'better',\n",
              "   'give',\n",
              "   'memory',\n",
              "   'do',\n",
              "   'apps',\n",
              "   'disable',\n",
              "   'run',\n",
              "   'window',\n",
              "   'actually',\n",
              "   'think',\n",
              "   'line',\n",
              "   'also',\n",
              "   'system1',\n",
              "   'file',\n",
              "   'peace',\n",
              "   'mickey',\n",
              "   'pe',\n",
              "   'michael',\n",
              "   'panayiotakis',\n",
              "   'lourayseasgwuedu',\n",
              "   'ace',\n",
              "   'uunetseasgwuedulouray',\n",
              "   'make',\n",
              "   'mswindows',\n",
              "   'grp',\n",
              "   'file',\n",
              "   'reflect',\n",
              "   'hd',\n",
              "   'directory',\n",
              "   'well',\n",
              "   'aint',\n",
              "   'always',\n",
              "   'right',\n",
              "   'ive',\n",
              "   'never',\n",
              "   'wronggd'],\n",
              "  ['kv07iastateedu',\n",
              "   'warren',\n",
              "   'vonroeschlaub',\n",
              "   'subject',\n",
              "   'albert',\n",
              "   'sabin',\n",
              "   'replyto',\n",
              "   'kv07iastateedu',\n",
              "   'warren',\n",
              "   'vonroeschlaub',\n",
              "   'organization',\n",
              "   'ministry',\n",
              "   'silly',\n",
              "   'walk',\n",
              "   'line',\n",
              "   '30',\n",
              "   'article',\n",
              "   '1993apr1522565717804ramboatlantadgcom',\n",
              "   'wpratlantadgcom',\n",
              "   'bill',\n",
              "   'rawlins',\n",
              "   'writes',\n",
              "   'since',\n",
              "   'referred',\n",
              "   'messiah',\n",
              "   'assume',\n",
              "   'referring',\n",
              "   'new',\n",
              "   'testament',\n",
              "   'please',\n",
              "   'detail',\n",
              "   'complaint',\n",
              "   'email',\n",
              "   'dont',\n",
              "   'want',\n",
              "   'post',\n",
              "   'firstcentury',\n",
              "   'greek',\n",
              "   'wellknown',\n",
              "   'wellunderstood',\n",
              "   'considered',\n",
              "   'josephus',\n",
              "   'jewish',\n",
              "   'historian',\n",
              "   'also',\n",
              "   'wrote',\n",
              "   'jesus',\n",
              "   'addition',\n",
              "   'four',\n",
              "   'gospel',\n",
              "   'account',\n",
              "   'much',\n",
              "   'harmony',\n",
              "   'bill',\n",
              "   'find',\n",
              "   'rather',\n",
              "   'remarkable',\n",
              "   'managed',\n",
              "   'zero',\n",
              "   'probably',\n",
              "   'weakest',\n",
              "   'evidence',\n",
              "   'probably',\n",
              "   'convincing',\n",
              "   'antichristian',\n",
              "   'literature',\n",
              "   'put',\n",
              "   'jewish',\n",
              "   'council',\n",
              "   'second',\n",
              "   'century',\n",
              "   'enormous',\n",
              "   'quantity',\n",
              "   'detailed',\n",
              "   'argument',\n",
              "   'christianity',\n",
              "   'many',\n",
              "   'argument',\n",
              "   'still',\n",
              "   'used',\n",
              "   'today',\n",
              "   'despite',\n",
              "   'volume',\n",
              "   'tract',\n",
              "   'attacking',\n",
              "   'christianity',\n",
              "   'one',\n",
              "   'denies',\n",
              "   'existance',\n",
              "   'jesus',\n",
              "   'activity',\n",
              "   'find',\n",
              "   'considerably',\n",
              "   'compelling',\n",
              "   'josephus',\n",
              "   'harmony',\n",
              "   'gospel',\n",
              "   'especially',\n",
              "   'considering',\n",
              "   'matthew',\n",
              "   'luke',\n",
              "   'probably',\n",
              "   'used',\n",
              "   'mark',\n",
              "   'source',\n",
              "   'l',\n",
              "   'warren',\n",
              "   'kurt',\n",
              "   'vonroeschlaub',\n",
              "   'kv07iastateedu',\n",
              "   'iowa',\n",
              "   'state',\n",
              "   'university',\n",
              "   'math',\n",
              "   'department',\n",
              "   '400',\n",
              "   'carver',\n",
              "   'hall',\n",
              "   'ames',\n",
              "   'ia',\n",
              "   '50011',\n",
              "   'j']])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to train claassification task\n",
        "\n",
        "def train_classifier(X,y,model_name,feature_type):\n",
        "\n",
        "  X_train, X_test, y_train,y_test = train_test_split(X,y,test_size=0.2, random_state=42,stratify=y)\n",
        "\n",
        "  #grid option\n",
        "  lr_params = {'C': [0.1,1,10]}\n",
        "  lr_grid = GridSearchCV(LogisticRegression(),lr_params, cv=2)\n",
        "  lr_grid.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "  print(f'Best logistic regression paarams: {feature_type}:',lr_grid.best_params_)\n",
        "  print(f'logistic regression accuracy: {feature_type}:',accuracy_score(y_test,lr_grid.predict(X_test)))\n",
        "\n",
        "  joblib.dump(lr_grid.best_estimator_, f'lr_model_{feature_type.lower()}.pkl')\n",
        "\n",
        "  ##########\n",
        "  # can add more algo and create models\n",
        "  # gbc_model_tfidf.pkl\n",
        "  # gbc_model_w2v.pkl\n",
        "\n",
        "  # lr_model_glove.pkl\n",
        "  # gbc_model_glove.pkl\n",
        "  #########\n",
        "\n",
        "  from sklearn.ensemble import GradientBoostingClassifier   #addfor gbc blk\n",
        "  gbc = GradientBoostingClassifier(random_state=42)\n",
        "  gbc_params = {'n_estimators':[50]}\n",
        "  gbc_grid = GridSearchCV(gbc,gbc_params, cv=2)\n",
        "  gbc_grid.fit(X_train,y_train)\n",
        "\n",
        "  print(f'Best GBC paarams: {feature_type}:',gbc_grid.best_params_)\n",
        "  print(f'GBC accuracy: {feature_type}:',accuracy_score(y_test,gbc_grid.predict(X_test)))\n",
        "\n",
        "  joblib.dump(gbc_grid.best_estimator_, f'gbc_model_{feature_type.lower()}.pkl')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Rq6Bdt2m6sUV"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature_types = ['tfidf'] # , 'word2vec']\n",
        "# X_features = {'tfidf': X_tfidf} #, 'word2vec': X_w2v}\n",
        "\n",
        "feature_types = ['tfidf' , 'word2vec', 'glove', 'fasttext']  #add glove,ft\n",
        "X_features = {'tfidf': X_tfidf, 'word2vec': X_w2v, 'glove':X_glove, 'fasttext':X_ft} #add glove,ft\n",
        "\n",
        "\n",
        "\n",
        "for feature_type in feature_types:\n",
        "  print(f'Training classification using {feature_type}')\n",
        "\n",
        "  train_classifier(X_features[feature_type], data['category'], 'classifier', feature_type)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TY8_j3C7Bjpb",
        "outputId": "22f9c810-f306-444e-c895-49238ff9027f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training classification using tfidf\n",
            "Best logistic regression paarams: tfidf: {'C': 10}\n",
            "logistic regression accuracy: tfidf: 0.7904509283819628\n",
            "Best GBC paarams: tfidf: {'n_estimators': 50}\n",
            "GBC accuracy: tfidf: 0.7347480106100795\n",
            "Training classification using word2vec\n",
            "Best logistic regression paarams: word2vec: {'C': 10}\n",
            "logistic regression accuracy: word2vec: 0.6153846153846154\n",
            "Best GBC paarams: word2vec: {'n_estimators': 50}\n",
            "GBC accuracy: word2vec: 0.6021220159151194\n",
            "Training classification using glove\n",
            "Best logistic regression paarams: glove: {'C': 10}\n",
            "logistic regression accuracy: glove: 0.7214854111405835\n",
            "Best GBC paarams: glove: {'n_estimators': 50}\n",
            "GBC accuracy: glove: 0.7108753315649867\n",
            "Training classification using fasttext\n",
            "Best logistic regression paarams: fasttext: {'C': 10}\n",
            "logistic regression accuracy: fasttext: 0.7904509283819628\n",
            "Best GBC paarams: fasttext: {'n_estimators': 50}\n",
            "GBC accuracy: fasttext: 0.7745358090185677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "user selection of the type of vectorization(tfidf/w2v/glove/fasttext/etc) should be passed\n",
        "lr_model_tfidf\n",
        "lr_model_w2v\n",
        "gbc_model_tfidf\n",
        "gbc_model_w2v.....\n",
        "'''"
      ],
      "metadata": {
        "id": "ChvVRjyMHpCu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "cc2285e2-9543-4e3c-8cd6-3b6af4bebc39"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nuser selection of the type of vectorization(tfidf/w2v/glove/fasttext/etc) should be passed\\nlr_model_tfidf\\nlr_model_w2v\\ngbc_model_tfidf\\ngbc_model_w2v.....\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_names = list(categories.keys())\n",
        "joblib.dump(target_names, 'target_names.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-8DwA4nELhH",
        "outputId": "45d15974-58e4-4521-ed80-2aa419e56528"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['target_names.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taitJeQXGa16",
        "outputId": "3e3651b1-f6dd-4cae-f420-3f42077a22c4"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['comp', 'rec', 'sci', 'talk', 'soc', 'misc', 'alt']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n3aegSCZ1KSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_input = \"indian won the cricket match\"\n",
        "\n",
        "cleaned_input  = preprocess_text(new_input)\n",
        "#tokenized_input = word_tokenize(cleaned_input)\n",
        "\n",
        "tfidf_vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
        "lr_model = joblib.load('lr_model_tfidf.pkl')\n",
        "tgt_names = joblib.load('target_names.pkl')\n",
        "\n",
        "X_input = tfidf_vectorizer.transform([cleaned_input])\n",
        "\n",
        "lr_pred = lr_model.predict(X_input)[0]\n",
        "print(lr_pred)\n",
        "\n",
        "print(f'Prediction: {tgt_names[lr_pred]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2fCHqXcCa6h",
        "outputId": "3901d9b7-97ef-46d5-d4a3-26142637827c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Prediction: comp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "#from utils import preprocess_text\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# remove common words like \"the,is,and,etc'\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# do lemmatization\n",
        "nltk.download('wordnet')\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "from gensim.models import Word2Vec #addfor w2v\n",
        "#from utils import preprocess_text , get_word2vec_embeddings #addfor w2v\n",
        "from utils import preprocess_text, get_word2vec_embeddings, get_glove_embeddings, get_fasttext_embeddings #add glov,ft\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity #addfor recom\n",
        "from textblob import TextBlob #addfor sentiment\n",
        "from gensim.models import KeyedVectors #add glove\n",
        "import fasttext\n",
        "\n",
        "@st.cache_resource\n",
        "def load_models():\n",
        "\n",
        "    tfidf_vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
        "    lr_model_tfidf = joblib.load('lr_model_tfidf.pkl')\n",
        "    tgt_names = joblib.load('target_names.pkl')\n",
        "\n",
        "    data = pd.read_csv('preprocessed_data.csv')\n",
        "\n",
        "    w2v_model = Word2Vec.load('word2vec.model') #addfor w2v\n",
        "    lr_model_word2vec = joblib.load('lr_model_word2vec.pkl') #addfor w2v\n",
        "\n",
        "    gbc_model_tfidf = joblib.load('gbc_model_tfidf.pkl') #addfor gbc\n",
        "    gbc_model_word2vec = joblib.load('gbc_model_word2vec.pkl') #addfor gbc\n",
        "\n",
        "    lr_model_glove = joblib.load('lr_model_glove.pkl') #add for glv ft blk\n",
        "    gbc_model_glove = joblib.load('gbc_model_glove.pkl')\n",
        "    lr_model_fasttext = joblib.load('lr_model_fasttext.pkl')\n",
        "    gbc_model_fasttext = joblib.load('gbc_model_fasttext.pkl')\n",
        "\n",
        "    glove_model = KeyedVectors.load_word2vec_format('glove.6B.50d.txt', binary=False, no_header=True)\n",
        "    ft_model = fasttext.load_model('fasttext.model')\n",
        "\n",
        "\n",
        "    X_tfidf = tfidf_vectorizer.transform(data['claened_text'])\n",
        "    tokenized_texts = [word_tokenize(text) for text in data['claened_text']]\n",
        "\n",
        "    X_w2v = np.array([get_word2vec_embeddings(text, w2v_model) for text in tokenized_texts]) #addfor w2v\n",
        "\n",
        "    X_glove = np.array([get_glove_embeddings(text, glove_model) for text in tokenized_texts]) #add blk glv, tf\n",
        "    X_ft = np.array([get_fasttext_embeddings(\" \".join(tokens), ft_model) for tokens in tokenized_texts])\n",
        "    X_features = {'tfidf': X_tfidf, 'word2vec': X_w2v, 'glove': X_glove, 'fasttext': X_ft}\n",
        "\n",
        "    #X_features = {'tfidf': X_tfidf}\n",
        "    #X_features = {'tfidf': X_tfidf, 'word2vec': X_w2v} #addfor w2v\n",
        "\n",
        "\n",
        "\n",
        "    return(tfidf_vectorizer, lr_model_tfidf, w2v_model, lr_model_word2vec, glove_model, ft_model,\n",
        "           lr_model_glove, gbc_model_glove, lr_model_fasttext, gbc_model_fasttext,\n",
        "           gbc_model_tfidf, gbc_model_word2vec, tgt_names, data, X_features) #addfor w2v, glv, ft\n",
        "\n",
        "\n",
        "tfidf_vectorizer, lr_model_tfidf, w2v_model, lr_model_word2vec, glove_model, ft_model, \\\n",
        "lr_model_glove, gbc_model_glove, lr_model_fasttext, gbc_model_fasttext, \\\n",
        "gbc_model_tfidf, gbc_model_word2vec, tgt_names, data, X_features = load_models() #addfor w2v, glv,ft\n",
        "\n",
        "\n",
        "\n",
        "st.title('Text App for Forum')\n",
        "\n",
        "\n",
        "#task = st.sidebar.selectbox('Select Task',[\"Classification\"]) #\"Recommendation\"\n",
        "#task = st.sidebar.selectbox('Select Task',[\"Classification\",\"Recommendation\"]) #addfor recom\n",
        "task = st.sidebar.selectbox('Select Task',[\"Classification\",\"Recommendation\",\"Sentiment Analysis\"]) #addfor sentiment\n",
        "\n",
        "#feature_type = st.sidebar.selectbox('Select Feature Type',[\"TFIDF\"])\n",
        "#feature_type = st.sidebar.selectbox(\"Select Feature Type\", [\"TFIDF\", \"Word2Vec\"]) #add w2v\n",
        "feature_type = st.sidebar.selectbox(\"Select Feature Type\", [\"TFIDF\", \"Word2Vec\", \"GloVe\", \"FastText\"]) #addd glv,ft\n",
        "\n",
        "user_input = st.text_area(\"enter text for analysis:\",height =150)\n",
        "\n",
        "if st.button(\"Analyze\"):\n",
        "  if user_input:\n",
        "      cleaned_input  = preprocess_text(user_input)\n",
        "      tokenized_input = word_tokenize(cleaned_input)#add w2v\n",
        "\n",
        "      if feature_type == \"TFIDF\":\n",
        "          X_input = tfidf_vectorizer.transform([cleaned_input])\n",
        "          lr_model = lr_model_tfidf\n",
        "          gbc_model = gbc_model_tfidf # add gbc\n",
        "      elif feature_type == \"Word2Vec\":  # add w2v blk\n",
        "            X_input = np.array([get_word2vec_embeddings(tokenized_input, w2v_model)])\n",
        "            lr_model = lr_model_word2vec\n",
        "            gbc_model = gbc_model_word2vec # add gbc\n",
        "      elif feature_type == \"GloVe\": #add glv blk\n",
        "            X_input = np.array([get_glove_embeddings(tokenized_input, glove_model)])\n",
        "            lr_model = lr_model_glove\n",
        "            gbc_model = gbc_model_glove\n",
        "      else:  # FastText #add ft blk\n",
        "            X_input = np.array([get_fasttext_embeddings(cleaned_input, ft_model)])\n",
        "            lr_model = lr_model_fasttext\n",
        "            gbc_model = gbc_model_fasttext\n",
        "      if task ==  \"Classification\":\n",
        "          lr_pred = lr_model.predict(X_input)[0]\n",
        "\n",
        "          print(lr_pred)\n",
        "          st.subheader('Results:')\n",
        "          st.write(f'Logistic Regfression Prediction: {tgt_names[lr_pred]}')\n",
        "          gbc_pred = gbc_model.predict(X_input)[0] #addfor gbc\n",
        "          st.write(f'GBC Prediction: {tgt_names[gbc_pred]}') #addfor gbc\n",
        "      elif task == \"Recommendation\": #addfor recom  blk\n",
        "          sim_scores = cosine_similarity(X_input, X_features[feature_type.lower()])\n",
        "          top_indices = sim_scores[0].argsort()[-5:][::-1]\n",
        "          st.subheader(\"Top 5 Similar Documents\")\n",
        "          for idx in top_indices:\n",
        "              st.write(f\"**Category**: {data['category_name'][idx]}\")\n",
        "              st.write(f\"**Text**: {data['text'][idx]}\") #[:200]}...\")\n",
        "              st.write(\"---\")\n",
        "      elif task == \"Sentiment Analysis\": #addfor sentiment block\n",
        "          sentiment = TextBlob(cleaned_input).sentiment.polarity\n",
        "          st.subheader(\"Sentiment Analysis Result\")\n",
        "          st.write(f\"Sentiment Polarity: {sentiment:.4f}\")\n",
        "          st.write(\"Positive\" if sentiment > 0 else \"Negative\" if sentiment < 0 else \"Neutral\")\n",
        "  else:\n",
        "    st.error('Please enter some text')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bdHiQzkHBIW",
        "outputId": "88549d61-f95b-4a94-f645-54c386d3c6bb"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 34.9.13.55"
      ],
      "metadata": {
        "id": "NSKJr9wrMUlo"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65MOJBDqV9T7",
        "outputId": "5f7ebc48-2123-4b60-b78c-0843f4717437"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.106.87.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_4x74niMIWm",
        "outputId": "17eef1db-ab3c-4eb8-bfd1-56bcca602c2c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.106.87.16:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K\u001b[1G\u001b[0JNeed to install the following packages:\n",
            "localtunnel@2.0.2\n",
            "Ok to proceed? (y) \u001b[20G\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aTF1k_gRMQRM"
      },
      "execution_count": 53,
      "outputs": []
    }
  ]
}