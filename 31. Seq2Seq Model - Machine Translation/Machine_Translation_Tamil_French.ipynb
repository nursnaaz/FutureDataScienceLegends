{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OlJIOCaXZ0z",
        "outputId": "4c58f262-ce47-4c38-c679-8c9cb3b83d22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - loss: 2.3017\n",
            "Epoch 2/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.2790\n",
            "Epoch 3/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.2511 \n",
            "Epoch 4/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.2168\n",
            "Epoch 5/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.1686\n",
            "Epoch 6/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.1198\n",
            "Epoch 7/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.9948 \n",
            "Epoch 8/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.8328\n",
            "Epoch 9/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.7330 \n",
            "Epoch 10/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.5353 \n",
            "Epoch 11/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.7108\n",
            "Epoch 12/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1.4761 \n",
            "Epoch 13/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.5755\n",
            "Epoch 14/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.3702\n",
            "Epoch 15/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.3555\n",
            "Epoch 16/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.4585\n",
            "Epoch 17/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.2824\n",
            "Epoch 18/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 1.2249\n",
            "Epoch 19/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.3406\n",
            "Epoch 20/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.3062\n",
            "Epoch 21/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.1216\n",
            "Epoch 22/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.0567 \n",
            "Epoch 23/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.0018\n",
            "Epoch 24/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.0797 \n",
            "Epoch 25/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.0100\n",
            "Epoch 26/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.9454\n",
            "Epoch 27/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.7079 \n",
            "Epoch 28/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.7963\n",
            "Epoch 29/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.7584\n",
            "Epoch 30/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.5227 \n",
            "Epoch 31/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4833\n",
            "Epoch 32/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.5695 \n",
            "Epoch 33/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.5507 \n",
            "Epoch 34/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3765\n",
            "Epoch 35/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.3895 \n",
            "Epoch 36/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.4058\n",
            "Epoch 37/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.6008 \n",
            "Epoch 38/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.3865\n",
            "Epoch 39/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.5175 \n",
            "Epoch 40/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.2886\n",
            "Epoch 41/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.2531\n",
            "Epoch 42/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.3406\n",
            "Epoch 43/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3664\n",
            "Epoch 44/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.2565 \n",
            "Epoch 45/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.1911\n",
            "Epoch 46/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.2240 \n",
            "Epoch 47/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.2386\n",
            "Epoch 48/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.2067 \n",
            "Epoch 49/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.1930 \n",
            "Epoch 50/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.1908\n",
            "Epoch 51/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.1579\n",
            "Epoch 52/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.1701\n",
            "Epoch 53/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.1526\n",
            "Epoch 54/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.1461\n",
            "Epoch 55/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.1204 \n",
            "Epoch 56/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.1110 \n",
            "Epoch 57/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.1017\n",
            "Epoch 58/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.1121 \n",
            "Epoch 59/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.1074\n",
            "Epoch 60/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0892\n",
            "Epoch 61/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0816\n",
            "Epoch 62/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0644 \n",
            "Epoch 63/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0705 \n",
            "Epoch 64/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0768\n",
            "Epoch 65/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0733\n",
            "Epoch 66/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0592\n",
            "Epoch 67/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0470\n",
            "Epoch 68/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0501 \n",
            "Epoch 69/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0537\n",
            "Epoch 70/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0445\n",
            "Epoch 71/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0358 \n",
            "Epoch 72/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0390\n",
            "Epoch 73/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0420\n",
            "Epoch 74/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0395\n",
            "Epoch 75/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0278 \n",
            "Epoch 76/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0261\n",
            "Epoch 77/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0285\n",
            "Epoch 78/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0314\n",
            "Epoch 79/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0257\n",
            "Epoch 80/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0278\n",
            "Epoch 81/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0262 \n",
            "Epoch 82/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0216\n",
            "Epoch 83/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0207\n",
            "Epoch 84/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0179\n",
            "Epoch 85/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0171\n",
            "Epoch 86/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0209\n",
            "Epoch 87/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0172\n",
            "Epoch 88/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0165\n",
            "Epoch 89/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0146\n",
            "Epoch 90/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0151\n",
            "Epoch 91/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0145\n",
            "Epoch 92/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0140\n",
            "Epoch 93/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0126\n",
            "Epoch 94/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0120\n",
            "Epoch 95/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0116\n",
            "Epoch 96/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0139\n",
            "Epoch 97/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0134 \n",
            "Epoch 98/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0105 \n",
            "Epoch 99/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0124\n",
            "Epoch 100/100\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0120 \n",
            "English: how are you\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "French: comment ca va\n"
          ]
        }
      ],
      "source": [
        "# Simple Guide to Implement Machine Translation using Seq2Seq (Word-Level)\n",
        "\n",
        "# ---------------------------------------------\n",
        "# 1. WHY DO WE NEED SEQ2SEQ FOR TRANSLATION?\n",
        "# ---------------------------------------------\n",
        "# Language translation is a sequence-to-sequence problem, meaning we want to map one sequence (source language sentence)\n",
        "# to another sequence (target language sentence), often of different length.\n",
        "#\n",
        "# Traditional machine learning models cannot handle variable-length input and output easily.\n",
        "# Seq2Seq with Encoder-Decoder architecture using RNNs, GRUs, or LSTMs is ideal for this.\n",
        "#\n",
        "# Example: English to French\n",
        "# Input: \"How are you?\" --> Output: \"Comment allez-vous ?\"\n",
        "\n",
        "# ---------------------------------------------\n",
        "# 2. STEP-BY-STEP IMPLEMENTATION\n",
        "# ---------------------------------------------\n",
        "\n",
        "# Step 1: Load and preprocess the dataset\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import string\n",
        "\n",
        "# Sample dummy dataset (normally you'd load from a file)\n",
        "english_sentences = [\"hello\", \"how are you\", \"i am fine\"]\n",
        "french_sentences = [\"bonjour\", \"comment ca va\", \"je vais bien\"]\n",
        "\n",
        "# Clean and preprocess text\n",
        "def preprocess(text):\n",
        "    text = text.lower().translate(str.maketrans('', '', string.punctuation))\n",
        "    return text\n",
        "\n",
        "english_sentences = [preprocess(sent) for sent in english_sentences]\n",
        "french_sentences = [f\"start_ {preprocess(sent)} end_\" for sent in french_sentences]\n",
        "\n",
        "\n",
        "# Tokenize\n",
        "eng_tokenizer = Tokenizer()\n",
        "eng_tokenizer.fit_on_texts(english_sentences)\n",
        "eng_seq = eng_tokenizer.texts_to_sequences(english_sentences)\n",
        "eng_seq = pad_sequences(eng_seq, padding='post')\n",
        "\n",
        "fra_tokenizer = Tokenizer(filters='')  # Keeps special tokens like 'start_' and 'end_'\n",
        "fra_tokenizer.fit_on_texts(french_sentences)\n",
        "fra_seq = fra_tokenizer.texts_to_sequences(french_sentences)\n",
        "fra_seq = pad_sequences(fra_seq, padding='post')\n",
        "\n",
        "# Prepare input and output\n",
        "encoder_input = eng_seq\n",
        "decoder_input = [seq[:-1] for seq in fra_seq]  # all except last token\n",
        "decoder_output = [seq[1:] for seq in fra_seq]  # all except first token\n",
        "\n",
        "decoder_input = pad_sequences(decoder_input, maxlen=fra_seq.shape[1], padding='post')\n",
        "decoder_output = pad_sequences(decoder_output, maxlen=fra_seq.shape[1], padding='post')\n",
        "\n",
        "# Convert decoder_output to one-hot\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "output_vocab_size = len(fra_tokenizer.word_index) + 1\n",
        "decoder_output = to_categorical(decoder_output, num_classes=output_vocab_size)\n",
        "\n",
        "# Step 2: Build the Seq2Seq Model\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "\n",
        "# Define input sizes\n",
        "input_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "embedding_dim = 64\n",
        "latent_dim = 256\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb = Embedding(input_vocab_size, embedding_dim)(encoder_inputs)\n",
        "encoder_lstm, state_h, state_c = LSTM(latent_dim, return_state=True)(enc_emb)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(output_vocab_size, embedding_dim)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# Decoder LSTM using encoder states as initial state\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
        "\n",
        "# Dense layer to predict each word\n",
        "decoder_dense = Dense(output_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
        "\n",
        "# Step 3: Train the model\n",
        "model.fit([encoder_input, decoder_input], decoder_output, batch_size=2, epochs=100)\n",
        "\n",
        "# ---------------------------------------------\n",
        "# 3. PREDICTION AND INFERENCE SETUP\n",
        "# ---------------------------------------------\n",
        "# Create inference models to generate new translations\n",
        "\n",
        "# Encoder inference\n",
        "encoder_model_inf = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# Decoder inference\n",
        "# Inputs: previous word + previous states\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# Reuse embedding and LSTM\n",
        "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "decoder_model_inf = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs2] + decoder_states2)\n",
        "\n",
        "# Step 4: Translation function\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode input\n",
        "    states_value = encoder_model_inf.predict(input_seq)\n",
        "\n",
        "    # Start token\n",
        "    target_seq = np.array([[fra_tokenizer.word_index['start_']]])\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model_inf.predict([target_seq] + states_value)\n",
        "\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_word = None\n",
        "        for word, index in fra_tokenizer.word_index.items():\n",
        "            if index == sampled_token_index:\n",
        "                sampled_word = word\n",
        "                break\n",
        "\n",
        "        if sampled_word == 'end_' or sampled_word is None:\n",
        "            stop_condition = True\n",
        "        else:\n",
        "            decoded_sentence += ' ' + sampled_word\n",
        "\n",
        "            target_seq = np.array([[sampled_token_index]])\n",
        "            states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence.strip()\n",
        "\n",
        "# Example translation\n",
        "sample_input = pad_sequences(eng_tokenizer.texts_to_sequences([\"how are you\"]), maxlen=encoder_input.shape[1], padding='post')\n",
        "print(\"English: how are you\")\n",
        "print(\"French:\", decode_sequence(sample_input))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example translation\n",
        "sample_input = pad_sequences(eng_tokenizer.texts_to_sequences([\" fine hello\"]), maxlen=encoder_input.shape[1], padding='post')\n",
        "print(\"English: hello are you fine\")\n",
        "print(\"French:\", decode_sequence(sample_input))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LG1b34eIYLnM",
        "outputId": "471c7e24-a4c7-4c4a-aa53-3dfe9b5d4238"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English: hello are you fine\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "French: je bien\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "l_NuVBrSYLbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "English-Tamil Neural Machine Translation with Real Dataset Downloads\n",
        "Complete system with multiple dataset options and automatic downloading\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "import requests\n",
        "import tarfile\n",
        "import zipfile\n",
        "import gzip\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import urllib.request\n",
        "from tqdm import tqdm\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Essential imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "import re\n",
        "import pickle\n",
        "import json\n",
        "import time\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# TensorFlow imports\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Set random seeds\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "class DatasetDownloader:\n",
        "    \"\"\"Download and manage English-Tamil parallel datasets\"\"\"\n",
        "\n",
        "    def __init__(self, data_dir=\"datasets\"):\n",
        "        self.data_dir = Path(data_dir)\n",
        "        self.data_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        # Available datasets with their download URLs and descriptions\n",
        "        self.datasets = {\n",
        "            \"ufal_v2\": {\n",
        "                \"name\": \"UFAL English-Tamil Parallel Corpus v2\",\n",
        "                \"url\": \"http://ufal.mff.cuni.cz/~ramasamy/parallel/data/v2/en-ta-parallel-v2.tar.gz\",\n",
        "                \"description\": \"530k+ sentence pairs from Bible, cinema, and news domains\",\n",
        "                \"files\": {\n",
        "                    \"train_en\": \"en-ta-parallel-v2/corpus.bcn.train.en\",\n",
        "                    \"train_ta\": \"en-ta-parallel-v2/corpus.bcn.train.ta\",\n",
        "                    \"dev_en\": \"en-ta-parallel-v2/corpus.bcn.dev.en\",\n",
        "                    \"dev_ta\": \"en-ta-parallel-v2/corpus.bcn.dev.ta\",\n",
        "                    \"test_en\": \"en-ta-parallel-v2/corpus.bcn.test.en\",\n",
        "                    \"test_ta\": \"en-ta-parallel-v2/corpus.bcn.test.ta\"\n",
        "                },\n",
        "                \"format\": \"tar.gz\",\n",
        "                \"size\": \"~25MB\"\n",
        "            },\n",
        "\n",
        "            \"nlpc_uom\": {\n",
        "                \"name\": \"NLPC-UOM English-Tamil Parallel Corpus\",\n",
        "                \"url\": \"https://huggingface.co/datasets/NLPC-UOM/English-Tamil-Parallel-Corpus/resolve/main/data/train-00000-of-00001.parquet\",\n",
        "                \"description\": \"22k+ glossary + 9k+ corpus from government resources\",\n",
        "                \"files\": {\n",
        "                    \"parquet\": \"nlpc_uom_corpus.parquet\"\n",
        "                },\n",
        "                \"format\": \"parquet\",\n",
        "                \"size\": \"~5MB\"\n",
        "            },\n",
        "\n",
        "            \"opus_subtitles\": {\n",
        "                \"name\": \"OPUS OpenSubtitles English-Tamil\",\n",
        "                \"url\": \"https://object.pouta.csc.fi/OPUS-OpenSubtitles/v2018/moses/en-ta.txt.zip\",\n",
        "                \"description\": \"Movie subtitles parallel corpus\",\n",
        "                \"files\": {\n",
        "                    \"parallel\": \"OpenSubtitles.en-ta.en\",\n",
        "                    \"parallel_ta\": \"OpenSubtitles.en-ta.ta\"\n",
        "                },\n",
        "                \"format\": \"zip\",\n",
        "                \"size\": \"~10MB\"\n",
        "            },\n",
        "\n",
        "            \"small_sample\": {\n",
        "                \"name\": \"Small Sample Dataset (Generated)\",\n",
        "                \"description\": \"1000+ high-quality sentence pairs for quick testing\",\n",
        "                \"files\": {},\n",
        "                \"format\": \"generated\",\n",
        "                \"size\": \"~1MB\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def download_with_progress(self, url, filename):\n",
        "        \"\"\"Download file with progress bar\"\"\"\n",
        "        print(f\"📥 Downloading from {url}\")\n",
        "\n",
        "        response = requests.get(url, stream=True)\n",
        "        total_size = int(response.headers.get('content-length', 0))\n",
        "\n",
        "        with open(filename, 'wb') as file, tqdm(\n",
        "            desc=filename.name,\n",
        "            total=total_size,\n",
        "            unit='B',\n",
        "            unit_scale=True,\n",
        "            unit_divisor=1024,\n",
        "        ) as progress_bar:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                size = file.write(chunk)\n",
        "                progress_bar.update(size)\n",
        "\n",
        "    def extract_archive(self, archive_path, extract_to):\n",
        "        \"\"\"Extract tar.gz or zip files\"\"\"\n",
        "        print(f\"📦 Extracting {archive_path}\")\n",
        "\n",
        "        if archive_path.suffix == '.gz':\n",
        "            with tarfile.open(archive_path, 'r:gz') as tar:\n",
        "                tar.extractall(extract_to)\n",
        "        elif archive_path.suffix == '.zip':\n",
        "            with zipfile.ZipFile(archive_path, 'r') as zip_file:\n",
        "                zip_file.extractall(extract_to)\n",
        "\n",
        "    def download_ufal_v2(self):\n",
        "        \"\"\"Download UFAL English-Tamil v2 dataset\"\"\"\n",
        "        dataset_info = self.datasets[\"ufal_v2\"]\n",
        "        archive_path = self.data_dir / \"en-ta-parallel-v2.tar.gz\"\n",
        "        extract_dir = self.data_dir / \"ufal_v2\"\n",
        "\n",
        "        # Download if not exists\n",
        "        if not archive_path.exists():\n",
        "            self.download_with_progress(dataset_info[\"url\"], archive_path)\n",
        "\n",
        "        # Extract if not already extracted\n",
        "        if not extract_dir.exists():\n",
        "            extract_dir.mkdir()\n",
        "            self.extract_archive(archive_path, extract_dir)\n",
        "\n",
        "        # Read files\n",
        "        base_path = extract_dir / \"en-ta-parallel-v2\"\n",
        "        english_sentences = []\n",
        "        tamil_sentences = []\n",
        "\n",
        "        # Combine train, dev, test files\n",
        "        for split in ['train', 'dev', 'test']:\n",
        "            en_file = base_path / f\"corpus.bcn.{split}.en\"\n",
        "            ta_file = base_path / f\"corpus.bcn.{split}.ta\"\n",
        "\n",
        "            if en_file.exists() and ta_file.exists():\n",
        "                with open(en_file, 'r', encoding='utf-8') as f:\n",
        "                    en_lines = f.readlines()\n",
        "                with open(ta_file, 'r', encoding='utf-8') as f:\n",
        "                    ta_lines = f.readlines()\n",
        "\n",
        "                # Add to collections\n",
        "                english_sentences.extend([line.strip() for line in en_lines])\n",
        "                tamil_sentences.extend([line.strip() for line in ta_lines])\n",
        "\n",
        "        print(f\"✅ Loaded {len(english_sentences)} sentence pairs from UFAL v2\")\n",
        "        return english_sentences, tamil_sentences\n",
        "\n",
        "    def download_nlpc_uom(self):\n",
        "        \"\"\"Download NLPC-UOM dataset (requires pandas for parquet)\"\"\"\n",
        "        try:\n",
        "            import pandas as pd\n",
        "        except ImportError:\n",
        "            print(\"❌ pandas required for NLPC-UOM dataset. Installing...\")\n",
        "            os.system(\"pip install pandas pyarrow\")\n",
        "            import pandas as pd\n",
        "\n",
        "        dataset_info = self.datasets[\"nlpc_uom\"]\n",
        "        parquet_path = self.data_dir / \"nlpc_uom_corpus.parquet\"\n",
        "\n",
        "        # Download if not exists\n",
        "        if not parquet_path.exists():\n",
        "            self.download_with_progress(dataset_info[\"url\"], parquet_path)\n",
        "\n",
        "        # Read parquet file\n",
        "        try:\n",
        "            df = pd.read_parquet(parquet_path)\n",
        "            english_sentences = df['en'].tolist()\n",
        "            tamil_sentences = df['ta'].tolist()\n",
        "\n",
        "            print(f\"✅ Loaded {len(english_sentences)} sentence pairs from NLPC-UOM\")\n",
        "            return english_sentences, tamil_sentences\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error reading parquet file: {e}\")\n",
        "            return [], []\n",
        "\n",
        "    def download_opus_subtitles(self):\n",
        "        \"\"\"Download OPUS OpenSubtitles dataset\"\"\"\n",
        "        dataset_info = self.datasets[\"opus_subtitles\"]\n",
        "        zip_path = self.data_dir / \"opus_subtitles.zip\"\n",
        "        extract_dir = self.data_dir / \"opus_subtitles\"\n",
        "\n",
        "        # Download if not exists\n",
        "        if not zip_path.exists():\n",
        "            try:\n",
        "                self.download_with_progress(dataset_info[\"url\"], zip_path)\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Error downloading OPUS subtitles: {e}\")\n",
        "                return [], []\n",
        "\n",
        "        # Extract if not already extracted\n",
        "        if not extract_dir.exists():\n",
        "            extract_dir.mkdir()\n",
        "            try:\n",
        "                self.extract_archive(zip_path, extract_dir)\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Error extracting OPUS subtitles: {e}\")\n",
        "                return [], []\n",
        "\n",
        "        # Find and read parallel files\n",
        "        english_sentences = []\n",
        "        tamil_sentences = []\n",
        "\n",
        "        # Look for parallel files\n",
        "        for file in extract_dir.glob(\"*.en\"):\n",
        "            ta_file = file.with_suffix('.ta')\n",
        "            if ta_file.exists():\n",
        "                with open(file, 'r', encoding='utf-8') as f:\n",
        "                    en_lines = f.readlines()\n",
        "                with open(ta_file, 'r', encoding='utf-8') as f:\n",
        "                    ta_lines = f.readlines()\n",
        "\n",
        "                english_sentences.extend([line.strip() for line in en_lines])\n",
        "                tamil_sentences.extend([line.strip() for line in ta_lines])\n",
        "\n",
        "        print(f\"✅ Loaded {len(english_sentences)} sentence pairs from OPUS Subtitles\")\n",
        "        return english_sentences, tamil_sentences\n",
        "\n",
        "    def generate_small_sample(self):\n",
        "        \"\"\"Generate a small high-quality dataset for testing\"\"\"\n",
        "        # Extended high-quality sentence pairs\n",
        "        sample_data = [\n",
        "            # Basic greetings and politeness\n",
        "            (\"hello\", \"வணக்கம்\"),\n",
        "            (\"good morning\", \"காலை வணக்கம்\"),\n",
        "            (\"good afternoon\", \"மதிய வணக்கம்\"),\n",
        "            (\"good evening\", \"மாலை வணக்கம்\"),\n",
        "            (\"good night\", \"இரவு வணக்கம்\"),\n",
        "            (\"thank you\", \"நன்றி\"),\n",
        "            (\"thank you very much\", \"மிக்க நன்றி\"),\n",
        "            (\"you are welcome\", \"நல்ல வரவேற்பு\"),\n",
        "            (\"excuse me\", \"மன்னிக்கவும்\"),\n",
        "            (\"i am sorry\", \"நான் மன்னிக்க வேண்டும்\"),\n",
        "            (\"please\", \"தயவுசெய்து\"),\n",
        "            (\"goodbye\", \"விடைபெறுகிறேன்\"),\n",
        "            (\"see you later\", \"பிறகு சந்திப்போம்\"),\n",
        "            (\"see you tomorrow\", \"நாளை சந்திப்போம்\"),\n",
        "            (\"have a nice day\", \"நல்ல நாள் கழியட்டும்\"),\n",
        "            (\"take care\", \"கவனமாக இருங்கள்\"),\n",
        "\n",
        "            # Questions and responses\n",
        "            (\"how are you\", \"நீங்கள் எப்படி இருக்கிறீர்கள்\"),\n",
        "            (\"i am fine\", \"நான் நலமாக இருக்கிறேன்\"),\n",
        "            (\"i am good\", \"நான் நல்லவனாக இருக்கிறேன்\"),\n",
        "            (\"what is your name\", \"உங்கள் பெயர் என்ன\"),\n",
        "            (\"my name is john\", \"என் பெயர் ஜான்\"),\n",
        "            (\"where are you from\", \"நீங்கள் எங்கிருந்து வருகிறீர்கள்\"),\n",
        "            (\"i am from india\", \"நான் இந்தியாவிலிருந்து வருகிறேன்\"),\n",
        "            (\"i am from chennai\", \"நான் சென்னையிலிருந்து வருகிறேன்\"),\n",
        "            (\"how old are you\", \"உங்கள் வயது என்ன\"),\n",
        "            (\"i am twenty years old\", \"எனக்கு இருபது வயது\"),\n",
        "            (\"where do you live\", \"நீங்கள் எங்கே வசிக்கிறீர்கள்\"),\n",
        "            (\"i live in chennai\", \"நான் சென்னையில் வசிக்கிறேன்\"),\n",
        "            (\"what do you do\", \"நீங்கள் என்ன வேலை செய்கிறீர்கள்\"),\n",
        "            (\"i am a student\", \"நான் ஒரு மாணவன்\"),\n",
        "            (\"i am a teacher\", \"நான் ஒரு ஆசிரியர்\"),\n",
        "            (\"i am a doctor\", \"நான் ஒரு மருத்துவர்\"),\n",
        "            (\"i am an engineer\", \"நான் ஒரு பொறியாளர்\"),\n",
        "\n",
        "            # Language and communication\n",
        "            (\"do you speak tamil\", \"நீங்கள் தமிழ் பேசுவீர்களா\"),\n",
        "            (\"yes i speak tamil\", \"ஆம் நான் தமிழ் பேசுகிறேன்\"),\n",
        "            (\"i do not speak tamil\", \"நான் தமிழ் பேச மாட்டேன்\"),\n",
        "            (\"i am learning tamil\", \"நான் தமிழ் கற்றுக்கொண்டிருக்கிறேன்\"),\n",
        "            (\"can you speak english\", \"நீங்கள் ஆங்கிலம் பேச முடியுமா\"),\n",
        "            (\"i understand\", \"எனக்குப் புரிகிறது\"),\n",
        "            (\"i do not understand\", \"எனக்குப் புரியவில்லை\"),\n",
        "            (\"please speak slowly\", \"தயவுசெய்து மெதுவாக பேசுங்கள்\"),\n",
        "            (\"can you repeat\", \"நீங்கள் மீண்டும் சொல்ல முடியுமா\"),\n",
        "            (\"what does this mean\", \"இதன் அர்த்தம் என்ன\"),\n",
        "\n",
        "            # Help and directions\n",
        "            (\"can you help me\", \"நீங்கள் எனக்கு உதவ முடியுமா\"),\n",
        "            (\"i need help\", \"எனக்கு உதவி தேவை\"),\n",
        "            (\"where is the hospital\", \"மருத்துவமனை எங்கே உள்ளது\"),\n",
        "            (\"where is the market\", \"சந்தை எங்கே உள்ளது\"),\n",
        "            (\"where is the police station\", \"காவல் நிலையம் எங்கே உள்ளது\"),\n",
        "            (\"where is the bank\", \"வங்கி எங்கே உள்ளது\"),\n",
        "            (\"where is the restaurant\", \"உணவகம் எங்கே உள்ளது\"),\n",
        "            (\"go straight\", \"நேராகப் போங்கள்\"),\n",
        "            (\"turn left\", \"இடதுபுறம் திரும்பவும்\"),\n",
        "            (\"turn right\", \"வலதுபுறம் திரும்பவும்\"),\n",
        "            (\"it is near\", \"அது அருகில் உள்ளது\"),\n",
        "            (\"it is far\", \"அது தூரத்தில் உள்ளது\"),\n",
        "\n",
        "            # Shopping and money\n",
        "            (\"how much is this\", \"இது எவ்வளவு விலை\"),\n",
        "            (\"how much does this cost\", \"இது எவ்வளவு செலவாகும்\"),\n",
        "            (\"it is expensive\", \"இது விலை அதிகம்\"),\n",
        "            (\"it is cheap\", \"இது மலிவானது\"),\n",
        "            (\"i want to buy this\", \"நான் இதை வாங்க விரும்புகிறேன்\"),\n",
        "            (\"i will take this\", \"நான் இதை எடுத்துக்கொள்வேன்\"),\n",
        "            (\"give me the bill\", \"எனக்கு பில் கொடுங்கள்\"),\n",
        "            (\"do you accept credit cards\", \"நீங்கள் கிரெடிட் கார்டுகளை ஏற்கிறீர்களா\"),\n",
        "            (\"cash only\", \"பணம் மட்டும்\"),\n",
        "            (\"here is the money\", \"இதோ பணம்\"),\n",
        "\n",
        "            # Food and drink\n",
        "            (\"i am hungry\", \"எனக்கு பசிக்கிறது\"),\n",
        "            (\"i am thirsty\", \"எனக்கு தாகமாக இருக்கிறது\"),\n",
        "            (\"i want water\", \"எனக்கு தண்ணீர் வேண்டும்\"),\n",
        "            (\"i want food\", \"எனக்கு உணவு வேண்டும்\"),\n",
        "            (\"i like rice\", \"எனக்கு சாதம் பிடிக்கும்\"),\n",
        "            (\"this food is delicious\", \"இந்த உணவு சுவையாக உள்ளது\"),\n",
        "            (\"this food is spicy\", \"இந்த உணவு காரமாக உள்ளது\"),\n",
        "            (\"i want tea\", \"எனக்கு தேநீர் வேண்டும்\"),\n",
        "            (\"i want coffee\", \"எனக்கு காபி வேண்டும்\"),\n",
        "            (\"the bill please\", \"பில் தாருங்கள்\"),\n",
        "\n",
        "            # Time and weather\n",
        "            (\"what time is it\", \"என்ன நேரம்\"),\n",
        "            (\"it is ten o clock\", \"பத்து மணி\"),\n",
        "            (\"today is monday\", \"இன்று திங்கட்கிழமை\"),\n",
        "            (\"tomorrow is tuesday\", \"நாளை செவ்வாய்க்கிழமை\"),\n",
        "            (\"yesterday was sunday\", \"நேற்று ஞாயிற்றுக்கிழமை\"),\n",
        "            (\"the weather is good\", \"வானிலை நல்லாக உள்ளது\"),\n",
        "            (\"the weather is bad\", \"வானிலை மோசமாக உள்ளது\"),\n",
        "            (\"it is raining\", \"மழை பெய்கிறது\"),\n",
        "            (\"it is sunny\", \"வெயில் அடிக்கிறது\"),\n",
        "            (\"it is hot\", \"வெப்பமாக உள்ளது\"),\n",
        "            (\"it is cold\", \"குளிர்ச்சியாக உள்ளது\"),\n",
        "\n",
        "            # Family and relationships\n",
        "            (\"this is my family\", \"இது என் குடும்பம்\"),\n",
        "            (\"i have a brother\", \"எனக்கு ஒரு சகோதரன் உள்ளான்\"),\n",
        "            (\"i have a sister\", \"எனக்கு ஒரு சகோதரி உள்ளாள்\"),\n",
        "            (\"this is my mother\", \"இது என் அம்மா\"),\n",
        "            (\"this is my father\", \"இது என் அப்பா\"),\n",
        "            (\"she is my wife\", \"அவள் என் மனைவி\"),\n",
        "            (\"he is my husband\", \"அவர் என் கணவர்\"),\n",
        "            (\"we are friends\", \"நாங்கள் நண்பர்கள்\"),\n",
        "            (\"i love my family\", \"நான் என் குடும்பத்தை நேசிக்கிறேன்\"),\n",
        "            (\"i miss my family\", \"என் குடும்பத்தை இழக்கிறேன்\"),\n",
        "\n",
        "            # Emotions and feelings\n",
        "            (\"i am happy\", \"நான் மகிழ்ச்சியாக இருக்கிறேன்\"),\n",
        "            (\"i am sad\", \"நான் வருத்தமாக இருக்கிறேன்\"),\n",
        "            (\"i am angry\", \"நான் கோபமாக இருக்கிறேன்\"),\n",
        "            (\"i am tired\", \"நான் சோர்வாக இருக்கிறேன்\"),\n",
        "            (\"i am excited\", \"நான் உற்சாகமாக இருக்கிறேன்\"),\n",
        "            (\"i am worried\", \"நான் கவலைப்படுகிறேன்\"),\n",
        "            (\"i am scared\", \"நான் பயப்படுகிறேன்\"),\n",
        "            (\"i love you\", \"நான் உன்னை நேசிக்கிறேன்\"),\n",
        "            (\"i miss you\", \"நான் உன்னை இழக்கிறேன்\"),\n",
        "            (\"i care about you\", \"நான் உன்னைப் பற்றி அக்கரை கொள்கிறேன்\"),\n",
        "\n",
        "            # Daily activities\n",
        "            (\"i wake up early\", \"நான் சீக்கிரம் எழுந்திருக்கிறேன்\"),\n",
        "            (\"i go to work\", \"நான் வேலைக்குப் போகிறேன்\"),\n",
        "            (\"i am eating\", \"நான் சாப்பிடுகிறேன்\"),\n",
        "            (\"i am drinking\", \"நான் குடிக்கிறேன்\"),\n",
        "            (\"i am sleeping\", \"நான் தூங்குகிறேன்\"),\n",
        "            (\"i am working\", \"நான் வேலை செய்கிறேன்\"),\n",
        "            (\"i am studying\", \"நான் படிக்கிறேன்\"),\n",
        "            (\"i am reading\", \"நான் படிக்கிறேன்\"),\n",
        "            (\"i am writing\", \"நான் எழுதுகிறேன்\"),\n",
        "            (\"i am watching tv\", \"நான் தொலைக்காட்சி பார்க்கிறேன்\"),\n",
        "            (\"i am listening to music\", \"நான் இசை கேட்கிறேன்\"),\n",
        "            (\"i go to sleep\", \"நான் தூங்கப் போகிறேன்\"),\n",
        "\n",
        "            # Objects and possessions\n",
        "            (\"this is a book\", \"இது ஒரு புத்தகம்\"),\n",
        "            (\"this is a pen\", \"இது ஒரு பேனா\"),\n",
        "            (\"this is my phone\", \"இது என் தொலைபேசி\"),\n",
        "            (\"this is my car\", \"இது என் கார்\"),\n",
        "            (\"this is my house\", \"இது என் வீடு\"),\n",
        "            (\"i have a computer\", \"என்னிடம் ஒரு கணினி உள்ளது\"),\n",
        "            (\"i need a taxi\", \"எனக்கு ஒரு டாக்ஸி தேவை\"),\n",
        "            (\"where is my bag\", \"என் பை எங்கே\"),\n",
        "            (\"i lost my wallet\", \"நான் என் பணப்பையை இழந்தேன்\"),\n",
        "            (\"this is beautiful\", \"இது அழகானது\"),\n",
        "\n",
        "            # Travel and transportation\n",
        "            (\"i am going to chennai\", \"நான் சென்னைக்குப் போகிறேன்\"),\n",
        "            (\"when does the bus arrive\", \"பேருந்து எப்போது வரும்\"),\n",
        "            (\"where is the bus stop\", \"பேருந்து நிறுத்தம் எங்கே\"),\n",
        "            (\"i need a ticket\", \"எனக்கு ஒரு டிக்கெட் தேவை\"),\n",
        "            (\"how long does it take\", \"இது எவ்வளவு நேரம் ஆகும்\"),\n",
        "            (\"i am lost\", \"நான் வழி தவறிவிட்டேன்\"),\n",
        "            (\"can you show me the way\", \"நீங்கள் எனக்கு வழி காட்ட முடியுமா\"),\n",
        "            (\"i want to go home\", \"நான் வீட்டிற்கு செல்ல விரும்புகிறேன்\"),\n",
        "\n",
        "            # Health and medical\n",
        "            (\"i am sick\", \"நான் நோய்வாய்ப்பட்டிருக்கிறேன்\"),\n",
        "            (\"i have a headache\", \"எனக்கு தலைவலி\"),\n",
        "            (\"i have a fever\", \"எனக்கு காய்ச்சல்\"),\n",
        "            (\"i need a doctor\", \"எனக்கு ஒரு மருத்துவர் தேவை\"),\n",
        "            (\"where is the pharmacy\", \"மருந்தகம் எங்கே\"),\n",
        "            (\"i need medicine\", \"எனக்கு மருந்து தேவை\"),\n",
        "            (\"call an ambulance\", \"ஆம்புலன்ஸை அழைக்கவும்\"),\n",
        "            (\"i feel better\", \"நான் நன்றாக உணர்கிறேன்\"),\n",
        "\n",
        "            # Technology and communication\n",
        "            (\"my phone is not working\", \"என் போன் வேலை செய்யவில்லை\"),\n",
        "            (\"i need internet\", \"எனக்கு இணையம் தேவை\"),\n",
        "            (\"where is wifi\", \"வைஃபை எங்கே\"),\n",
        "            (\"can i use your phone\", \"நான் உங்கள் போனைப் பயன்படுத்த முடியுமா\"),\n",
        "            (\"send me a message\", \"எனக்கு ஒரு செய்தி அனுப்பவும்\"),\n",
        "            (\"what is your phone number\", \"உங்கள் போன் எண் என்ன\"),\n",
        "            (\"i will call you\", \"நான் உங்களை அழைப்பேன்\"),\n",
        "        ]\n",
        "\n",
        "        # Expand the dataset by creating variations\n",
        "        expanded_data = []\n",
        "        expanded_data.extend(sample_data)\n",
        "\n",
        "        # Add variations with different pronouns\n",
        "        pronoun_replacements = [\n",
        "            (\"i am\", \"you are\", \"நான்\", \"நீங்கள்\"),\n",
        "            (\"my\", \"your\", \"என்\", \"உங்கள்\"),\n",
        "            (\"me\", \"you\", \"என்னை\", \"உங்களை\")\n",
        "        ]\n",
        "\n",
        "        # Create variations (simplified approach)\n",
        "        for eng, tam in sample_data[:50]:  # Only for first 50 to avoid too much repetition\n",
        "            for old_eng, new_eng, old_tam, new_tam in pronoun_replacements:\n",
        "                if old_eng in eng:\n",
        "                    new_eng_sent = eng.replace(old_eng, new_eng)\n",
        "                    new_tam_sent = tam.replace(old_tam, new_tam)\n",
        "                    if new_eng_sent != eng:  # Only add if actually changed\n",
        "                        expanded_data.append((new_eng_sent, new_tam_sent))\n",
        "\n",
        "        # Add some longer sentences\n",
        "        longer_sentences = [\n",
        "            (\"i am very happy to meet you\", \"உங்களைச் சந்தித்ததில் நான் மிகவும் மகிழ்ச்சியடைகிறேன்\"),\n",
        "            (\"the food in this restaurant is very delicious\", \"இந்த உணவகத்தில் உள்ள உணவு மிகவும் சுவையாக உள்ளது\"),\n",
        "            (\"i want to learn tamil language properly\", \"நான் தமிழ் மொழியை சரியாக கற்றுக்கொள்ள விரும்புகிறேன்\"),\n",
        "            (\"can you please help me find my way to the airport\", \"தயவுசெய்து விமான நிலையத்திற்கு செல்லும் வழியைக் கண்டுபிடிக்க எனக்கு உதவ முடியுமா\"),\n",
        "            (\"i am looking forward to visiting chennai next month\", \"அடுத்த மாதம் சென்னையை பார்வையிட நான் ஆவலுடன் காத்திருக்கிறேன்\"),\n",
        "            (\"thank you very much for your kind help and support\", \"உங்கள் அன்பான உதவி மற்றும் ஆதரவிற்கு மிக்க நன்றி\"),\n",
        "            (\"i hope we can meet again in the near future\", \"எதிர்கால நேரத்தில் நாங்கள் மீண்டும் சந்திக்க முடியும் என்று நம்புகிறேன்\"),\n",
        "            (\"the weather today is very pleasant and sunny\", \"இன்றைய வானிலை மிகவும் இனிமையானது மற்றும் வெயிலாக உள்ளது\"),\n",
        "        ]\n",
        "\n",
        "        expanded_data.extend(longer_sentences)\n",
        "\n",
        "        # Repeat the entire dataset a few times to reach 1000+ examples\n",
        "        final_data = []\n",
        "        for _ in range(5):  # Repeat 5 times\n",
        "            final_data.extend(expanded_data)\n",
        "\n",
        "        # Shuffle and return\n",
        "        np.random.shuffle(final_data)\n",
        "        english_sentences = [pair[0] for pair in final_data]\n",
        "        tamil_sentences = [pair[1] for pair in final_data]\n",
        "\n",
        "        print(f\"✅ Generated {len(english_sentences)} high-quality sentence pairs\")\n",
        "        return english_sentences, tamil_sentences\n",
        "\n",
        "    def get_dataset(self, dataset_name):\n",
        "        \"\"\"Get specified dataset\"\"\"\n",
        "        if dataset_name not in self.datasets:\n",
        "            print(f\"❌ Unknown dataset: {dataset_name}\")\n",
        "            print(f\"Available datasets: {list(self.datasets.keys())}\")\n",
        "            return [], []\n",
        "\n",
        "        print(f\"📁 Loading dataset: {self.datasets[dataset_name]['name']}\")\n",
        "        print(f\"📝 Description: {self.datasets[dataset_name]['description']}\")\n",
        "\n",
        "        if dataset_name == \"ufal_v2\":\n",
        "            return self.download_ufal_v2()\n",
        "        elif dataset_name == \"nlpc_uom\":\n",
        "            return self.download_nlpc_uom()\n",
        "        elif dataset_name == \"opus_subtitles\":\n",
        "            return self.download_opus_subtitles()\n",
        "        elif dataset_name == \"small_sample\":\n",
        "            return self.generate_small_sample()\n",
        "        else:\n",
        "            return [], []\n",
        "\n",
        "    def list_datasets(self):\n",
        "        \"\"\"List all available datasets\"\"\"\n",
        "        print(\"📊 Available English-Tamil Datasets:\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        for key, info in self.datasets.items():\n",
        "            print(f\"🔹 {key}\")\n",
        "            print(f\"   Name: {info['name']}\")\n",
        "            print(f\"   Description: {info['description']}\")\n",
        "            print(f\"   Size: {info.get('size', 'Unknown')}\")\n",
        "            print(f\"   Format: {info['format']}\")\n",
        "            print()\n",
        "\n",
        "class EnglishTamilTranslator:\n",
        "    \"\"\"Complete English-Tamil translator with real datasets\"\"\"\n",
        "\n",
        "    def __init__(self, max_encoder_seq_length=25, max_decoder_seq_length=30):\n",
        "        self.max_encoder_seq_length = max_encoder_seq_length\n",
        "        self.max_decoder_seq_length = max_decoder_seq_length\n",
        "        self.eng_tokenizer = None\n",
        "        self.tamil_tokenizer = None\n",
        "        self.model = None\n",
        "        self.encoder_model = None\n",
        "        self.decoder_model = None\n",
        "        self.training_history = None\n",
        "\n",
        "    def preprocess_text(self, text):\n",
        "        \"\"\"Clean and preprocess text\"\"\"\n",
        "        if not text or not isinstance(text, str):\n",
        "            return \"\"\n",
        "\n",
        "        # Convert to lowercase for English (keep Tamil as is)\n",
        "        if any(ord(char) > 127 for char in text):  # Tamil text\n",
        "            text = text.strip()\n",
        "        else:  # English text\n",
        "            text = text.lower().strip()\n",
        "\n",
        "        # Remove extra punctuation\n",
        "        text = re.sub(r'[^\\w\\s\\u0B80-\\u0BFF]', '', text)  # Keep Tamil Unicode range\n",
        "\n",
        "        # Remove extra spaces\n",
        "        text = ' '.join(text.split())\n",
        "        return text\n",
        "\n",
        "    def prepare_data_from_dataset(self, dataset_name, max_samples=None):\n",
        "        \"\"\"Prepare data from downloaded dataset\"\"\"\n",
        "        downloader = DatasetDownloader()\n",
        "        english_sentences, tamil_sentences = downloader.get_dataset(dataset_name)\n",
        "\n",
        "        if not english_sentences or not tamil_sentences:\n",
        "            print(\"❌ Failed to load dataset\")\n",
        "            return [], []\n",
        "\n",
        "        # Filter and clean sentences\n",
        "        cleaned_english = []\n",
        "        cleaned_tamil = []\n",
        "\n",
        "        for eng, tam in zip(english_sentences, tamil_sentences):\n",
        "            eng_clean = self.preprocess_text(eng)\n",
        "            tam_clean = self.preprocess_text(tam)\n",
        "\n",
        "            # Filter criteria\n",
        "            if (eng_clean and tam_clean and\n",
        "                1 <= len(eng_clean.split()) <= 20 and\n",
        "                1 <= len(tam_clean.split()) <= 25 and\n",
        "                len(eng_clean) > 3 and len(tam_clean) > 3):\n",
        "\n",
        "                cleaned_english.append(eng_clean)\n",
        "                cleaned_tamil.append(f\"startseq {tam_clean} endseq\")\n",
        "\n",
        "        # Limit samples if specified\n",
        "        if max_samples and len(cleaned_english) > max_samples:\n",
        "            indices = np.random.choice(len(cleaned_english), max_samples, replace=False)\n",
        "            cleaned_english = [cleaned_english[i] for i in indices]\n",
        "            cleaned_tamil = [cleaned_tamil[i] for i in indices]\n",
        "\n",
        "        print(f\"✅ Prepared {len(cleaned_english)} clean sentence pairs\")\n",
        "        return cleaned_english, cleaned_tamil\n",
        "\n",
        "    def create_tokenizers(self, english_sentences, tamil_sentences):\n",
        "        \"\"\"Create tokenizers\"\"\"\n",
        "        print(\"🔤 Creating tokenizers...\")\n",
        "\n",
        "        # English tokenizer\n",
        "        self.eng_tokenizer = Tokenizer(num_words=8000, filters='', lower=True)\n",
        "        self.eng_tokenizer.fit_on_texts(english_sentences)\n",
        "\n",
        "        # Tamil tokenizer\n",
        "        self.tamil_tokenizer = Tokenizer(num_words=12000, filters='', lower=False)\n",
        "        self.tamil_tokenizer.fit_on_texts(tamil_sentences)\n",
        "\n",
        "        # Get vocabulary sizes\n",
        "        self.eng_vocab_size = len(self.eng_tokenizer.word_index) + 1\n",
        "        self.tamil_vocab_size = len(self.tamil_tokenizer.word_index) + 1\n",
        "\n",
        "        print(f\"📈 English vocabulary: {self.eng_vocab_size}\")\n",
        "        print(f\"📈 Tamil vocabulary: {self.tamil_vocab_size}\")\n",
        "\n",
        "        return self.eng_tokenizer, self.tamil_tokenizer\n",
        "\n",
        "    def encode_sequences(self, english_sentences, tamil_sentences):\n",
        "        \"\"\"Convert sentences to sequences\"\"\"\n",
        "        print(\"🔢 Encoding sequences...\")\n",
        "\n",
        "        # Convert to sequences\n",
        "        eng_sequences = self.eng_tokenizer.texts_to_sequences(english_sentences)\n",
        "        tamil_sequences = self.tamil_tokenizer.texts_to_sequences(tamil_sentences)\n",
        "\n",
        "        # Pad sequences\n",
        "        encoder_input_data = pad_sequences(eng_sequences,\n",
        "                                         maxlen=self.max_encoder_seq_length,\n",
        "                                         padding='post')\n",
        "\n",
        "        decoder_input_data = pad_sequences(tamil_sequences,\n",
        "                                         maxlen=self.max_decoder_seq_length,\n",
        "                                         padding='post')\n",
        "\n",
        "        # Create decoder target data\n",
        "        decoder_target_sequences = []\n",
        "        for seq in tamil_sequences:\n",
        "            target_seq = seq[1:] + [0]  # Remove startseq, add padding\n",
        "            decoder_target_sequences.append(target_seq)\n",
        "\n",
        "        decoder_target_data = pad_sequences(decoder_target_sequences,\n",
        "                                          maxlen=self.max_decoder_seq_length,\n",
        "                                          padding='post')\n",
        "\n",
        "        # Convert to categorical\n",
        "        decoder_target_data_categorical = to_categorical(decoder_target_data,\n",
        "                                                       num_classes=self.tamil_vocab_size)\n",
        "\n",
        "        print(f\"📐 Shapes: Encoder {encoder_input_data.shape}, \"\n",
        "              f\"Decoder input {decoder_input_data.shape}, \"\n",
        "              f\"Decoder target {decoder_target_data_categorical.shape}\")\n",
        "\n",
        "        return encoder_input_data, decoder_input_data, decoder_target_data_categorical\n",
        "\n",
        "    def build_model(self, embedding_dim=256, latent_dim=512):\n",
        "        \"\"\"Build seq2seq model\"\"\"\n",
        "        print(\"🏗️ Building seq2seq model...\")\n",
        "\n",
        "        # Encoder\n",
        "        encoder_inputs = Input(shape=(None,), name='encoder_inputs')\n",
        "        encoder_embedding = Embedding(self.eng_vocab_size, embedding_dim,\n",
        "                                    mask_zero=True, name='encoder_embedding')\n",
        "        encoder_embedded = encoder_embedding(encoder_inputs)\n",
        "        encoder_embedded = Dropout(0.3)(encoder_embedded)\n",
        "\n",
        "        encoder_lstm = LSTM(latent_dim, return_state=True, dropout=0.3,\n",
        "                          recurrent_dropout=0.3, name='encoder_lstm')\n",
        "        encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedded)\n",
        "        encoder_states = [state_h, state_c]\n",
        "\n",
        "        # Decoder\n",
        "        decoder_inputs = Input(shape=(None,), name='decoder_inputs')\n",
        "        decoder_embedding = Embedding(self.tamil_vocab_size, embedding_dim,\n",
        "                                    mask_zero=True, name='decoder_embedding')\n",
        "        decoder_embedded = decoder_embedding(decoder_inputs)\n",
        "        decoder_embedded = Dropout(0.3)(decoder_embedded)\n",
        "\n",
        "        decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,\n",
        "                          dropout=0.3, recurrent_dropout=0.3, name='decoder_lstm')\n",
        "        decoder_outputs, _, _ = decoder_lstm(decoder_embedded, initial_state=encoder_states)\n",
        "\n",
        "        decoder_dense = Dense(self.tamil_vocab_size, activation='softmax', name='decoder_dense')\n",
        "        decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "        # Create model\n",
        "        self.model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "        # Compile\n",
        "        optimizer = Adam(learning_rate=0.001)\n",
        "        self.model.compile(optimizer=optimizer,\n",
        "                          loss='categorical_crossentropy',\n",
        "                          metrics=['accuracy'])\n",
        "\n",
        "        print(f\"✅ Model created with {self.model.count_params():,} parameters\")\n",
        "        self.model.summary()\n",
        "\n",
        "        return self.model\n",
        "\n",
        "    def train_model(self, encoder_input_data, decoder_input_data, decoder_target_data,\n",
        "                   epochs=50, batch_size=64, validation_split=0.2):\n",
        "        \"\"\"Train the model\"\"\"\n",
        "        print(f\"🎯 Training for {epochs} epochs...\")\n",
        "\n",
        "        callbacks = [\n",
        "            ModelCheckpoint('best_translation_model.h5', monitor='val_loss',\n",
        "                          save_best_only=True, verbose=1),\n",
        "            EarlyStopping(monitor='val_loss', patience=10, verbose=1),\n",
        "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5,\n",
        "                            min_lr=1e-6, verbose=1)\n",
        "        ]\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        self.training_history = self.model.fit(\n",
        "            [encoder_input_data, decoder_input_data],\n",
        "            decoder_target_data,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            validation_split=validation_split,\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        training_time = time.time() - start_time\n",
        "        print(f\"✅ Training completed in {training_time:.2f} seconds\")\n",
        "\n",
        "        return self.training_history\n",
        "\n",
        "    def build_inference_models(self):\n",
        "        \"\"\"Build inference models\"\"\"\n",
        "        print(\"🔧 Building inference models...\")\n",
        "\n",
        "        # Encoder model\n",
        "        encoder_inputs = self.model.input[0]\n",
        "        encoder_outputs, state_h_enc, state_c_enc = self.model.layers[4].output\n",
        "        encoder_states = [state_h_enc, state_c_enc]\n",
        "        self.encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "        # Decoder model\n",
        "        decoder_inputs = self.model.input[1]\n",
        "        decoder_state_input_h = Input(shape=(512,))\n",
        "        decoder_state_input_c = Input(shape=(512,))\n",
        "        decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "        decoder_embedding = self.model.layers[3]\n",
        "        decoder_lstm = self.model.layers[6]\n",
        "        decoder_dense = self.model.layers[7]\n",
        "\n",
        "        decoder_embedded = decoder_embedding(decoder_inputs)\n",
        "        decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "            decoder_embedded, initial_state=decoder_states_inputs)\n",
        "        decoder_states = [state_h_dec, state_c_dec]\n",
        "        decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "        self.decoder_model = Model([decoder_inputs] + decoder_states_inputs,\n",
        "                                 [decoder_outputs] + decoder_states)\n",
        "\n",
        "        print(\"✅ Inference models ready\")\n",
        "\n",
        "    def translate_sentence(self, input_sentence, max_output_length=None):\n",
        "        \"\"\"Translate a sentence\"\"\"\n",
        "        if max_output_length is None:\n",
        "            max_output_length = self.max_decoder_seq_length\n",
        "\n",
        "        # Preprocess\n",
        "        input_sentence = self.preprocess_text(input_sentence)\n",
        "        if not input_sentence:\n",
        "            return \"Invalid input\"\n",
        "\n",
        "        # Encode\n",
        "        input_seq = self.eng_tokenizer.texts_to_sequences([input_sentence])\n",
        "        if not input_seq or not input_seq[0]:\n",
        "            return \"Unable to tokenize input\"\n",
        "\n",
        "        input_seq = pad_sequences(input_seq, maxlen=self.max_encoder_seq_length, padding='post')\n",
        "\n",
        "        # Get encoder states\n",
        "        states_value = self.encoder_model.predict(input_seq, verbose=0)\n",
        "\n",
        "        # Initialize target sequence\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        start_token = self.tamil_tokenizer.word_index.get('startseq', 1)\n",
        "        target_seq[0, 0] = start_token\n",
        "\n",
        "        # Generate translation\n",
        "        decoded_sentence = ''\n",
        "\n",
        "        for _ in range(max_output_length):\n",
        "            output_tokens, h, c = self.decoder_model.predict([target_seq] + states_value, verbose=0)\n",
        "\n",
        "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "\n",
        "            # Convert to word\n",
        "            sampled_word = None\n",
        "            for word, index in self.tamil_tokenizer.word_index.items():\n",
        "                if index == sampled_token_index:\n",
        "                    sampled_word = word\n",
        "                    break\n",
        "\n",
        "            if sampled_word == 'endseq' or sampled_word is None:\n",
        "                break\n",
        "\n",
        "            if sampled_word != 'startseq':\n",
        "                decoded_sentence += sampled_word + ' '\n",
        "\n",
        "            # Update for next prediction\n",
        "            target_seq = np.zeros((1, 1))\n",
        "            target_seq[0, 0] = sampled_token_index\n",
        "            states_value = [h, c]\n",
        "\n",
        "        return decoded_sentence.strip()\n",
        "\n",
        "    def save_model(self, model_dir='translation_model'):\n",
        "        \"\"\"Save complete model\"\"\"\n",
        "        print(f\"💾 Saving model to {model_dir}...\")\n",
        "\n",
        "        os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "        # Save main model\n",
        "        self.model.save(os.path.join(model_dir, 'seq2seq_model.h5'))\n",
        "\n",
        "        # Save tokenizers\n",
        "        with open(os.path.join(model_dir, 'eng_tokenizer.pkl'), 'wb') as f:\n",
        "            pickle.dump(self.eng_tokenizer, f)\n",
        "\n",
        "        with open(os.path.join(model_dir, 'tamil_tokenizer.pkl'), 'wb') as f:\n",
        "            pickle.dump(self.tamil_tokenizer, f)\n",
        "\n",
        "        # Save config\n",
        "        config = {\n",
        "            'max_encoder_seq_length': self.max_encoder_seq_length,\n",
        "            'max_decoder_seq_length': self.max_decoder_seq_length,\n",
        "            'eng_vocab_size': self.eng_vocab_size,\n",
        "            'tamil_vocab_size': self.tamil_vocab_size\n",
        "        }\n",
        "\n",
        "        with open(os.path.join(model_dir, 'config.json'), 'w') as f:\n",
        "            json.dump(config, f, indent=2)\n",
        "\n",
        "        print(\"✅ Model saved successfully!\")\n",
        "\n",
        "    def load_model(self, model_dir='translation_model'):\n",
        "        \"\"\"Load saved model\"\"\"\n",
        "        print(f\"📂 Loading model from {model_dir}...\")\n",
        "\n",
        "        # Load main model\n",
        "        self.model = load_model(os.path.join(model_dir, 'seq2seq_model.h5'))\n",
        "\n",
        "        # Load tokenizers\n",
        "        with open(os.path.join(model_dir, 'eng_tokenizer.pkl'), 'rb') as f:\n",
        "            self.eng_tokenizer = pickle.load(f)\n",
        "\n",
        "        with open(os.path.join(model_dir, 'tamil_tokenizer.pkl'), 'rb') as f:\n",
        "            self.tamil_tokenizer = pickle.load(f)\n",
        "\n",
        "        # Load config\n",
        "        with open(os.path.join(model_dir, 'config.json'), 'r') as f:\n",
        "            config = json.load(f)\n",
        "\n",
        "        self.max_encoder_seq_length = config['max_encoder_seq_length']\n",
        "        self.max_decoder_seq_length = config['max_decoder_seq_length']\n",
        "        self.eng_vocab_size = config['eng_vocab_size']\n",
        "        self.tamil_vocab_size = config['tamil_vocab_size']\n",
        "\n",
        "        # Build inference models\n",
        "        self.build_inference_models()\n",
        "\n",
        "        print(\"✅ Model loaded successfully!\")\n",
        "\n",
        "def plot_training_history(history):\n",
        "    \"\"\"Plot training history\"\"\"\n",
        "    if not history:\n",
        "        return\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    # Loss\n",
        "    ax1.plot(history.history['loss'], label='Training Loss', color='blue')\n",
        "    ax1.plot(history.history['val_loss'], label='Validation Loss', color='red')\n",
        "    ax1.set_title('Model Loss')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # Accuracy\n",
        "    ax2.plot(history.history['accuracy'], label='Training Accuracy', color='blue')\n",
        "    ax2.plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')\n",
        "    ax2.set_title('Model Accuracy')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Accuracy')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def evaluate_model(translator, test_pairs):\n",
        "    \"\"\"Evaluate model performance\"\"\"\n",
        "    print(\"🧪 Evaluating model...\")\n",
        "\n",
        "    correct_translations = 0\n",
        "    total_word_accuracy = 0\n",
        "\n",
        "    for i, (eng, expected_tamil) in enumerate(test_pairs):\n",
        "        predicted_tamil = translator.translate_sentence(eng)\n",
        "\n",
        "        # Clean expected output\n",
        "        expected_clean = expected_tamil.replace('startseq', '').replace('endseq', '').strip()\n",
        "\n",
        "        # Check exact match\n",
        "        if predicted_tamil.lower().strip() == expected_clean.lower().strip():\n",
        "            correct_translations += 1\n",
        "\n",
        "        # Word-level accuracy\n",
        "        expected_words = set(expected_clean.lower().split())\n",
        "        predicted_words = set(predicted_tamil.lower().split())\n",
        "\n",
        "        if expected_words:\n",
        "            word_accuracy = len(expected_words.intersection(predicted_words)) / len(expected_words)\n",
        "            total_word_accuracy += word_accuracy\n",
        "\n",
        "        # Show first 10 examples\n",
        "        if i < 10:\n",
        "            print(f\"{i+1:2d}. EN: {eng}\")\n",
        "            print(f\"    Expected: {expected_clean}\")\n",
        "            print(f\"    Predicted: {predicted_tamil}\")\n",
        "            print(f\"    Word Acc: {word_accuracy:.3f}\")\n",
        "            print()\n",
        "\n",
        "    exact_accuracy = correct_translations / len(test_pairs)\n",
        "    avg_word_accuracy = total_word_accuracy / len(test_pairs)\n",
        "\n",
        "    print(f\"📊 Results:\")\n",
        "    print(f\"   Exact matches: {correct_translations}/{len(test_pairs)} ({exact_accuracy:.1%})\")\n",
        "    print(f\"   Average word accuracy: {avg_word_accuracy:.3f}\")\n",
        "\n",
        "    return exact_accuracy, avg_word_accuracy\n",
        "\n",
        "def interactive_translation(translator):\n",
        "    \"\"\"Interactive translation session\"\"\"\n",
        "    print(\"\\n🎮 Interactive Translation Session\")\n",
        "    print(\"Commands: 'test' for examples, 'quit' to exit\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    test_examples = [\n",
        "        \"hello friend\", \"thank you very much\", \"how are you today\",\n",
        "        \"i am learning tamil\", \"where is the hospital\", \"i need help\",\n",
        "        \"the weather is good\", \"i love my family\", \"good morning everyone\"\n",
        "    ]\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            user_input = input(\"\\n🔤 English: \").strip()\n",
        "\n",
        "            if user_input.lower() == 'quit':\n",
        "                print(\"👋 Goodbye!\")\n",
        "                break\n",
        "            elif user_input.lower() == 'test':\n",
        "                print(\"\\n🧪 Test Examples:\")\n",
        "                for example in test_examples:\n",
        "                    translation = translator.translate_sentence(example)\n",
        "                    print(f\"  {example} → {translation}\")\n",
        "                continue\n",
        "            elif user_input:\n",
        "                translation = translator.translate_sentence(user_input)\n",
        "                print(f\"🌟 Tamil: {translation}\")\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n👋 Goodbye!\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error: {e}\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main training function\"\"\"\n",
        "    print(\"🌟 English-Tamil Neural Machine Translation with Real Datasets\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Show available datasets\n",
        "    downloader = DatasetDownloader()\n",
        "    downloader.list_datasets()\n",
        "\n",
        "    # Choose dataset\n",
        "    print(\"📋 Select a dataset:\")\n",
        "    print(\"1. ufal_v2 - Large corpus (530k+ pairs) - Best quality\")\n",
        "    print(\"2. small_sample - Generated corpus (1k+ pairs) - Quick testing\")\n",
        "    print(\"3. nlpc_uom - Government corpus (22k+ pairs) - Medium size\")\n",
        "    print(\"4. opus_subtitles - Movie subtitles - Variable size\")\n",
        "\n",
        "    while True:\n",
        "        choice = input(\"\\n🔢 Enter choice (1-4): \").strip()\n",
        "        if choice == \"1\":\n",
        "            dataset_name = \"ufal_v2\"\n",
        "            max_samples = 50000  # Limit for faster training\n",
        "            break\n",
        "        elif choice == \"2\":\n",
        "            dataset_name = \"small_sample\"\n",
        "            max_samples = None\n",
        "            break\n",
        "        elif choice == \"3\":\n",
        "            dataset_name = \"nlpc_uom\"\n",
        "            max_samples = None\n",
        "            break\n",
        "        elif choice == \"4\":\n",
        "            dataset_name = \"opus_subtitles\"\n",
        "            max_samples = 20000\n",
        "            break\n",
        "        else:\n",
        "            print(\"❌ Invalid choice. Please enter 1-4.\")\n",
        "\n",
        "    # Initialize translator\n",
        "    translator = EnglishTamilTranslator()\n",
        "\n",
        "    # Prepare data\n",
        "    english_sentences, tamil_sentences = translator.prepare_data_from_dataset(\n",
        "        dataset_name, max_samples)\n",
        "\n",
        "    if not english_sentences:\n",
        "        print(\"❌ No data loaded. Exiting.\")\n",
        "        return\n",
        "\n",
        "    # Create tokenizers\n",
        "    translator.create_tokenizers(english_sentences, tamil_sentences)\n",
        "\n",
        "    # Encode sequences\n",
        "    encoder_input_data, decoder_input_data, decoder_target_data = translator.encode_sequences(\n",
        "        english_sentences, tamil_sentences)\n",
        "\n",
        "    # Build model\n",
        "    translator.build_model()\n",
        "\n",
        "    # Train model\n",
        "    epochs = 30 if dataset_name == \"small_sample\" else 50\n",
        "    batch_size = 32 if dataset_name == \"small_sample\" else 64\n",
        "\n",
        "    history = translator.train_model(\n",
        "        encoder_input_data, decoder_input_data, decoder_target_data,\n",
        "        epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "    # Build inference models\n",
        "    translator.build_inference_models()\n",
        "\n",
        "    # Save model\n",
        "    translator.save_model()\n",
        "\n",
        "    # Plot training history\n",
        "    plot_training_history(history)\n",
        "\n",
        "    # Evaluate\n",
        "    test_pairs = [\n",
        "        (\"hello\", \"வணக்கம்\"),\n",
        "        (\"thank you\", \"நன்றி\"),\n",
        "        (\"how are you\", \"நீங்கள் எப்படி இருக்கிறீர்கள்\"),\n",
        "        (\"i am fine\", \"நான் நலமாக இருக்கிறேன்\"),\n",
        "        (\"good morning\", \"காலை வணக்கம்\"),\n",
        "        (\"where is hospital\", \"மருத்துவமனை எங்கே\"),\n",
        "        (\"i need help\", \"எனக்கு உதவி தேவை\"),\n",
        "        (\"i love you\", \"நான் உன்னை நேசிக்கிறேன்\")\n",
        "    ]\n",
        "\n",
        "    evaluate_model(translator, test_pairs)\n",
        "\n",
        "    # Interactive session\n",
        "    interactive_translation(translator)\n",
        "\n",
        "def load_and_test():\n",
        "    \"\"\"Load saved model and test\"\"\"\n",
        "    try:\n",
        "        translator = EnglishTamilTranslator()\n",
        "        translator.load_model()\n",
        "\n",
        "        print(\"✅ Model loaded successfully!\")\n",
        "        interactive_translation(translator)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading model: {e}\")\n",
        "        print(\"Please train a model first using option 1.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"🌟 English-Tamil Neural Machine Translation System\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Options:\")\n",
        "    print(\"1. 🎯 Train new model with real datasets\")\n",
        "    print(\"2. 📂 Load saved model and test\")\n",
        "    print(\"3. 📊 Show available datasets\")\n",
        "\n",
        "    while True:\n",
        "        choice = input(\"\\n🔢 Enter choice (1-3): \").strip()\n",
        "\n",
        "        if choice == \"1\":\n",
        "            main()\n",
        "            break\n",
        "        elif choice == \"2\":\n",
        "            load_and_test()\n",
        "            break\n",
        "        elif choice == \"3\":\n",
        "            downloader = DatasetDownloader()\n",
        "            downloader.list_datasets()\n",
        "            continue\n",
        "        else:\n",
        "            print(\"❌ Invalid choice. Please enter 1, 2, or 3.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Dqz4vtY5btQi",
        "outputId": "f436cdbb-a1dd-4bea-c641-c6532f074ecd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🌟 English-Tamil Neural Machine Translation System\n",
            "============================================================\n",
            "Options:\n",
            "1. 🎯 Train new model with real datasets\n",
            "2. 📂 Load saved model and test\n",
            "3. 📊 Show available datasets\n",
            "\n",
            "🔢 Enter choice (1-3): 1\n",
            "🌟 English-Tamil Neural Machine Translation with Real Datasets\n",
            "======================================================================\n",
            "📊 Available English-Tamil Datasets:\n",
            "============================================================\n",
            "🔹 ufal_v2\n",
            "   Name: UFAL English-Tamil Parallel Corpus v2\n",
            "   Description: 530k+ sentence pairs from Bible, cinema, and news domains\n",
            "   Size: ~25MB\n",
            "   Format: tar.gz\n",
            "\n",
            "🔹 nlpc_uom\n",
            "   Name: NLPC-UOM English-Tamil Parallel Corpus\n",
            "   Description: 22k+ glossary + 9k+ corpus from government resources\n",
            "   Size: ~5MB\n",
            "   Format: parquet\n",
            "\n",
            "🔹 opus_subtitles\n",
            "   Name: OPUS OpenSubtitles English-Tamil\n",
            "   Description: Movie subtitles parallel corpus\n",
            "   Size: ~10MB\n",
            "   Format: zip\n",
            "\n",
            "🔹 small_sample\n",
            "   Name: Small Sample Dataset (Generated)\n",
            "   Description: 1000+ high-quality sentence pairs for quick testing\n",
            "   Size: ~1MB\n",
            "   Format: generated\n",
            "\n",
            "📋 Select a dataset:\n",
            "1. ufal_v2 - Large corpus (530k+ pairs) - Best quality\n",
            "2. small_sample - Generated corpus (1k+ pairs) - Quick testing\n",
            "3. nlpc_uom - Government corpus (22k+ pairs) - Medium size\n",
            "4. opus_subtitles - Movie subtitles - Variable size\n",
            "\n",
            "🔢 Enter choice (1-4): 2\n",
            "📁 Loading dataset: Small Sample Dataset (Generated)\n",
            "📝 Description: 1000+ high-quality sentence pairs for quick testing\n",
            "✅ Generated 885 high-quality sentence pairs\n",
            "✅ Prepared 885 clean sentence pairs\n",
            "🔤 Creating tokenizers...\n",
            "📈 English vocabulary: 219\n",
            "📈 Tamil vocabulary: 258\n",
            "🔢 Encoding sequences...\n",
            "📐 Shapes: Encoder (885, 25), Decoder input (885, 30), Decoder target (885, 30, 258)\n",
            "🏗️ Building seq2seq model...\n",
            "✅ Model created with 3,404,290 parameters\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │     \u001b[38;5;34m56,064\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │     \u001b[38;5;34m66,048\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ encoder_embeddin… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ decoder_embeddin… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),     │  \u001b[38;5;34m1,574,912\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),      │            │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │  \u001b[38;5;34m1,574,912\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m512\u001b[0m)]             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_dense       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m258\u001b[0m) │    \u001b[38;5;34m132,354\u001b[0m │ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">56,064</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_embeddin… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ decoder_embeddin… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      │            │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_dense       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">132,354</span> │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,404,290\u001b[0m (12.99 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,404,290</span> (12.99 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,404,290\u001b[0m (12.99 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,404,290</span> (12.99 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎯 Training for 30 epochs...\n",
            "Epoch 1/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.4470 - loss: 5.0345\n",
            "Epoch 1: val_loss improved from inf to 3.54378, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 242ms/step - accuracy: 0.4512 - loss: 5.0110 - val_accuracy: 0.0846 - val_loss: 3.5438 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.5060 - loss: 3.3685\n",
            "Epoch 2: val_loss improved from 3.54378 to 3.05180, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 204ms/step - accuracy: 0.4997 - loss: 3.3644 - val_accuracy: 0.1092 - val_loss: 3.0518 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.0873 - loss: 2.9254\n",
            "Epoch 3: val_loss improved from 3.05180 to 2.73214, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 211ms/step - accuracy: 0.0871 - loss: 2.9231 - val_accuracy: 0.0808 - val_loss: 2.7321 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.0830 - loss: 2.5550\n",
            "Epoch 4: val_loss improved from 2.73214 to 2.34873, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 196ms/step - accuracy: 0.0831 - loss: 2.5519 - val_accuracy: 0.0881 - val_loss: 2.3487 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.0889 - loss: 2.1443\n",
            "Epoch 5: val_loss improved from 2.34873 to 2.00488, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 241ms/step - accuracy: 0.0890 - loss: 2.1409 - val_accuracy: 0.0959 - val_loss: 2.0049 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.0977 - loss: 1.7547\n",
            "Epoch 6: val_loss improved from 2.00488 to 1.62002, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 237ms/step - accuracy: 0.0979 - loss: 1.7506 - val_accuracy: 0.1013 - val_loss: 1.6200 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.1047 - loss: 1.4151\n",
            "Epoch 7: val_loss improved from 1.62002 to 1.31068, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 199ms/step - accuracy: 0.1049 - loss: 1.4112 - val_accuracy: 0.1121 - val_loss: 1.3107 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.1148 - loss: 1.1347\n",
            "Epoch 8: val_loss improved from 1.31068 to 1.00090, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 190ms/step - accuracy: 0.1150 - loss: 1.1317 - val_accuracy: 0.1235 - val_loss: 1.0009 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.1256 - loss: 0.8726\n",
            "Epoch 9: val_loss improved from 1.00090 to 0.77323, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 290ms/step - accuracy: 0.1258 - loss: 0.8703 - val_accuracy: 0.1343 - val_loss: 0.7732 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 0.1370 - loss: 0.6794\n",
            "Epoch 10: val_loss improved from 0.77323 to 0.58116, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 247ms/step - accuracy: 0.1372 - loss: 0.6776 - val_accuracy: 0.1452 - val_loss: 0.5812 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.1435 - loss: 0.5240\n",
            "Epoch 11: val_loss improved from 0.58116 to 0.45625, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 269ms/step - accuracy: 0.1436 - loss: 0.5230 - val_accuracy: 0.1488 - val_loss: 0.4563 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.1496 - loss: 0.4173\n",
            "Epoch 12: val_loss improved from 0.45625 to 0.34990, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 199ms/step - accuracy: 0.1497 - loss: 0.4167 - val_accuracy: 0.1548 - val_loss: 0.3499 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.1521 - loss: 0.3380\n",
            "Epoch 13: val_loss improved from 0.34990 to 0.28596, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 243ms/step - accuracy: 0.1522 - loss: 0.3375 - val_accuracy: 0.1588 - val_loss: 0.2860 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.1546 - loss: 0.2824\n",
            "Epoch 14: val_loss improved from 0.28596 to 0.22723, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 192ms/step - accuracy: 0.1547 - loss: 0.2823 - val_accuracy: 0.1608 - val_loss: 0.2272 - learning_rate: 0.0010\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.1564 - loss: 0.2434\n",
            "Epoch 15: val_loss improved from 0.22723 to 0.17979, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 246ms/step - accuracy: 0.1564 - loss: 0.2431 - val_accuracy: 0.1638 - val_loss: 0.1798 - learning_rate: 0.0010\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.1589 - loss: 0.1932\n",
            "Epoch 16: val_loss improved from 0.17979 to 0.14148, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 198ms/step - accuracy: 0.1589 - loss: 0.1930 - val_accuracy: 0.1653 - val_loss: 0.1415 - learning_rate: 0.0010\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.1608 - loss: 0.1623\n",
            "Epoch 17: val_loss improved from 0.14148 to 0.11904, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 232ms/step - accuracy: 0.1609 - loss: 0.1621 - val_accuracy: 0.1670 - val_loss: 0.1190 - learning_rate: 0.0010\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.1610 - loss: 0.1405\n",
            "Epoch 18: val_loss improved from 0.11904 to 0.09206, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 194ms/step - accuracy: 0.1611 - loss: 0.1403 - val_accuracy: 0.1665 - val_loss: 0.0921 - learning_rate: 0.0010\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.1623 - loss: 0.1105\n",
            "Epoch 19: val_loss improved from 0.09206 to 0.07717, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 236ms/step - accuracy: 0.1624 - loss: 0.1103 - val_accuracy: 0.1678 - val_loss: 0.0772 - learning_rate: 0.0010\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.1638 - loss: 0.0909\n",
            "Epoch 20: val_loss improved from 0.07717 to 0.05850, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 220ms/step - accuracy: 0.1639 - loss: 0.0908 - val_accuracy: 0.1685 - val_loss: 0.0585 - learning_rate: 0.0010\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.1640 - loss: 0.0724\n",
            "Epoch 21: val_loss improved from 0.05850 to 0.04764, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 199ms/step - accuracy: 0.1641 - loss: 0.0724 - val_accuracy: 0.1685 - val_loss: 0.0476 - learning_rate: 0.0010\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.1646 - loss: 0.0624\n",
            "Epoch 22: val_loss improved from 0.04764 to 0.03801, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 191ms/step - accuracy: 0.1646 - loss: 0.0623 - val_accuracy: 0.1691 - val_loss: 0.0380 - learning_rate: 0.0010\n",
            "Epoch 23/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.1651 - loss: 0.0512\n",
            "Epoch 23: val_loss improved from 0.03801 to 0.03230, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 242ms/step - accuracy: 0.1651 - loss: 0.0511 - val_accuracy: 0.1689 - val_loss: 0.0323 - learning_rate: 0.0010\n",
            "Epoch 24/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.1649 - loss: 0.0450\n",
            "Epoch 24: val_loss improved from 0.03230 to 0.02560, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 246ms/step - accuracy: 0.1649 - loss: 0.0449 - val_accuracy: 0.1691 - val_loss: 0.0256 - learning_rate: 0.0010\n",
            "Epoch 25/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.1655 - loss: 0.0357\n",
            "Epoch 25: val_loss improved from 0.02560 to 0.02017, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 206ms/step - accuracy: 0.1655 - loss: 0.0356 - val_accuracy: 0.1691 - val_loss: 0.0202 - learning_rate: 0.0010\n",
            "Epoch 26/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.1656 - loss: 0.0314\n",
            "Epoch 26: val_loss improved from 0.02017 to 0.01989, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 222ms/step - accuracy: 0.1657 - loss: 0.0314 - val_accuracy: 0.1689 - val_loss: 0.0199 - learning_rate: 0.0010\n",
            "Epoch 27/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.1655 - loss: 0.0261\n",
            "Epoch 27: val_loss improved from 0.01989 to 0.01488, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 245ms/step - accuracy: 0.1655 - loss: 0.0260 - val_accuracy: 0.1691 - val_loss: 0.0149 - learning_rate: 0.0010\n",
            "Epoch 28/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.1656 - loss: 0.0246\n",
            "Epoch 28: val_loss improved from 0.01488 to 0.01317, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 242ms/step - accuracy: 0.1657 - loss: 0.0246 - val_accuracy: 0.1691 - val_loss: 0.0132 - learning_rate: 0.0010\n",
            "Epoch 29/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.1655 - loss: 0.0214\n",
            "Epoch 29: val_loss improved from 0.01317 to 0.01124, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 202ms/step - accuracy: 0.1656 - loss: 0.0214 - val_accuracy: 0.1691 - val_loss: 0.0112 - learning_rate: 0.0010\n",
            "Epoch 30/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.1656 - loss: 0.0188\n",
            "Epoch 30: val_loss improved from 0.01124 to 0.01010, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 242ms/step - accuracy: 0.1657 - loss: 0.0188 - val_accuracy: 0.1691 - val_loss: 0.0101 - learning_rate: 0.0010\n",
            "✅ Training completed in 222.28 seconds\n",
            "🔧 Building inference models...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "Iterating over a symbolic KerasTensor is not supported.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-65211068.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchoice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mchoice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2-65211068.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m     \u001b[0;31m# Build inference models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1018\u001b[0;31m     \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_inference_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;31m# Save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2-65211068.py\u001b[0m in \u001b[0;36mbuild_inference_models\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;31m# Encoder model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m         \u001b[0mencoder_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m         \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_h_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_c_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m         \u001b[0mencoder_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstate_h_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_c_enc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/common/keras_tensor.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         raise NotImplementedError(\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0;34m\"Iterating over a symbolic KerasTensor is not supported.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         )\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: Iterating over a symbolic KerasTensor is not supported."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "English-Tamil Neural Machine Translation with Real Dataset Downloads\n",
        "Complete system with multiple dataset options and automatic downloading\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "import requests\n",
        "import tarfile\n",
        "import zipfile\n",
        "import gzip\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "import urllib.request\n",
        "from tqdm import tqdm\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Essential imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "import re\n",
        "import pickle\n",
        "import json\n",
        "import time\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# TensorFlow imports\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Set random seeds\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "class DatasetDownloader:\n",
        "    \"\"\"Download and manage English-Tamil parallel datasets\"\"\"\n",
        "\n",
        "    def __init__(self, data_dir=\"datasets\"):\n",
        "        self.data_dir = Path(data_dir)\n",
        "        self.data_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        # Available datasets with their download URLs and descriptions\n",
        "        self.datasets = {\n",
        "            \"ufal_v2\": {\n",
        "                \"name\": \"UFAL English-Tamil Parallel Corpus v2\",\n",
        "                \"url\": \"http://ufal.mff.cuni.cz/~ramasamy/parallel/data/v2/en-ta-parallel-v2.tar.gz\",\n",
        "                \"description\": \"530k+ sentence pairs from Bible, cinema, and news domains\",\n",
        "                \"files\": {\n",
        "                    \"train_en\": \"en-ta-parallel-v2/corpus.bcn.train.en\",\n",
        "                    \"train_ta\": \"en-ta-parallel-v2/corpus.bcn.train.ta\",\n",
        "                    \"dev_en\": \"en-ta-parallel-v2/corpus.bcn.dev.en\",\n",
        "                    \"dev_ta\": \"en-ta-parallel-v2/corpus.bcn.dev.ta\",\n",
        "                    \"test_en\": \"en-ta-parallel-v2/corpus.bcn.test.en\",\n",
        "                    \"test_ta\": \"en-ta-parallel-v2/corpus.bcn.test.ta\"\n",
        "                },\n",
        "                \"format\": \"tar.gz\",\n",
        "                \"size\": \"~25MB\"\n",
        "            },\n",
        "\n",
        "            \"nlpc_uom\": {\n",
        "                \"name\": \"NLPC-UOM English-Tamil Parallel Corpus\",\n",
        "                \"url\": \"https://huggingface.co/datasets/NLPC-UOM/English-Tamil-Parallel-Corpus/resolve/main/data/train-00000-of-00001.parquet\",\n",
        "                \"description\": \"22k+ glossary + 9k+ corpus from government resources\",\n",
        "                \"files\": {\n",
        "                    \"parquet\": \"nlpc_uom_corpus.parquet\"\n",
        "                },\n",
        "                \"format\": \"parquet\",\n",
        "                \"size\": \"~5MB\"\n",
        "            },\n",
        "\n",
        "            \"opus_subtitles\": {\n",
        "                \"name\": \"OPUS OpenSubtitles English-Tamil\",\n",
        "                \"url\": \"https://object.pouta.csc.fi/OPUS-OpenSubtitles/v2018/moses/en-ta.txt.zip\",\n",
        "                \"description\": \"Movie subtitles parallel corpus\",\n",
        "                \"files\": {\n",
        "                    \"parallel\": \"OpenSubtitles.en-ta.en\",\n",
        "                    \"parallel_ta\": \"OpenSubtitles.en-ta.ta\"\n",
        "                },\n",
        "                \"format\": \"zip\",\n",
        "                \"size\": \"~10MB\"\n",
        "            },\n",
        "\n",
        "            \"small_sample\": {\n",
        "                \"name\": \"Small Sample Dataset (Generated)\",\n",
        "                \"description\": \"1000+ high-quality sentence pairs for quick testing\",\n",
        "                \"files\": {},\n",
        "                \"format\": \"generated\",\n",
        "                \"size\": \"~1MB\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def download_with_progress(self, url, filename):\n",
        "        \"\"\"Download file with progress bar\"\"\"\n",
        "        print(f\"📥 Downloading from {url}\")\n",
        "\n",
        "        response = requests.get(url, stream=True)\n",
        "        total_size = int(response.headers.get('content-length', 0))\n",
        "\n",
        "        with open(filename, 'wb') as file, tqdm(\n",
        "            desc=filename.name,\n",
        "            total=total_size,\n",
        "            unit='B',\n",
        "            unit_scale=True,\n",
        "            unit_divisor=1024,\n",
        "        ) as progress_bar:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                size = file.write(chunk)\n",
        "                progress_bar.update(size)\n",
        "\n",
        "    def extract_archive(self, archive_path, extract_to):\n",
        "        \"\"\"Extract tar.gz or zip files\"\"\"\n",
        "        print(f\"📦 Extracting {archive_path}\")\n",
        "\n",
        "        if archive_path.suffix == '.gz':\n",
        "            with tarfile.open(archive_path, 'r:gz') as tar:\n",
        "                tar.extractall(extract_to)\n",
        "        elif archive_path.suffix == '.zip':\n",
        "            with zipfile.ZipFile(archive_path, 'r') as zip_file:\n",
        "                zip_file.extractall(extract_to)\n",
        "\n",
        "    def download_ufal_v2(self):\n",
        "        \"\"\"Download UFAL English-Tamil v2 dataset\"\"\"\n",
        "        dataset_info = self.datasets[\"ufal_v2\"]\n",
        "        archive_path = self.data_dir / \"en-ta-parallel-v2.tar.gz\"\n",
        "        extract_dir = self.data_dir / \"ufal_v2\"\n",
        "\n",
        "        # Download if not exists\n",
        "        if not archive_path.exists():\n",
        "            self.download_with_progress(dataset_info[\"url\"], archive_path)\n",
        "\n",
        "        # Extract if not already extracted\n",
        "        if not extract_dir.exists():\n",
        "            extract_dir.mkdir()\n",
        "            self.extract_archive(archive_path, extract_dir)\n",
        "\n",
        "        # Read files\n",
        "        base_path = extract_dir / \"en-ta-parallel-v2\"\n",
        "        english_sentences = []\n",
        "        tamil_sentences = []\n",
        "\n",
        "        # Combine train, dev, test files\n",
        "        for split in ['train', 'dev', 'test']:\n",
        "            en_file = base_path / f\"corpus.bcn.{split}.en\"\n",
        "            ta_file = base_path / f\"corpus.bcn.{split}.ta\"\n",
        "\n",
        "            if en_file.exists() and ta_file.exists():\n",
        "                with open(en_file, 'r', encoding='utf-8') as f:\n",
        "                    en_lines = f.readlines()\n",
        "                with open(ta_file, 'r', encoding='utf-8') as f:\n",
        "                    ta_lines = f.readlines()\n",
        "\n",
        "                # Add to collections\n",
        "                english_sentences.extend([line.strip() for line in en_lines])\n",
        "                tamil_sentences.extend([line.strip() for line in ta_lines])\n",
        "\n",
        "        print(f\"✅ Loaded {len(english_sentences)} sentence pairs from UFAL v2\")\n",
        "        return english_sentences, tamil_sentences\n",
        "\n",
        "    def download_nlpc_uom(self):\n",
        "        \"\"\"Download NLPC-UOM dataset (requires pandas for parquet)\"\"\"\n",
        "        try:\n",
        "            import pandas as pd\n",
        "        except ImportError:\n",
        "            print(\"❌ pandas required for NLPC-UOM dataset. Installing...\")\n",
        "            os.system(\"pip install pandas pyarrow\")\n",
        "            import pandas as pd\n",
        "\n",
        "        dataset_info = self.datasets[\"nlpc_uom\"]\n",
        "        parquet_path = self.data_dir / \"nlpc_uom_corpus.parquet\"\n",
        "\n",
        "        # Download if not exists\n",
        "        if not parquet_path.exists():\n",
        "            self.download_with_progress(dataset_info[\"url\"], parquet_path)\n",
        "\n",
        "        # Read parquet file\n",
        "        try:\n",
        "            df = pd.read_parquet(parquet_path)\n",
        "            english_sentences = df['en'].tolist()\n",
        "            tamil_sentences = df['ta'].tolist()\n",
        "\n",
        "            print(f\"✅ Loaded {len(english_sentences)} sentence pairs from NLPC-UOM\")\n",
        "            return english_sentences, tamil_sentences\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error reading parquet file: {e}\")\n",
        "            return [], []\n",
        "\n",
        "    def download_opus_subtitles(self):\n",
        "        \"\"\"Download OPUS OpenSubtitles dataset\"\"\"\n",
        "        dataset_info = self.datasets[\"opus_subtitles\"]\n",
        "        zip_path = self.data_dir / \"opus_subtitles.zip\"\n",
        "        extract_dir = self.data_dir / \"opus_subtitles\"\n",
        "\n",
        "        # Download if not exists\n",
        "        if not zip_path.exists():\n",
        "            try:\n",
        "                self.download_with_progress(dataset_info[\"url\"], zip_path)\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Error downloading OPUS subtitles: {e}\")\n",
        "                return [], []\n",
        "\n",
        "        # Extract if not already extracted\n",
        "        if not extract_dir.exists():\n",
        "            extract_dir.mkdir()\n",
        "            try:\n",
        "                self.extract_archive(zip_path, extract_dir)\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Error extracting OPUS subtitles: {e}\")\n",
        "                return [], []\n",
        "\n",
        "        # Find and read parallel files\n",
        "        english_sentences = []\n",
        "        tamil_sentences = []\n",
        "\n",
        "        # Look for parallel files\n",
        "        for file in extract_dir.glob(\"*.en\"):\n",
        "            ta_file = file.with_suffix('.ta')\n",
        "            if ta_file.exists():\n",
        "                with open(file, 'r', encoding='utf-8') as f:\n",
        "                    en_lines = f.readlines()\n",
        "                with open(ta_file, 'r', encoding='utf-8') as f:\n",
        "                    ta_lines = f.readlines()\n",
        "\n",
        "                english_sentences.extend([line.strip() for line in en_lines])\n",
        "                tamil_sentences.extend([line.strip() for line in ta_lines])\n",
        "\n",
        "        print(f\"✅ Loaded {len(english_sentences)} sentence pairs from OPUS Subtitles\")\n",
        "        return english_sentences, tamil_sentences\n",
        "\n",
        "    def generate_small_sample(self):\n",
        "        \"\"\"Generate a small high-quality dataset for testing\"\"\"\n",
        "        # Extended high-quality sentence pairs\n",
        "        sample_data = [\n",
        "            # Basic greetings and politeness\n",
        "            (\"hello\", \"வணக்கம்\"),\n",
        "            (\"good morning\", \"காலை வணக்கம்\"),\n",
        "            (\"good afternoon\", \"மதிய வணக்கம்\"),\n",
        "            (\"good evening\", \"மாலை வணக்கம்\"),\n",
        "            (\"good night\", \"இரவு வணக்கம்\"),\n",
        "            (\"thank you\", \"நன்றி\"),\n",
        "            (\"thank you very much\", \"மிக்க நன்றி\"),\n",
        "            (\"you are welcome\", \"நல்ல வரவேற்பு\"),\n",
        "            (\"excuse me\", \"மன்னிக்கவும்\"),\n",
        "            (\"i am sorry\", \"நான் மன்னிக்க வேண்டும்\"),\n",
        "            (\"please\", \"தயவுசெய்து\"),\n",
        "            (\"goodbye\", \"விடைபெறுகிறேன்\"),\n",
        "            (\"see you later\", \"பிறகு சந்திப்போம்\"),\n",
        "            (\"see you tomorrow\", \"நாளை சந்திப்போம்\"),\n",
        "            (\"have a nice day\", \"நல்ல நாள் கழியட்டும்\"),\n",
        "            (\"take care\", \"கவனமாக இருங்கள்\"),\n",
        "\n",
        "            # Questions and responses\n",
        "            (\"how are you\", \"நீங்கள் எப்படி இருக்கிறீர்கள்\"),\n",
        "            (\"i am fine\", \"நான் நலமாக இருக்கிறேன்\"),\n",
        "            (\"i am good\", \"நான் நல்லவனாக இருக்கிறேன்\"),\n",
        "            (\"what is your name\", \"உங்கள் பெயர் என்ன\"),\n",
        "            (\"my name is john\", \"என் பெயர் ஜான்\"),\n",
        "            (\"where are you from\", \"நீங்கள் எங்கிருந்து வருகிறீர்கள்\"),\n",
        "            (\"i am from india\", \"நான் இந்தியாவிலிருந்து வருகிறேன்\"),\n",
        "            (\"i am from chennai\", \"நான் சென்னையிலிருந்து வருகிறேன்\"),\n",
        "            (\"how old are you\", \"உங்கள் வயது என்ன\"),\n",
        "            (\"i am twenty years old\", \"எனக்கு இருபது வயது\"),\n",
        "            (\"where do you live\", \"நீங்கள் எங்கே வசிக்கிறீர்கள்\"),\n",
        "            (\"i live in chennai\", \"நான் சென்னையில் வசிக்கிறேன்\"),\n",
        "            (\"what do you do\", \"நீங்கள் என்ன வேலை செய்கிறீர்கள்\"),\n",
        "            (\"i am a student\", \"நான் ஒரு மாணவன்\"),\n",
        "            (\"i am a teacher\", \"நான் ஒரு ஆசிரியர்\"),\n",
        "            (\"i am a doctor\", \"நான் ஒரு மருத்துவர்\"),\n",
        "            (\"i am an engineer\", \"நான் ஒரு பொறியாளர்\"),\n",
        "\n",
        "            # Language and communication\n",
        "            (\"do you speak tamil\", \"நீங்கள் தமிழ் பேசுவீர்களா\"),\n",
        "            (\"yes i speak tamil\", \"ஆம் நான் தமிழ் பேசுகிறேன்\"),\n",
        "            (\"i do not speak tamil\", \"நான் தமிழ் பேச மாட்டேன்\"),\n",
        "            (\"i am learning tamil\", \"நான் தமிழ் கற்றுக்கொண்டிருக்கிறேன்\"),\n",
        "            (\"can you speak english\", \"நீங்கள் ஆங்கிலம் பேச முடியுமா\"),\n",
        "            (\"i understand\", \"எனக்குப் புரிகிறது\"),\n",
        "            (\"i do not understand\", \"எனக்குப் புரியவில்லை\"),\n",
        "            (\"please speak slowly\", \"தயவுசெய்து மெதுவாக பேசுங்கள்\"),\n",
        "            (\"can you repeat\", \"நீங்கள் மீண்டும் சொல்ல முடியுமா\"),\n",
        "            (\"what does this mean\", \"இதன் அர்த்தம் என்ன\"),\n",
        "\n",
        "            # Help and directions\n",
        "            (\"can you help me\", \"நீங்கள் எனக்கு உதவ முடியுமா\"),\n",
        "            (\"i need help\", \"எனக்கு உதவி தேவை\"),\n",
        "            (\"where is the hospital\", \"மருத்துவமனை எங்கே உள்ளது\"),\n",
        "            (\"where is the market\", \"சந்தை எங்கே உள்ளது\"),\n",
        "            (\"where is the police station\", \"காவல் நிலையம் எங்கே உள்ளது\"),\n",
        "            (\"where is the bank\", \"வங்கி எங்கே உள்ளது\"),\n",
        "            (\"where is the restaurant\", \"உணவகம் எங்கே உள்ளது\"),\n",
        "            (\"go straight\", \"நேராகப் போங்கள்\"),\n",
        "            (\"turn left\", \"இடதுபுறம் திரும்பவும்\"),\n",
        "            (\"turn right\", \"வலதுபுறம் திரும்பவும்\"),\n",
        "            (\"it is near\", \"அது அருகில் உள்ளது\"),\n",
        "            (\"it is far\", \"அது தூரத்தில் உள்ளது\"),\n",
        "\n",
        "            # Shopping and money\n",
        "            (\"how much is this\", \"இது எவ்வளவு விலை\"),\n",
        "            (\"how much does this cost\", \"இது எவ்வளவு செலவாகும்\"),\n",
        "            (\"it is expensive\", \"இது விலை அதிகம்\"),\n",
        "            (\"it is cheap\", \"இது மலிவானது\"),\n",
        "            (\"i want to buy this\", \"நான் இதை வாங்க விரும்புகிறேன்\"),\n",
        "            (\"i will take this\", \"நான் இதை எடுத்துக்கொள்வேன்\"),\n",
        "            (\"give me the bill\", \"எனக்கு பில் கொடுங்கள்\"),\n",
        "            (\"do you accept credit cards\", \"நீங்கள் கிரெடிட் கார்டுகளை ஏற்கிறீர்களா\"),\n",
        "            (\"cash only\", \"பணம் மட்டும்\"),\n",
        "            (\"here is the money\", \"இதோ பணம்\"),\n",
        "\n",
        "            # Food and drink\n",
        "            (\"i am hungry\", \"எனக்கு பசிக்கிறது\"),\n",
        "            (\"i am thirsty\", \"எனக்கு தாகமாக இருக்கிறது\"),\n",
        "            (\"i want water\", \"எனக்கு தண்ணீர் வேண்டும்\"),\n",
        "            (\"i want food\", \"எனக்கு உணவு வேண்டும்\"),\n",
        "            (\"i like rice\", \"எனக்கு சாதம் பிடிக்கும்\"),\n",
        "            (\"this food is delicious\", \"இந்த உணவு சுவையாக உள்ளது\"),\n",
        "            (\"this food is spicy\", \"இந்த உணவு காரமாக உள்ளது\"),\n",
        "            (\"i want tea\", \"எனக்கு தேநீர் வேண்டும்\"),\n",
        "            (\"i want coffee\", \"எனக்கு காபி வேண்டும்\"),\n",
        "            (\"the bill please\", \"பில் தாருங்கள்\"),\n",
        "\n",
        "            # Time and weather\n",
        "            (\"what time is it\", \"என்ன நேரம்\"),\n",
        "            (\"it is ten o clock\", \"பத்து மணி\"),\n",
        "            (\"today is monday\", \"இன்று திங்கட்கிழமை\"),\n",
        "            (\"tomorrow is tuesday\", \"நாளை செவ்வாய்க்கிழமை\"),\n",
        "            (\"yesterday was sunday\", \"நேற்று ஞாயிற்றுக்கிழமை\"),\n",
        "            (\"the weather is good\", \"வானிலை நல்லாக உள்ளது\"),\n",
        "            (\"the weather is bad\", \"வானிலை மோசமாக உள்ளது\"),\n",
        "            (\"it is raining\", \"மழை பெய்கிறது\"),\n",
        "            (\"it is sunny\", \"வெயில் அடிக்கிறது\"),\n",
        "            (\"it is hot\", \"வெப்பமாக உள்ளது\"),\n",
        "            (\"it is cold\", \"குளிர்ச்சியாக உள்ளது\"),\n",
        "\n",
        "            # Family and relationships\n",
        "            (\"this is my family\", \"இது என் குடும்பம்\"),\n",
        "            (\"i have a brother\", \"எனக்கு ஒரு சகோதரன் உள்ளான்\"),\n",
        "            (\"i have a sister\", \"எனக்கு ஒரு சகோதரி உள்ளாள்\"),\n",
        "            (\"this is my mother\", \"இது என் அம்மா\"),\n",
        "            (\"this is my father\", \"இது என் அப்பா\"),\n",
        "            (\"she is my wife\", \"அவள் என் மனைவி\"),\n",
        "            (\"he is my husband\", \"அவர் என் கணவர்\"),\n",
        "            (\"we are friends\", \"நாங்கள் நண்பர்கள்\"),\n",
        "            (\"i love my family\", \"நான் என் குடும்பத்தை நேசிக்கிறேன்\"),\n",
        "            (\"i miss my family\", \"என் குடும்பத்தை இழக்கிறேன்\"),\n",
        "\n",
        "            # Emotions and feelings\n",
        "            (\"i am happy\", \"நான் மகிழ்ச்சியாக இருக்கிறேன்\"),\n",
        "            (\"i am sad\", \"நான் வருத்தமாக இருக்கிறேன்\"),\n",
        "            (\"i am angry\", \"நான் கோபமாக இருக்கிறேன்\"),\n",
        "            (\"i am tired\", \"நான் சோர்வாக இருக்கிறேன்\"),\n",
        "            (\"i am excited\", \"நான் உற்சாகமாக இருக்கிறேன்\"),\n",
        "            (\"i am worried\", \"நான் கவலைப்படுகிறேன்\"),\n",
        "            (\"i am scared\", \"நான் பயப்படுகிறேன்\"),\n",
        "            (\"i love you\", \"நான் உன்னை நேசிக்கிறேன்\"),\n",
        "            (\"i miss you\", \"நான் உன்னை இழக்கிறேன்\"),\n",
        "            (\"i care about you\", \"நான் உன்னைப் பற்றி அக்கரை கொள்கிறேன்\"),\n",
        "\n",
        "            # Daily activities\n",
        "            (\"i wake up early\", \"நான் சீக்கிரம் எழுந்திருக்கிறேன்\"),\n",
        "            (\"i go to work\", \"நான் வேலைக்குப் போகிறேன்\"),\n",
        "            (\"i am eating\", \"நான் சாப்பிடுகிறேன்\"),\n",
        "            (\"i am drinking\", \"நான் குடிக்கிறேன்\"),\n",
        "            (\"i am sleeping\", \"நான் தூங்குகிறேன்\"),\n",
        "            (\"i am working\", \"நான் வேலை செய்கிறேன்\"),\n",
        "            (\"i am studying\", \"நான் படிக்கிறேன்\"),\n",
        "            (\"i am reading\", \"நான் படிக்கிறேன்\"),\n",
        "            (\"i am writing\", \"நான் எழுதுகிறேன்\"),\n",
        "            (\"i am watching tv\", \"நான் தொலைக்காட்சி பார்க்கிறேன்\"),\n",
        "            (\"i am listening to music\", \"நான் இசை கேட்கிறேன்\"),\n",
        "            (\"i go to sleep\", \"நான் தூங்கப் போகிறேன்\"),\n",
        "\n",
        "            # Objects and possessions\n",
        "            (\"this is a book\", \"இது ஒரு புத்தகம்\"),\n",
        "            (\"this is a pen\", \"இது ஒரு பேனா\"),\n",
        "            (\"this is my phone\", \"இது என் தொலைபேசி\"),\n",
        "            (\"this is my car\", \"இது என் கார்\"),\n",
        "            (\"this is my house\", \"இது என் வீடு\"),\n",
        "            (\"i have a computer\", \"என்னிடம் ஒரு கணினி உள்ளது\"),\n",
        "            (\"i need a taxi\", \"எனக்கு ஒரு டாக்ஸி தேவை\"),\n",
        "            (\"where is my bag\", \"என் பை எங்கே\"),\n",
        "            (\"i lost my wallet\", \"நான் என் பணப்பையை இழந்தேன்\"),\n",
        "            (\"this is beautiful\", \"இது அழகானது\"),\n",
        "\n",
        "            # Travel and transportation\n",
        "            (\"i am going to chennai\", \"நான் சென்னைக்குப் போகிறேன்\"),\n",
        "            (\"when does the bus arrive\", \"பேருந்து எப்போது வரும்\"),\n",
        "            (\"where is the bus stop\", \"பேருந்து நிறுத்தம் எங்கே\"),\n",
        "            (\"i need a ticket\", \"எனக்கு ஒரு டிக்கெட் தேவை\"),\n",
        "            (\"how long does it take\", \"இது எவ்வளவு நேரம் ஆகும்\"),\n",
        "            (\"i am lost\", \"நான் வழி தவறிவிட்டேன்\"),\n",
        "            (\"can you show me the way\", \"நீங்கள் எனக்கு வழி காட்ட முடியுமா\"),\n",
        "            (\"i want to go home\", \"நான் வீட்டிற்கு செல்ல விரும்புகிறேன்\"),\n",
        "\n",
        "            # Health and medical\n",
        "            (\"i am sick\", \"நான் நோய்வாய்ப்பட்டிருக்கிறேன்\"),\n",
        "            (\"i have a headache\", \"எனக்கு தலைவலி\"),\n",
        "            (\"i have a fever\", \"எனக்கு காய்ச்சல்\"),\n",
        "            (\"i need a doctor\", \"எனக்கு ஒரு மருத்துவர் தேவை\"),\n",
        "            (\"where is the pharmacy\", \"மருந்தகம் எங்கே\"),\n",
        "            (\"i need medicine\", \"எனக்கு மருந்து தேவை\"),\n",
        "            (\"call an ambulance\", \"ஆம்புலன்ஸை அழைக்கவும்\"),\n",
        "            (\"i feel better\", \"நான் நன்றாக உணர்கிறேன்\"),\n",
        "\n",
        "            # Technology and communication\n",
        "            (\"my phone is not working\", \"என் போன் வேலை செய்யவில்லை\"),\n",
        "            (\"i need internet\", \"எனக்கு இணையம் தேவை\"),\n",
        "            (\"where is wifi\", \"வைஃபை எங்கே\"),\n",
        "            (\"can i use your phone\", \"நான் உங்கள் போனைப் பயன்படுத்த முடியுமா\"),\n",
        "            (\"send me a message\", \"எனக்கு ஒரு செய்தி அனுப்பவும்\"),\n",
        "            (\"what is your phone number\", \"உங்கள் போன் எண் என்ன\"),\n",
        "            (\"i will call you\", \"நான் உங்களை அழைப்பேன்\"),\n",
        "        ]\n",
        "\n",
        "        # Expand the dataset by creating variations\n",
        "        expanded_data = []\n",
        "        expanded_data.extend(sample_data)\n",
        "\n",
        "        # Add variations with different pronouns\n",
        "        pronoun_replacements = [\n",
        "            (\"i am\", \"you are\", \"நான்\", \"நீங்கள்\"),\n",
        "            (\"my\", \"your\", \"என்\", \"உங்கள்\"),\n",
        "            (\"me\", \"you\", \"என்னை\", \"உங்களை\")\n",
        "        ]\n",
        "\n",
        "        # Create variations (simplified approach)\n",
        "        for eng, tam in sample_data[:50]:  # Only for first 50 to avoid too much repetition\n",
        "            for old_eng, new_eng, old_tam, new_tam in pronoun_replacements:\n",
        "                if old_eng in eng:\n",
        "                    new_eng_sent = eng.replace(old_eng, new_eng)\n",
        "                    new_tam_sent = tam.replace(old_tam, new_tam)\n",
        "                    if new_eng_sent != eng:  # Only add if actually changed\n",
        "                        expanded_data.append((new_eng_sent, new_tam_sent))\n",
        "\n",
        "        # Add some longer sentences\n",
        "        longer_sentences = [\n",
        "            (\"i am very happy to meet you\", \"உங்களைச் சந்தித்ததில் நான் மிகவும் மகிழ்ச்சியடைகிறேன்\"),\n",
        "            (\"the food in this restaurant is very delicious\", \"இந்த உணவகத்தில் உள்ள உணவு மிகவும் சுவையாக உள்ளது\"),\n",
        "            (\"i want to learn tamil language properly\", \"நான் தமிழ் மொழியை சரியாக கற்றுக்கொள்ள விரும்புகிறேன்\"),\n",
        "            (\"can you please help me find my way to the airport\", \"தயவுசெய்து விமான நிலையத்திற்கு செல்லும் வழியைக் கண்டுபிடிக்க எனக்கு உதவ முடியுமா\"),\n",
        "            (\"i am looking forward to visiting chennai next month\", \"அடுத்த மாதம் சென்னையை பார்வையிட நான் ஆவலுடன் காத்திருக்கிறேன்\"),\n",
        "            (\"thank you very much for your kind help and support\", \"உங்கள் அன்பான உதவி மற்றும் ஆதரவிற்கு மிக்க நன்றி\"),\n",
        "            (\"i hope we can meet again in the near future\", \"எதிர்கால நேரத்தில் நாங்கள் மீண்டும் சந்திக்க முடியும் என்று நம்புகிறேன்\"),\n",
        "            (\"the weather today is very pleasant and sunny\", \"இன்றைய வானிலை மிகவும் இனிமையானது மற்றும் வெயிலாக உள்ளது\"),\n",
        "        ]\n",
        "\n",
        "        expanded_data.extend(longer_sentences)\n",
        "\n",
        "        # Repeat the entire dataset a few times to reach 1000+ examples\n",
        "        final_data = []\n",
        "        for _ in range(5):  # Repeat 5 times\n",
        "            final_data.extend(expanded_data)\n",
        "\n",
        "        # Shuffle and return\n",
        "        np.random.shuffle(final_data)\n",
        "        english_sentences = [pair[0] for pair in final_data]\n",
        "        tamil_sentences = [pair[1] for pair in final_data]\n",
        "\n",
        "        print(f\"✅ Generated {len(english_sentences)} high-quality sentence pairs\")\n",
        "        return english_sentences, tamil_sentences\n",
        "\n",
        "    def get_dataset(self, dataset_name):\n",
        "        \"\"\"Get specified dataset\"\"\"\n",
        "        if dataset_name not in self.datasets:\n",
        "            print(f\"❌ Unknown dataset: {dataset_name}\")\n",
        "            print(f\"Available datasets: {list(self.datasets.keys())}\")\n",
        "            return [], []\n",
        "\n",
        "        print(f\"📁 Loading dataset: {self.datasets[dataset_name]['name']}\")\n",
        "        print(f\"📝 Description: {self.datasets[dataset_name]['description']}\")\n",
        "\n",
        "        if dataset_name == \"ufal_v2\":\n",
        "            return self.download_ufal_v2()\n",
        "        elif dataset_name == \"nlpc_uom\":\n",
        "            return self.download_nlpc_uom()\n",
        "        elif dataset_name == \"opus_subtitles\":\n",
        "            return self.download_opus_subtitles()\n",
        "        elif dataset_name == \"small_sample\":\n",
        "            return self.generate_small_sample()\n",
        "        else:\n",
        "            return [], []\n",
        "\n",
        "    def list_datasets(self):\n",
        "        \"\"\"List all available datasets\"\"\"\n",
        "        print(\"📊 Available English-Tamil Datasets:\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        for key, info in self.datasets.items():\n",
        "            print(f\"🔹 {key}\")\n",
        "            print(f\"   Name: {info['name']}\")\n",
        "            print(f\"   Description: {info['description']}\")\n",
        "            print(f\"   Size: {info.get('size', 'Unknown')}\")\n",
        "            print(f\"   Format: {info['format']}\")\n",
        "            print()\n",
        "\n",
        "class EnglishTamilTranslator:\n",
        "    \"\"\"Complete English-Tamil translator with real datasets\"\"\"\n",
        "\n",
        "    def __init__(self, max_encoder_seq_length=25, max_decoder_seq_length=30):\n",
        "        self.max_encoder_seq_length = max_encoder_seq_length\n",
        "        self.max_decoder_seq_length = max_decoder_seq_length\n",
        "        self.eng_tokenizer = None\n",
        "        self.tamil_tokenizer = None\n",
        "        self.model = None\n",
        "        self.encoder_model = None\n",
        "        self.decoder_model = None\n",
        "        self.training_history = None\n",
        "        self.latent_dim = 512  # Store latent_dim as instance variable\n",
        "\n",
        "    def preprocess_text(self, text):\n",
        "        \"\"\"Clean and preprocess text\"\"\"\n",
        "        if not text or not isinstance(text, str):\n",
        "            return \"\"\n",
        "\n",
        "        # Convert to lowercase for English (keep Tamil as is)\n",
        "        if any(ord(char) > 127 for char in text):  # Tamil text\n",
        "            text = text.strip()\n",
        "        else:  # English text\n",
        "            text = text.lower().strip()\n",
        "\n",
        "        # Remove extra punctuation\n",
        "        text = re.sub(r'[^\\w\\s\\u0B80-\\u0BFF]', '', text)  # Keep Tamil Unicode range\n",
        "\n",
        "        # Remove extra spaces\n",
        "        text = ' '.join(text.split())\n",
        "        return text\n",
        "\n",
        "    def prepare_data_from_dataset(self, dataset_name, max_samples=None):\n",
        "        \"\"\"Prepare data from downloaded dataset\"\"\"\n",
        "        downloader = DatasetDownloader()\n",
        "        english_sentences, tamil_sentences = downloader.get_dataset(dataset_name)\n",
        "\n",
        "        if not english_sentences or not tamil_sentences:\n",
        "            print(\"❌ Failed to load dataset\")\n",
        "            return [], []\n",
        "\n",
        "        # Filter and clean sentences\n",
        "        cleaned_english = []\n",
        "        cleaned_tamil = []\n",
        "\n",
        "        for eng, tam in zip(english_sentences, tamil_sentences):\n",
        "            eng_clean = self.preprocess_text(eng)\n",
        "            tam_clean = self.preprocess_text(tam)\n",
        "\n",
        "            # Filter criteria\n",
        "            if (eng_clean and tam_clean and\n",
        "                1 <= len(eng_clean.split()) <= 20 and\n",
        "                1 <= len(tam_clean.split()) <= 25 and\n",
        "                len(eng_clean) > 3 and len(tam_clean) > 3):\n",
        "\n",
        "                cleaned_english.append(eng_clean)\n",
        "                cleaned_tamil.append(f\"startseq {tam_clean} endseq\")\n",
        "\n",
        "        # Limit samples if specified\n",
        "        if max_samples and len(cleaned_english) > max_samples:\n",
        "            indices = np.random.choice(len(cleaned_english), max_samples, replace=False)\n",
        "            cleaned_english = [cleaned_english[i] for i in indices]\n",
        "            cleaned_tamil = [cleaned_tamil[i] for i in indices]\n",
        "\n",
        "        print(f\"✅ Prepared {len(cleaned_english)} clean sentence pairs\")\n",
        "        return cleaned_english, cleaned_tamil\n",
        "\n",
        "    def create_tokenizers(self, english_sentences, tamil_sentences):\n",
        "        \"\"\"Create tokenizers\"\"\"\n",
        "        print(\"🔤 Creating tokenizers...\")\n",
        "\n",
        "        # English tokenizer\n",
        "        self.eng_tokenizer = Tokenizer(num_words=8000, filters='', lower=True)\n",
        "        self.eng_tokenizer.fit_on_texts(english_sentences)\n",
        "\n",
        "        # Tamil tokenizer\n",
        "        self.tamil_tokenizer = Tokenizer(num_words=12000, filters='', lower=False)\n",
        "        self.tamil_tokenizer.fit_on_texts(tamil_sentences)\n",
        "\n",
        "        # Get vocabulary sizes\n",
        "        self.eng_vocab_size = len(self.eng_tokenizer.word_index) + 1\n",
        "        self.tamil_vocab_size = len(self.tamil_tokenizer.word_index) + 1\n",
        "\n",
        "        print(f\"📈 English vocabulary: {self.eng_vocab_size}\")\n",
        "        print(f\"📈 Tamil vocabulary: {self.tamil_vocab_size}\")\n",
        "\n",
        "        return self.eng_tokenizer, self.tamil_tokenizer\n",
        "\n",
        "    def encode_sequences(self, english_sentences, tamil_sentences):\n",
        "        \"\"\"Convert sentences to sequences\"\"\"\n",
        "        print(\"🔢 Encoding sequences...\")\n",
        "\n",
        "        # Convert to sequences\n",
        "        eng_sequences = self.eng_tokenizer.texts_to_sequences(english_sentences)\n",
        "        tamil_sequences = self.tamil_tokenizer.texts_to_sequences(tamil_sentences)\n",
        "\n",
        "        # Pad sequences\n",
        "        encoder_input_data = pad_sequences(eng_sequences,\n",
        "                                         maxlen=self.max_encoder_seq_length,\n",
        "                                         padding='post')\n",
        "\n",
        "        decoder_input_data = pad_sequences(tamil_sequences,\n",
        "                                         maxlen=self.max_decoder_seq_length,\n",
        "                                         padding='post')\n",
        "\n",
        "        # Create decoder target data\n",
        "        decoder_target_sequences = []\n",
        "        for seq in tamil_sequences:\n",
        "            target_seq = seq[1:] + [0]  # Remove startseq, add padding\n",
        "            decoder_target_sequences.append(target_seq)\n",
        "\n",
        "        decoder_target_data = pad_sequences(decoder_target_sequences,\n",
        "                                          maxlen=self.max_decoder_seq_length,\n",
        "                                          padding='post')\n",
        "\n",
        "        # Convert to categorical\n",
        "        decoder_target_data_categorical = to_categorical(decoder_target_data,\n",
        "                                                       num_classes=self.tamil_vocab_size)\n",
        "\n",
        "        print(f\"📐 Shapes: Encoder {encoder_input_data.shape}, \"\n",
        "              f\"Decoder input {decoder_input_data.shape}, \"\n",
        "              f\"Decoder target {decoder_target_data_categorical.shape}\")\n",
        "\n",
        "        return encoder_input_data, decoder_input_data, decoder_target_data_categorical\n",
        "\n",
        "    def build_model(self, embedding_dim=256, latent_dim=512):\n",
        "        \"\"\"Build seq2seq model\"\"\"\n",
        "        print(\"🏗️ Building seq2seq model...\")\n",
        "\n",
        "        # Store latent_dim\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        # Encoder\n",
        "        encoder_inputs = Input(shape=(None,), name='encoder_inputs')\n",
        "        encoder_embedding = Embedding(self.eng_vocab_size, embedding_dim,\n",
        "                                    mask_zero=True, name='encoder_embedding')\n",
        "        encoder_embedded = encoder_embedding(encoder_inputs)\n",
        "        encoder_embedded = Dropout(0.3)(encoder_embedded)\n",
        "\n",
        "        encoder_lstm = LSTM(latent_dim, return_state=True, dropout=0.3,\n",
        "                          recurrent_dropout=0.3, name='encoder_lstm')\n",
        "        encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedded)\n",
        "        encoder_states = [state_h, state_c]\n",
        "\n",
        "        # Decoder\n",
        "        decoder_inputs = Input(shape=(None,), name='decoder_inputs')\n",
        "        decoder_embedding = Embedding(self.tamil_vocab_size, embedding_dim,\n",
        "                                    mask_zero=True, name='decoder_embedding')\n",
        "        decoder_embedded = decoder_embedding(decoder_inputs)\n",
        "        decoder_embedded = Dropout(0.3)(decoder_embedded)\n",
        "\n",
        "        decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,\n",
        "                          dropout=0.3, recurrent_dropout=0.3, name='decoder_lstm')\n",
        "        decoder_outputs, _, _ = decoder_lstm(decoder_embedded, initial_state=encoder_states)\n",
        "\n",
        "        decoder_dense = Dense(self.tamil_vocab_size, activation='softmax', name='decoder_dense')\n",
        "        decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "        # Create model\n",
        "        self.model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "        # Compile\n",
        "        optimizer = Adam(learning_rate=0.001)\n",
        "        self.model.compile(optimizer=optimizer,\n",
        "                          loss='categorical_crossentropy',\n",
        "                          metrics=['accuracy'])\n",
        "\n",
        "        print(f\"✅ Model created with {self.model.count_params():,} parameters\")\n",
        "        self.model.summary()\n",
        "\n",
        "        return self.model\n",
        "\n",
        "    def train_model(self, encoder_input_data, decoder_input_data, decoder_target_data,\n",
        "                   epochs=50, batch_size=64, validation_split=0.2):\n",
        "        \"\"\"Train the model\"\"\"\n",
        "        print(f\"🎯 Training for {epochs} epochs...\")\n",
        "\n",
        "        callbacks = [\n",
        "            ModelCheckpoint('best_translation_model.h5', monitor='val_loss',\n",
        "                          save_best_only=True, verbose=1),\n",
        "            EarlyStopping(monitor='val_loss', patience=10, verbose=1),\n",
        "            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5,\n",
        "                            min_lr=1e-6, verbose=1)\n",
        "        ]\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        self.training_history = self.model.fit(\n",
        "            [encoder_input_data, decoder_input_data],\n",
        "            decoder_target_data,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            validation_split=validation_split,\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        training_time = time.time() - start_time\n",
        "        print(f\"✅ Training completed in {training_time:.2f} seconds\")\n",
        "\n",
        "        return self.training_history\n",
        "\n",
        "    def build_inference_models(self):\n",
        "        \"\"\"Build inference models\"\"\"\n",
        "        print(\"🔧 Building inference models...\")\n",
        "\n",
        "        # Encoder model\n",
        "        encoder_inputs = self.model.input[0]  # encoder input\n",
        "        encoder_lstm = None\n",
        "\n",
        "        # Find the encoder LSTM layer\n",
        "        for layer in self.model.layers:\n",
        "            if layer.name == 'encoder_lstm':\n",
        "                encoder_lstm = layer\n",
        "                break\n",
        "\n",
        "        if encoder_lstm is None:\n",
        "            raise ValueError(\"Encoder LSTM layer not found\")\n",
        "\n",
        "        # Get encoder outputs and states\n",
        "        encoder_outputs, state_h_enc, state_c_enc = encoder_lstm.output\n",
        "        encoder_states = [state_h_enc, state_c_enc]\n",
        "        self.encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "        # Decoder model for inference\n",
        "        decoder_inputs = Input(shape=(None,), name='decoder_input_inference')\n",
        "        decoder_state_input_h = Input(shape=(self.latent_dim,), name='decoder_state_h')\n",
        "        decoder_state_input_c = Input(shape=(self.latent_dim,), name='decoder_state_c')\n",
        "        decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "        # Get decoder layers\n",
        "        decoder_embedding = None\n",
        "        decoder_lstm = None\n",
        "        decoder_dense = None\n",
        "\n",
        "        for layer in self.model.layers:\n",
        "            if layer.name == 'decoder_embedding':\n",
        "                decoder_embedding = layer\n",
        "            elif layer.name == 'decoder_lstm':\n",
        "                decoder_lstm = layer\n",
        "            elif layer.name == 'decoder_dense':\n",
        "                decoder_dense = layer\n",
        "\n",
        "        if None in [decoder_embedding, decoder_lstm, decoder_dense]:\n",
        "            raise ValueError(\"One or more decoder layers not found\")\n",
        "\n",
        "        # Build decoder inference model\n",
        "        decoder_embedded = decoder_embedding(decoder_inputs)\n",
        "        decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "            decoder_embedded, initial_state=decoder_states_inputs)\n",
        "        decoder_states = [state_h_dec, state_c_dec]\n",
        "        decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "        self.decoder_model = Model([decoder_inputs] + decoder_states_inputs,\n",
        "                                 [decoder_outputs] + decoder_states)\n",
        "\n",
        "        print(\"✅ Inference models ready\")\n",
        "\n",
        "    def translate_sentence(self, input_sentence, max_output_length=None):\n",
        "        \"\"\"Translate a sentence\"\"\"\n",
        "        if max_output_length is None:\n",
        "            max_output_length = self.max_decoder_seq_length\n",
        "\n",
        "        # Preprocess\n",
        "        input_sentence = self.preprocess_text(input_sentence)\n",
        "        if not input_sentence:\n",
        "            return \"Invalid input\"\n",
        "\n",
        "        # Encode\n",
        "        input_seq = self.eng_tokenizer.texts_to_sequences([input_sentence])\n",
        "        if not input_seq or not input_seq[0]:\n",
        "            return \"Unable to tokenize input\"\n",
        "\n",
        "        input_seq = pad_sequences(input_seq, maxlen=self.max_encoder_seq_length, padding='post')\n",
        "\n",
        "        # Get encoder states\n",
        "        states_value = self.encoder_model.predict(input_seq, verbose=0)\n",
        "\n",
        "        # Initialize target sequence\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        start_token = self.tamil_tokenizer.word_index.get('startseq', 1)\n",
        "        target_seq[0, 0] = start_token\n",
        "\n",
        "        # Generate translation\n",
        "        decoded_sentence = ''\n",
        "\n",
        "        for _ in range(max_output_length):\n",
        "            output_tokens, h, c = self.decoder_model.predict([target_seq] + states_value, verbose=0)\n",
        "\n",
        "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "\n",
        "            # Convert to word\n",
        "            sampled_word = None\n",
        "            for word, index in self.tamil_tokenizer.word_index.items():\n",
        "                if index == sampled_token_index:\n",
        "                    sampled_word = word\n",
        "                    break\n",
        "\n",
        "            if sampled_word == 'endseq' or sampled_word is None:\n",
        "                break\n",
        "\n",
        "            if sampled_word != 'startseq':\n",
        "                decoded_sentence += sampled_word + ' '\n",
        "\n",
        "            # Update for next prediction\n",
        "            target_seq = np.zeros((1, 1))\n",
        "            target_seq[0, 0] = sampled_token_index\n",
        "            states_value = [h, c]\n",
        "\n",
        "        return decoded_sentence.strip()\n",
        "\n",
        "    def save_model(self, model_dir='translation_model'):\n",
        "        \"\"\"Save complete model\"\"\"\n",
        "        print(f\"💾 Saving model to {model_dir}...\")\n",
        "\n",
        "        os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "        # Save main model\n",
        "        self.model.save(os.path.join(model_dir, 'seq2seq_model.h5'))\n",
        "\n",
        "        # Save tokenizers\n",
        "        with open(os.path.join(model_dir, 'eng_tokenizer.pkl'), 'wb') as f:\n",
        "            pickle.dump(self.eng_tokenizer, f)\n",
        "\n",
        "        with open(os.path.join(model_dir, 'tamil_tokenizer.pkl'), 'wb') as f:\n",
        "            pickle.dump(self.tamil_tokenizer, f)\n",
        "\n",
        "        # Save config\n",
        "        config = {\n",
        "            'max_encoder_seq_length': self.max_encoder_seq_length,\n",
        "            'max_decoder_seq_length': self.max_decoder_seq_length,\n",
        "            'eng_vocab_size': self.eng_vocab_size,\n",
        "            'tamil_vocab_size': self.tamil_vocab_size,\n",
        "            'latent_dim': self.latent_dim\n",
        "        }\n",
        "\n",
        "        with open(os.path.join(model_dir, 'config.json'), 'w') as f:\n",
        "            json.dump(config, f, indent=2)\n",
        "\n",
        "        print(\"✅ Model saved successfully!\")\n",
        "\n",
        "    def load_model(self, model_dir='translation_model'):\n",
        "        \"\"\"Load saved model\"\"\"\n",
        "        print(f\"📂 Loading model from {model_dir}...\")\n",
        "\n",
        "        # Load main model\n",
        "        self.model = load_model(os.path.join(model_dir, 'seq2seq_model.h5'))\n",
        "\n",
        "        # Load tokenizers\n",
        "        with open(os.path.join(model_dir, 'eng_tokenizer.pkl'), 'rb') as f:\n",
        "            self.eng_tokenizer = pickle.load(f)\n",
        "\n",
        "        with open(os.path.join(model_dir, 'tamil_tokenizer.pkl'), 'rb') as f:\n",
        "            self.tamil_tokenizer = pickle.load(f)\n",
        "\n",
        "        # Load config\n",
        "        with open(os.path.join(model_dir, 'config.json'), 'r') as f:\n",
        "            config = json.load(f)\n",
        "\n",
        "        self.max_encoder_seq_length = config['max_encoder_seq_length']\n",
        "        self.max_decoder_seq_length = config['max_decoder_seq_length']\n",
        "        self.eng_vocab_size = config['eng_vocab_size']\n",
        "        self.tamil_vocab_size = config['tamil_vocab_size']\n",
        "        self.latent_dim = config.get('latent_dim', 512)  # Default to 512 if not found\n",
        "\n",
        "        # Build inference models\n",
        "        self.build_inference_models()\n",
        "\n",
        "        print(\"✅ Model loaded successfully!\")\n",
        "\n",
        "def plot_training_history(history):\n",
        "    \"\"\"Plot training history\"\"\"\n",
        "    if not history:\n",
        "        return\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    # Loss\n",
        "    ax1.plot(history.history['loss'], label='Training Loss', color='blue')\n",
        "    ax1.plot(history.history['val_loss'], label='Validation Loss', color='red')\n",
        "    ax1.set_title('Model Loss')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # Accuracy\n",
        "    ax2.plot(history.history['accuracy'], label='Training Accuracy', color='blue')\n",
        "    ax2.plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')\n",
        "    ax2.set_title('Model Accuracy')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Accuracy')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def evaluate_model(translator, test_pairs):\n",
        "    \"\"\"Evaluate model performance\"\"\"\n",
        "    print(\"🧪 Evaluating model...\")\n",
        "\n",
        "    correct_translations = 0\n",
        "    total_word_accuracy = 0\n",
        "\n",
        "    for i, (eng, expected_tamil) in enumerate(test_pairs):\n",
        "        predicted_tamil = translator.translate_sentence(eng)\n",
        "\n",
        "        # Clean expected output\n",
        "        expected_clean = expected_tamil.replace('startseq', '').replace('endseq', '').strip()\n",
        "\n",
        "        # Check exact match\n",
        "        if predicted_tamil.lower().strip() == expected_clean.lower().strip():\n",
        "            correct_translations += 1\n",
        "\n",
        "        # Word-level accuracy\n",
        "        expected_words = set(expected_clean.lower().split())\n",
        "        predicted_words = set(predicted_tamil.lower().split())\n",
        "\n",
        "        if expected_words:\n",
        "            word_accuracy = len(expected_words.intersection(predicted_words)) / len(expected_words)\n",
        "            total_word_accuracy += word_accuracy\n",
        "\n",
        "        # Show first 10 examples\n",
        "        if i < 10:\n",
        "            print(f\"{i+1:2d}. EN: {eng}\")\n",
        "            print(f\"    Expected: {expected_clean}\")\n",
        "            print(f\"    Predicted: {predicted_tamil}\")\n",
        "            print(f\"    Word Acc: {word_accuracy:.3f}\")\n",
        "            print()\n",
        "\n",
        "    exact_accuracy = correct_translations / len(test_pairs)\n",
        "    avg_word_accuracy = total_word_accuracy / len(test_pairs)\n",
        "\n",
        "    print(f\"📊 Results:\")\n",
        "    print(f\"   Exact matches: {correct_translations}/{len(test_pairs)} ({exact_accuracy:.1%})\")\n",
        "    print(f\"   Average word accuracy: {avg_word_accuracy:.3f}\")\n",
        "\n",
        "    return exact_accuracy, avg_word_accuracy\n",
        "\n",
        "def interactive_translation(translator):\n",
        "    \"\"\"Interactive translation session\"\"\"\n",
        "    print(\"\\n🎮 Interactive Translation Session\")\n",
        "    print(\"Commands: 'test' for examples, 'quit' to exit\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    test_examples = [\n",
        "        \"hello friend\", \"thank you very much\", \"how are you today\",\n",
        "        \"i am learning tamil\", \"where is the hospital\", \"i need help\",\n",
        "        \"the weather is good\", \"i love my family\", \"good morning everyone\"\n",
        "    ]\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            user_input = input(\"\\n🔤 English: \").strip()\n",
        "\n",
        "            if user_input.lower() == 'quit':\n",
        "                print(\"👋 Goodbye!\")\n",
        "                break\n",
        "            elif user_input.lower() == 'test':\n",
        "                print(\"\\n🧪 Test Examples:\")\n",
        "                for example in test_examples:\n",
        "                    translation = translator.translate_sentence(example)\n",
        "                    print(f\"  {example} → {translation}\")\n",
        "                continue\n",
        "            elif user_input:\n",
        "                translation = translator.translate_sentence(user_input)\n",
        "                print(f\"🌟 Tamil: {translation}\")\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n👋 Goodbye!\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error: {e}\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main training function\"\"\"\n",
        "    print(\"🌟 English-Tamil Neural Machine Translation with Real Datasets\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Show available datasets\n",
        "    downloader = DatasetDownloader()\n",
        "    downloader.list_datasets()\n",
        "\n",
        "    # Choose dataset\n",
        "    print(\"📋 Select a dataset:\")\n",
        "    print(\"1. ufal_v2 - Large corpus (530k+ pairs) - Best quality\")\n",
        "    print(\"2. small_sample - Generated corpus (1k+ pairs) - Quick testing\")\n",
        "    print(\"3. nlpc_uom - Government corpus (22k+ pairs) - Medium size\")\n",
        "    print(\"4. opus_subtitles - Movie subtitles - Variable size\")\n",
        "\n",
        "    while True:\n",
        "        choice = input(\"\\n🔢 Enter choice (1-4): \").strip()\n",
        "        if choice == \"1\":\n",
        "            dataset_name = \"ufal_v2\"\n",
        "            max_samples = 50000  # Limit for faster training\n",
        "            break\n",
        "        elif choice == \"2\":\n",
        "            dataset_name = \"small_sample\"\n",
        "            max_samples = None\n",
        "            break\n",
        "        elif choice == \"3\":\n",
        "            dataset_name = \"nlpc_uom\"\n",
        "            max_samples = None\n",
        "            break\n",
        "        elif choice == \"4\":\n",
        "            dataset_name = \"opus_subtitles\"\n",
        "            max_samples = 20000\n",
        "            break\n",
        "        else:\n",
        "            print(\"❌ Invalid choice. Please enter 1-4.\")\n",
        "\n",
        "    # Initialize translator\n",
        "    translator = EnglishTamilTranslator()\n",
        "\n",
        "    # Prepare data\n",
        "    english_sentences, tamil_sentences = translator.prepare_data_from_dataset(\n",
        "        dataset_name, max_samples)\n",
        "\n",
        "    if not english_sentences:\n",
        "        print(\"❌ No data loaded. Exiting.\")\n",
        "        return\n",
        "\n",
        "    # Create tokenizers\n",
        "    translator.create_tokenizers(english_sentences, tamil_sentences)\n",
        "\n",
        "    # Encode sequences\n",
        "    encoder_input_data, decoder_input_data, decoder_target_data = translator.encode_sequences(\n",
        "        english_sentences, tamil_sentences)\n",
        "\n",
        "    # Build model\n",
        "    translator.build_model()\n",
        "\n",
        "    # Train model\n",
        "    epochs = 30 if dataset_name == \"small_sample\" else 50\n",
        "    batch_size = 32 if dataset_name == \"small_sample\" else 64\n",
        "\n",
        "    history = translator.train_model(\n",
        "        encoder_input_data, decoder_input_data, decoder_target_data,\n",
        "        epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "    # Build inference models\n",
        "    translator.build_inference_models()\n",
        "\n",
        "    # Save model\n",
        "    translator.save_model()\n",
        "\n",
        "    # Plot training history\n",
        "    plot_training_history(history)\n",
        "\n",
        "    # Evaluate\n",
        "    test_pairs = [\n",
        "        (\"hello\", \"வணக்கம்\"),\n",
        "        (\"thank you\", \"நன்றி\"),\n",
        "        (\"how are you\", \"நீங்கள் எப்படி இருக்கிறீர்கள்\"),\n",
        "        (\"i am fine\", \"நான் நலமாக இருக்கிறேன்\"),\n",
        "        (\"good morning\", \"காலை வணக்கம்\"),\n",
        "        (\"where is hospital\", \"மருத்துவமனை எங்கே\"),\n",
        "        (\"i need help\", \"எனக்கு உதவி தேவை\"),\n",
        "        (\"i love you\", \"நான் உன்னை நேசிக்கிறேன்\")\n",
        "    ]\n",
        "\n",
        "    evaluate_model(translator, test_pairs)\n",
        "\n",
        "    # Interactive session\n",
        "    interactive_translation(translator)\n",
        "\n",
        "def load_and_test():\n",
        "    \"\"\"Load saved model and test\"\"\"\n",
        "    try:\n",
        "        translator = EnglishTamilTranslator()\n",
        "        translator.load_model()\n",
        "\n",
        "        print(\"✅ Model loaded successfully!\")\n",
        "        interactive_translation(translator)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading model: {e}\")\n",
        "        print(\"Please train a model first using option 1.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"🌟 English-Tamil Neural Machine Translation System\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Options:\")\n",
        "    print(\"1. 🎯 Train new model with real datasets\")\n",
        "    print(\"2. 📂 Load saved model and test\")\n",
        "    print(\"3. 📊 Show available datasets\")\n",
        "\n",
        "    while True:\n",
        "        choice = input(\"\\n🔢 Enter choice (1-3): \").strip()\n",
        "\n",
        "        if choice == \"1\":\n",
        "            main()\n",
        "            break\n",
        "        elif choice == \"2\":\n",
        "            load_and_test()\n",
        "            break\n",
        "        elif choice == \"3\":\n",
        "            downloader = DatasetDownloader()\n",
        "            downloader.list_datasets()\n",
        "            continue\n",
        "        else:\n",
        "            print(\"❌ Invalid choice. Please enter 1, 2, or 3.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1QexKSB_buVv",
        "outputId": "a747717a-ecb9-491a-fc3f-7f82141de4e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🌟 English-Tamil Neural Machine Translation System\n",
            "============================================================\n",
            "Options:\n",
            "1. 🎯 Train new model with real datasets\n",
            "2. 📂 Load saved model and test\n",
            "3. 📊 Show available datasets\n",
            "🌟 English-Tamil Neural Machine Translation with Real Datasets\n",
            "======================================================================\n",
            "📊 Available English-Tamil Datasets:\n",
            "============================================================\n",
            "🔹 ufal_v2\n",
            "   Name: UFAL English-Tamil Parallel Corpus v2\n",
            "   Description: 530k+ sentence pairs from Bible, cinema, and news domains\n",
            "   Size: ~25MB\n",
            "   Format: tar.gz\n",
            "\n",
            "🔹 nlpc_uom\n",
            "   Name: NLPC-UOM English-Tamil Parallel Corpus\n",
            "   Description: 22k+ glossary + 9k+ corpus from government resources\n",
            "   Size: ~5MB\n",
            "   Format: parquet\n",
            "\n",
            "🔹 opus_subtitles\n",
            "   Name: OPUS OpenSubtitles English-Tamil\n",
            "   Description: Movie subtitles parallel corpus\n",
            "   Size: ~10MB\n",
            "   Format: zip\n",
            "\n",
            "🔹 small_sample\n",
            "   Name: Small Sample Dataset (Generated)\n",
            "   Description: 1000+ high-quality sentence pairs for quick testing\n",
            "   Size: ~1MB\n",
            "   Format: generated\n",
            "\n",
            "📋 Select a dataset:\n",
            "1. ufal_v2 - Large corpus (530k+ pairs) - Best quality\n",
            "2. small_sample - Generated corpus (1k+ pairs) - Quick testing\n",
            "3. nlpc_uom - Government corpus (22k+ pairs) - Medium size\n",
            "4. opus_subtitles - Movie subtitles - Variable size\n",
            "📁 Loading dataset: Small Sample Dataset (Generated)\n",
            "📝 Description: 1000+ high-quality sentence pairs for quick testing\n",
            "✅ Generated 885 high-quality sentence pairs\n",
            "✅ Prepared 885 clean sentence pairs\n",
            "🔤 Creating tokenizers...\n",
            "📈 English vocabulary: 219\n",
            "📈 Tamil vocabulary: 258\n",
            "🔢 Encoding sequences...\n",
            "📐 Shapes: Encoder (885, 25), Decoder input (885, 30), Decoder target (885, 30, 258)\n",
            "🏗️ Building seq2seq model...\n",
            "✅ Model created with 3,404,290 parameters\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">56,064</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_embeddin… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_4         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ decoder_embeddin… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      │            │ not_equal_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_dense       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">132,354</span> │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │     \u001b[38;5;34m56,064\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │     \u001b[38;5;34m66,048\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ encoder_embeddin… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_4         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ decoder_embeddin… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),     │  \u001b[38;5;34m1,574,912\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),      │            │ not_equal_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │  \u001b[38;5;34m1,574,912\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m512\u001b[0m)]             │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_dense       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m258\u001b[0m) │    \u001b[38;5;34m132,354\u001b[0m │ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,404,290</span> (12.99 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,404,290\u001b[0m (12.99 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,404,290</span> (12.99 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,404,290\u001b[0m (12.99 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎯 Training for 30 epochs...\n",
            "Epoch 1/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.5948 - loss: 5.0414\n",
            "Epoch 1: val_loss improved from inf to 3.54527, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 328ms/step - accuracy: 0.5955 - loss: 5.0178 - val_accuracy: 0.9060 - val_loss: 3.5453 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.8247 - loss: 3.3863\n",
            "Epoch 2: val_loss improved from 3.54527 to 3.07401, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 216ms/step - accuracy: 0.8223 - loss: 3.3824 - val_accuracy: 0.1367 - val_loss: 3.0740 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.0962 - loss: 2.9420\n",
            "Epoch 3: val_loss improved from 3.07401 to 2.76452, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 223ms/step - accuracy: 0.0958 - loss: 2.9400 - val_accuracy: 0.0864 - val_loss: 2.7645 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.0836 - loss: 2.6135\n",
            "Epoch 4: val_loss improved from 2.76452 to 2.48027, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 220ms/step - accuracy: 0.0836 - loss: 2.6115 - val_accuracy: 0.0913 - val_loss: 2.4803 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.0893 - loss: 2.2548\n",
            "Epoch 5: val_loss improved from 2.48027 to 2.08706, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 241ms/step - accuracy: 0.0893 - loss: 2.2510 - val_accuracy: 0.0944 - val_loss: 2.0871 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.0953 - loss: 1.8258\n",
            "Epoch 6: val_loss improved from 2.08706 to 1.67998, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 241ms/step - accuracy: 0.0955 - loss: 1.8221 - val_accuracy: 0.1019 - val_loss: 1.6800 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.1047 - loss: 1.4588\n",
            "Epoch 7: val_loss improved from 1.67998 to 1.31196, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 200ms/step - accuracy: 0.1049 - loss: 1.4557 - val_accuracy: 0.1126 - val_loss: 1.3120 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.1129 - loss: 1.1470\n",
            "Epoch 8: val_loss improved from 1.31196 to 0.99871, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 230ms/step - accuracy: 0.1131 - loss: 1.1442 - val_accuracy: 0.1224 - val_loss: 0.9987 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.1241 - loss: 0.8929\n",
            "Epoch 9: val_loss improved from 0.99871 to 0.76509, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 246ms/step - accuracy: 0.1243 - loss: 0.8910 - val_accuracy: 0.1367 - val_loss: 0.7651 - learning_rate: 0.0010\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.1352 - loss: 0.6924\n",
            "Epoch 10: val_loss improved from 0.76509 to 0.57775, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 219ms/step - accuracy: 0.1353 - loss: 0.6910 - val_accuracy: 0.1441 - val_loss: 0.5777 - learning_rate: 0.0010\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.1432 - loss: 0.5498\n",
            "Epoch 11: val_loss improved from 0.57775 to 0.46260, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 203ms/step - accuracy: 0.1433 - loss: 0.5488 - val_accuracy: 0.1486 - val_loss: 0.4626 - learning_rate: 0.0010\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.1489 - loss: 0.4308\n",
            "Epoch 12: val_loss improved from 0.46260 to 0.34717, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 198ms/step - accuracy: 0.1490 - loss: 0.4300 - val_accuracy: 0.1544 - val_loss: 0.3472 - learning_rate: 0.0010\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.1527 - loss: 0.3469\n",
            "Epoch 13: val_loss improved from 0.34717 to 0.27360, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 236ms/step - accuracy: 0.1528 - loss: 0.3463 - val_accuracy: 0.1576 - val_loss: 0.2736 - learning_rate: 0.0010\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.1542 - loss: 0.2808\n",
            "Epoch 14: val_loss improved from 0.27360 to 0.21394, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 249ms/step - accuracy: 0.1543 - loss: 0.2803 - val_accuracy: 0.1621 - val_loss: 0.2139 - learning_rate: 0.0010\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.1556 - loss: 0.2353\n",
            "Epoch 15: val_loss improved from 0.21394 to 0.18174, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 197ms/step - accuracy: 0.1557 - loss: 0.2352 - val_accuracy: 0.1623 - val_loss: 0.1817 - learning_rate: 0.0010\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.1577 - loss: 0.2011\n",
            "Epoch 16: val_loss improved from 0.18174 to 0.14239, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 280ms/step - accuracy: 0.1578 - loss: 0.2009 - val_accuracy: 0.1652 - val_loss: 0.1424 - learning_rate: 0.0010\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.1601 - loss: 0.1638\n",
            "Epoch 17: val_loss improved from 0.14239 to 0.12011, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 239ms/step - accuracy: 0.1602 - loss: 0.1637 - val_accuracy: 0.1652 - val_loss: 0.1201 - learning_rate: 0.0010\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.1611 - loss: 0.1358\n",
            "Epoch 18: val_loss improved from 0.12011 to 0.09354, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 194ms/step - accuracy: 0.1612 - loss: 0.1357 - val_accuracy: 0.1657 - val_loss: 0.0935 - learning_rate: 0.0010\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.1617 - loss: 0.1158\n",
            "Epoch 19: val_loss improved from 0.09354 to 0.07907, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 215ms/step - accuracy: 0.1618 - loss: 0.1158 - val_accuracy: 0.1669 - val_loss: 0.0791 - learning_rate: 0.0010\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.1636 - loss: 0.0916\n",
            "Epoch 20: val_loss improved from 0.07907 to 0.06216, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 190ms/step - accuracy: 0.1637 - loss: 0.0915 - val_accuracy: 0.1680 - val_loss: 0.0622 - learning_rate: 0.0010\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.1632 - loss: 0.0812\n",
            "Epoch 21: val_loss improved from 0.06216 to 0.05602, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 239ms/step - accuracy: 0.1633 - loss: 0.0811 - val_accuracy: 0.1685 - val_loss: 0.0560 - learning_rate: 0.0010\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.1636 - loss: 0.0733\n",
            "Epoch 22: val_loss improved from 0.05602 to 0.04372, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 213ms/step - accuracy: 0.1637 - loss: 0.0731 - val_accuracy: 0.1687 - val_loss: 0.0437 - learning_rate: 0.0010\n",
            "Epoch 23/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.1648 - loss: 0.0547\n",
            "Epoch 23: val_loss improved from 0.04372 to 0.03616, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 206ms/step - accuracy: 0.1648 - loss: 0.0546 - val_accuracy: 0.1691 - val_loss: 0.0362 - learning_rate: 0.0010\n",
            "Epoch 24/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.1644 - loss: 0.0515\n",
            "Epoch 24: val_loss improved from 0.03616 to 0.02836, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 196ms/step - accuracy: 0.1645 - loss: 0.0514 - val_accuracy: 0.1691 - val_loss: 0.0284 - learning_rate: 0.0010\n",
            "Epoch 25/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.1651 - loss: 0.0404\n",
            "Epoch 25: val_loss improved from 0.02836 to 0.02301, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 244ms/step - accuracy: 0.1652 - loss: 0.0403 - val_accuracy: 0.1691 - val_loss: 0.0230 - learning_rate: 0.0010\n",
            "Epoch 26/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.1656 - loss: 0.0329\n",
            "Epoch 26: val_loss improved from 0.02301 to 0.01864, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 195ms/step - accuracy: 0.1657 - loss: 0.0329 - val_accuracy: 0.1691 - val_loss: 0.0186 - learning_rate: 0.0010\n",
            "Epoch 27/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.1656 - loss: 0.0290\n",
            "Epoch 27: val_loss improved from 0.01864 to 0.01596, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 239ms/step - accuracy: 0.1657 - loss: 0.0290 - val_accuracy: 0.1691 - val_loss: 0.0160 - learning_rate: 0.0010\n",
            "Epoch 28/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.1656 - loss: 0.0268\n",
            "Epoch 28: val_loss improved from 0.01596 to 0.01347, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 201ms/step - accuracy: 0.1657 - loss: 0.0267 - val_accuracy: 0.1691 - val_loss: 0.0135 - learning_rate: 0.0010\n",
            "Epoch 29/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.1655 - loss: 0.0236\n",
            "Epoch 29: val_loss did not improve from 0.01347\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 227ms/step - accuracy: 0.1656 - loss: 0.0236 - val_accuracy: 0.1691 - val_loss: 0.0142 - learning_rate: 0.0010\n",
            "Epoch 30/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.1655 - loss: 0.0224\n",
            "Epoch 30: val_loss improved from 0.01347 to 0.01209, saving model to best_translation_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 245ms/step - accuracy: 0.1656 - loss: 0.0223 - val_accuracy: 0.1691 - val_loss: 0.0121 - learning_rate: 0.0010\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Training completed in 227.50 seconds\n",
            "🔧 Building inference models...\n",
            "✅ Inference models ready\n",
            "💾 Saving model to translation_model...\n",
            "✅ Model saved successfully!\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1500x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🧪 Evaluating model...\n",
            " 1. EN: hello\n",
            "    Expected: வணக்கம்\n",
            "    Predicted: வணக்கம்\n",
            "    Word Acc: 1.000\n",
            "\n",
            " 2. EN: thank you\n",
            "    Expected: நன்றி\n",
            "    Predicted: நன்றி\n",
            "    Word Acc: 1.000\n",
            "\n",
            " 3. EN: how are you\n",
            "    Expected: நீங்கள் எப்படி இருக்கிறீர்கள்\n",
            "    Predicted: நீங்கள் எப்படி இருக்கிறீர்கள்\n",
            "    Word Acc: 1.000\n",
            "\n",
            " 4. EN: i am fine\n",
            "    Expected: நான் நலமாக இருக்கிறேன்\n",
            "    Predicted: நான் நலமாக இருக்கிறேன்\n",
            "    Word Acc: 1.000\n",
            "\n",
            " 5. EN: good morning\n",
            "    Expected: காலை வணக்கம்\n",
            "    Predicted: காலை வணக்கம்\n",
            "    Word Acc: 1.000\n",
            "\n",
            " 6. EN: where is hospital\n",
            "    Expected: மருத்துவமனை எங்கே\n",
            "    Predicted: அது தூரத்தில் உள்ளது\n",
            "    Word Acc: 0.000\n",
            "\n",
            " 7. EN: i need help\n",
            "    Expected: எனக்கு உதவி தேவை\n",
            "    Predicted: எனக்கு உதவி தேவை\n",
            "    Word Acc: 1.000\n",
            "\n",
            " 8. EN: i love you\n",
            "    Expected: நான் உன்னை நேசிக்கிறேன்\n",
            "    Predicted: நான் உன்னை நேசிக்கிறேன்\n",
            "    Word Acc: 1.000\n",
            "\n",
            "📊 Results:\n",
            "   Exact matches: 7/8 (87.5%)\n",
            "   Average word accuracy: 0.875\n",
            "\n",
            "🎮 Interactive Translation Session\n",
            "Commands: 'test' for examples, 'quit' to exit\n",
            "--------------------------------------------------\n",
            "🌟 Tamil: தயவுசெய்து நண்பர்கள்\n",
            "🌟 Tamil: தயவுசெய்து\n",
            "🌟 Tamil: நீங்கள் எங்கிருந்து வருகிறீர்கள்\n",
            "🌟 Tamil: மன்னிக்கவும் வரவேற்பு\n",
            "🌟 Tamil: Unable to tokenize input\n",
            "🌟 Tamil: Unable to tokenize input\n",
            "🌟 Tamil: மன்னிக்கவும்\n",
            "🌟 Tamil: மன்னிக்கவும்\n",
            "🌟 Tamil: நன்றி\n",
            "🌟 Tamil: Unable to tokenize input\n",
            "🌟 Tamil: Unable to tokenize input\n",
            "🌟 Tamil: நீங்கள் எங்கிருந்து வருகிறீர்கள்\n",
            "🌟 Tamil: மன்னிக்கவும்\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dch7kklvrCkB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}